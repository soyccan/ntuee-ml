{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "np.set_printoptions(threshold=1e3, suppress=True, precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.X_t = None\n",
    "        self.y_hat = None\n",
    "        self.df = None\n",
    "        self.w = None\n",
    "    def normalize(self):\n",
    "        mean_x = np.nanmean(self.X, axis=1)\n",
    "        std_x = np.nanstd(self.X, axis=1)\n",
    "        std_x[std_x == 0] = 1\n",
    "        self.X = (self.X - mean_x[:, np.newaxis]) / std_x[:, np.newaxis]\n",
    "        self.X_t = self.X.T\n",
    "\n",
    "trainset = Dataset()\n",
    "trainset.df = pd.read_csv('train_datas_0.csv', dtype='float', na_values='-')\n",
    "trainset.df1 = pd.read_csv('train_datas_1.csv').apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "testset = Dataset()\n",
    "testset.df = pd.read_csv('test_datas.csv', dtype='float', na_values='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_data(sel_cols=['PM2.5']):\n",
    "    # correct dataframe\n",
    "    trainset.df1.drop(trainset.df1.index[-2+2162:-2+2208], inplace=True)\n",
    "    trainset.df1.dropna(how='all', inplace=True)\n",
    "    trainset.df1.drop(trainset.df1.index[(trainset.df1 == 0).all(axis=1)], inplace=True)\n",
    "    for s in (trainset.df, trainset.df1, testset.df):\n",
    "        for cnam in s.columns:\n",
    "            # fill NaN with mean\n",
    "            s[cnam].fillna(s[cnam].mean(), inplace=True)\n",
    "\n",
    "            # replace outlier with mean\n",
    "            # TODO: inplace?\n",
    "            s[cnam][abs(s[cnam] - s[cnam].mean()) > 10 * s[cnam].std()] = s[cnam].mean()\n",
    "\n",
    "        s.reindex()\n",
    "\n",
    "    # extract feature\n",
    "    c = len(sel_cols)\n",
    "    d = c * 9 * 2 + 18\n",
    "    n = len(trainset.df) - 9 + len(trainset.df1) - 9\n",
    "    X = torch.zeros((n, d))\n",
    "    y_hat = torch.zeros((n, 1))\n",
    "    \n",
    "    for i in range(len(trainset.df)-9):\n",
    "        X[i, 0:c*9] = torch.tensor(trainset.df.iloc[i:i+9][sel_cols].values.flatten())\n",
    "        X[i, c*9:c*9*2] = X[i, 0:c*9] ** 2\n",
    "        for j in range(9):\n",
    "            X[i, c*9*2+j] = (i+j) % 24 # hour\n",
    "        for j in range(9):\n",
    "            X[i, c*9*2+9+j] = ((i+j) // 24) % 365 # day\n",
    "        y_hat[i] = trainset.df.iloc[i+9]['PM2.5']\n",
    "    \n",
    "#     off = len(trainset.df) - 9\n",
    "#     for i in range(len(trainset.df1)-9):\n",
    "#         X[i+off, 0:15*9] = torch.tensor(trainset.df1.iloc[i:i+9].values.flatten())\n",
    "#         X[i+off, 15*9] = i % 24 # hour\n",
    "#         X[i+off, 15*9+1] = (i // 24) % 365 # day\n",
    "#         y_hat[i] = trainset.df1.iloc[i+9]['PM2.5']\n",
    "\n",
    "    trainset.X = X\n",
    "    trainset.y_hat = y_hat\n",
    "    #trainset.normalize()\n",
    "\n",
    "preprocess_training_data()#trainset.df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 764., 1930., 1824., 1486.,  926.,  706.,  443.,  328.,  147.,\n",
       "         104.,   48.,   14.,   15.,    9.,    8.,    3.,    4.,    0.,\n",
       "           0.,    3.]),\n",
       " array([  2.  ,   9.55,  17.1 ,  24.65,  32.2 ,  39.75,  47.3 ,  54.85,\n",
       "         62.4 ,  69.95,  77.5 ,  85.05,  92.6 , 100.15, 107.7 , 115.25,\n",
       "        122.8 , 130.35, 137.9 , 145.45, 153.  ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trainset.df['PM2.5'],bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(X, y_hat):\n",
    "    n, d = X.shape\n",
    "\n",
    "    linear_module = torch.nn.Linear(d, 1, bias=True)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    optim = torch.optim.Adam(linear_module.parameters(), lr=1e-3, betas=(0.99, 0.999))\n",
    "    num_iter = 10000\n",
    "\n",
    "    print('iter,\\tloss,\\tw')\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        y = linear_module(X)\n",
    "        loss = loss_func(y, y_hat) + 1e-5 * torch.norm(linear_module.weight)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(d).detach().numpy()))\n",
    "\n",
    "    true_w, residuals, rank, s  = np.linalg.lstsq(X.view((n, d)).numpy(), y_hat.view(n).numpy())\n",
    "            \n",
    "    print('\\ntrue w\\t\\t', true_w)\n",
    "    print('estimated w\\t', linear_module.weight.view(d).detach().numpy())\n",
    "    print('bias\\t', linear_module.bias.view(1).detach().numpy())\n",
    "    \n",
    "    testset.linear_module = linear_module\n",
    "\n",
    "#train(trainset.X, trainset.y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t24952.33,\t[ 0.14 -0.01 -0.11 -0.07 -0.1   0.13  0.04  0.05  0.03 -0.05  0.1   0.12 -0.15\n",
      "  0.02  0.13 -0.02  0.02  0.04  0.08  0.11 -0.17  0.12 -0.11 -0.16  0.05  0.08\n",
      " -0.06 -0.1   0.06  0.11  0.02  0.1  -0.16 -0.14  0.14 -0.07]\n",
      "1000,\t54.81,\t[ 0.18 -0.03 -0.14  0.02 -0.08  0.09  0.07  0.06  0.04 -0.01  0.    0.02 -0.02\n",
      "  0.01  0.01 -0.01  0.01  0.01  0.09  0.12 -0.13  0.15 -0.07 -0.1   0.09  0.11\n",
      " -0.01 -0.09  0.07  0.11  0.03  0.11 -0.15 -0.13  0.15 -0.06]\n",
      "2000,\t15.90,\t[ 0.21 -0.   -0.11  0.06 -0.05  0.12  0.11  0.1   0.09 -0.    0.    0.   -0.\n",
      "  0.   -0.   -0.    0.    0.01  0.09  0.12 -0.13  0.14 -0.06 -0.08  0.09  0.12\n",
      "  0.01 -0.09  0.07  0.11  0.03  0.11 -0.15 -0.13  0.15 -0.06]\n",
      "3000,\t13.68,\t[ 0.23  0.02 -0.08  0.09 -0.02  0.15  0.14  0.14  0.13 -0.    0.    0.   -0.\n",
      "  0.   -0.   -0.   -0.    0.01  0.07  0.09 -0.14  0.11 -0.07 -0.08  0.06  0.09\n",
      "  0.01 -0.09  0.07  0.11  0.02  0.11 -0.16 -0.14  0.14 -0.06]\n",
      "4000,\t12.97,\t[ 0.24  0.03 -0.07  0.1  -0.    0.17  0.16  0.17  0.18 -0.   -0.    0.   -0.\n",
      " -0.   -0.   -0.   -0.    0.01  0.04  0.07 -0.13  0.09 -0.06 -0.06  0.04  0.06\n",
      " -0.   -0.09  0.06  0.11  0.02  0.11 -0.16 -0.14  0.14 -0.06]\n",
      "5000,\t12.64,\t[ 0.22  0.02 -0.07  0.09 -0.    0.17  0.17  0.19  0.22 -0.    0.    0.   -0.\n",
      " -0.   -0.   -0.   -0.    0.01  0.03  0.05 -0.11  0.06 -0.04 -0.03  0.01  0.03\n",
      " -0.01 -0.09  0.06  0.11  0.02  0.11 -0.16 -0.14  0.14 -0.06]\n",
      "6000,\t12.37,\t[ 0.2   0.01 -0.07  0.08 -0.01  0.16  0.17  0.21  0.27 -0.    0.    0.   -0.\n",
      "  0.   -0.   -0.   -0.    0.    0.02  0.04 -0.07  0.03 -0.03 -0.   -0.01  0.02\n",
      " -0.   -0.1   0.06  0.11  0.02  0.11 -0.16 -0.14  0.14 -0.06]\n",
      "7000,\t12.13,\t[ 0.17 -0.01 -0.07  0.06 -0.01  0.15  0.16  0.23  0.34 -0.    0.    0.   -0.\n",
      "  0.   -0.   -0.   -0.    0.    0.02  0.03 -0.04 -0.01 -0.02  0.02 -0.02  0.01\n",
      "  0.01 -0.1   0.06  0.11  0.02  0.11 -0.16 -0.14  0.14 -0.05]\n",
      "8000,\t11.97,\t[ 0.14 -0.01 -0.05  0.04 -0.02  0.13  0.14  0.25  0.41 -0.    0.    0.   -0.\n",
      "  0.   -0.   -0.   -0.    0.    0.02  0.02 -0.01 -0.03 -0.02  0.03 -0.04  0.01\n",
      "  0.01 -0.1   0.06  0.11  0.02  0.11 -0.16 -0.14  0.14 -0.05]\n",
      "9000,\t11.87,\t[ 0.11 -0.01 -0.02  0.02 -0.02  0.11  0.11  0.24  0.49 -0.    0.    0.   -0.\n",
      "  0.   -0.   -0.   -0.    0.    0.02  0.01  0.   -0.04 -0.02  0.04 -0.04  0.02\n",
      "  0.01 -0.1   0.06  0.11  0.02  0.1  -0.16 -0.14  0.14 -0.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soyccan/anaconda3/envs/ml-hw1/lib/python3.6/site-packages/ipykernel_launcher.py:21: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "true w\t\t [ 0.05 -0.    0.07 -0.05  0.01  0.1   0.02  0.2   0.6  -0.    0.   -0.    0.\n",
      " -0.   -0.    0.   -0.    0.   -0.08 -0.06 -0.04 -0.06 -0.01  0.09  0.03  0.11\n",
      "  0.   -2.37 -1.69 -1.01 -0.34  0.34  1.01  1.69  2.37 -0.01]\n",
      "estimated w\t [ 0.08 -0.01  0.01 -0.   -0.02  0.1   0.07  0.23  0.55 -0.    0.    0.   -0.\n",
      "  0.   -0.   -0.   -0.    0.    0.02  0.01  0.01 -0.04 -0.02  0.04 -0.04  0.02\n",
      "  0.01 -0.1   0.06  0.1   0.02  0.1  -0.16 -0.14  0.14 -0.03]\n",
      "bias\t [0.03]\n",
      "validate loss 71.06912231445312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def validate():\n",
    "    X = trainset.X\n",
    "    y_hat = trainset.y_hat\n",
    "    n, d = X.shape\n",
    "\n",
    "    validate_sz = 2000\n",
    "    losses = []\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    for i in range(0, n, validate_sz):\n",
    "        idx_validate = pd.Series([False] * n)\n",
    "        idx_validate[i:i+validate_sz] = True\n",
    "\n",
    "        train(X[~idx_validate], y_hat[~idx_validate])\n",
    "        y = testset.linear_module(X[idx_validate])\n",
    "        l = loss_func(y, y_hat[idx_validate])\n",
    "        losses.append(l.item())\n",
    "        \n",
    "        break\n",
    "\n",
    "    print('validate loss', np.mean(losses))\n",
    "    print()\n",
    "\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_testing_data(sel_cols=['PM2.5']):\n",
    "    c = len(sel_cols)\n",
    "    d = c * 9 * 2 + 18\n",
    "    n = (len(testset.df) + 8) // 9\n",
    "    X = torch.zeros((n, d))\n",
    "\n",
    "    # extract feature\n",
    "    for i in range(n):\n",
    "        X[i, 0:c*9] = torch.tensor(testset.df.iloc[i*9:(i+1)*9][sel_cols].values.flatten())\n",
    "        X[i, c*9:c*9*2] = X[i, 0:c*9] ** 2\n",
    "        for j in range(9):\n",
    "            X[i, c*9*2+j] = (i*9+j) % 24 # hour\n",
    "        for j in range(9):\n",
    "            X[i, c*9*2+9+j] = ((i*9+j) // 24) % 365 # day\n",
    "    testset.X = X\n",
    "\n",
    "    #testset.normalize()\n",
    "\n",
    "preprocess_testing_data()#testset.df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13. 17. 21. 34. 24. 42. 54. 64. 67. 57. 43. 37. 58. 50. 40. 46. 31. 30. 22.\n",
      " 32. 32. 34. 27. 21. 24. 15.  6.  9. 21. 21. 22. 18. 18. 18. 24. 27. 16. 20.\n",
      "  8.  6. 11. 22. 20. 25. 21. 28. 27. 34. 33. 30. 45. 32. 34. 38. 22. 26. 13.\n",
      " 13.  6.  3.  4.  2.  5.  7.  9.  6.  3.  8. 21. 22. 27. 30. 23. 23. 53. 26.\n",
      " 19. 15. 16. 16. 18. 14.  5. 10. 19. 16. 12.  8.  8.  9. 14. 12. 14. 20. 26.\n",
      " 26. 39. 34. 31. 25. 48. 33. 25. 10.  2. 29. 27. 18. 15.  6.  3. 10. 16. 14.\n",
      " 13. 18. 24. 23. 23. 16. 18. 23. 26. 30. 22. 28. 22. 23. 39. 52. 37. 12. 14.\n",
      "  9. 23. 18. 15. 18. 29. 19. 28. 30. 26. 11. 12. 16. 21. 24. 26. 13.  3.  6.\n",
      "  9. 20. 23. 25. 10. 16. 25. 21. 23. 19. 12. 10.  7. 13. 27. 32. 30. 27. 37.\n",
      " 18.  4. 15. 15. 20. 22. 20. 29. 27. 21. 28. 26. 38. 28. 26. 21. 27. 31. 34.\n",
      " 23. 24. 23. 17. 22. 24. 20. 26. 23. 25. 30. 24. 23. 22. 18. 13.  9.  5.  2.\n",
      " 16. 15. 17. 16. 17. 20. 25. 16. 17. 20. 25. 24. 28. 22. 15. 20. 20. 24. 15.\n",
      "  4. 21. 14. 17. 26. 25. 24. 20. 29. 39. 26. 28. 32. 20.  8. 14. 15. 28. 33.\n",
      " 26. 48. 42. 31. 27. 41. 27. 26. 30. 35. 24. 26. 18. 18. 23.  6. 29. 33. 22.\n",
      " 12. 15. 15. 22. 18. 24. 21. 39. 33. 34. 24. 24. 27. 37. 32. 29. 33. 34. 40.\n",
      " 37. 26. 37. 22. 20. 20. 16. 18.  9. 11. 14. 11. 13. 12.  8.  9.  9.  9. 13.\n",
      " 12.  8.  7.  9.  7.  6.  7.  4.  9. 20. 23. 14. 13. 25. 23. 23. 13. 17. 17.\n",
      " 18. 11.  5.  6.  6.  8.  9.  6.  5.  7.  9. 14. 12. 12.  7. 11. 10.  7. 12.\n",
      " 10. 11. 11. 10.  9. 10.  7.  4.  8.  6.  6. 11.  6. 15.  9.  9.  8.  4.  5.\n",
      "  6.  9.  3.  8.  5.  9.  9.  6.  5.  5.  9.  3. 10.  4.  5.  4.  3.  5.  6.\n",
      "  6.  4. 13.  7. 11. 14.  9.  5.  8. 12.  7.  5.  5.  5.  5.  7.  7.  9.  9.\n",
      "  9.  8. 13.  7. 11.  9.  7.  8.  9. 20.  6.  6.  5. 10.  9.  6. 15.  5.  6.\n",
      "  6.  5.  7.  7.  8.  7.  7. 10. 10. 12.  4.  9.  4.  6.  7.  7.  7.  9.  8.\n",
      "  9.  8.  8.  8.  8. 10. 14.  6. 11.  6.  6.  7.  5. 10.  5.  8.  4.  5.  8.\n",
      "  9.  9.  7. 12. 12. 10. 11.  8.  9.  3. 13.  6.  6. 10.  4.  3. 11.  9.  3.\n",
      "  3.  7.  6.  5.  6.  8. 10. 13. 12.  6.  9.  8.  4.  4.  4. 10.  5.  4.  8.\n",
      "  7.  9.  5.  6. 12. 11.]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    X = testset.X\n",
    "    linear_module = testset.linear_module\n",
    "    n, d = X.shape\n",
    "    \n",
    "    y = linear_module(X)\n",
    "    y = torch.round(y).view(n).detach().numpy()\n",
    "    print(y)\n",
    "    testset.y = y\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    'id': ['id_' + str(i) for i in range(500)],\n",
    "    'value': testset.y\n",
    "})\n",
    "pred_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13., 135., 114.,  96.,  83.,  36.,  12.,   6.,   3.,   2.]),\n",
       " array([-5. ,  2.7, 10.4, 18.1, 25.8, 33.5, 41.2, 48.9, 56.6, 64.3, 72. ],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(testset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_solution():\n",
    "    w_hat, residuals, rank, s  = np.linalg.lstsq(trainset.X_t, trainset.y_hat)\n",
    "    X = trainset.X\n",
    "    X_t = trainset.X_t\n",
    "    y_hat = trainset.y_hat\n",
    "    assert w_hat.shape[0] == DIM\n",
    "    print('w_hat',w_hat)\n",
    "    print('train loss', np.linalg.norm(trainset.X_t.dot(w_hat) - trainset.y_hat)**2)\n",
    "    testset.w = w_hat\n",
    "\n",
    "    loss = []\n",
    "    d, n = trainset.X.shape\n",
    "    validate_sz = 2000\n",
    "    for i in range(0, n, validate_sz):\n",
    "        idx_validate = pd.Series([False] * n)\n",
    "        idx_validate[i:i+validate_sz] = True\n",
    "        loss.append(validate(X[:, idx_validate], y_hat[idx_validate], testset.w))\n",
    "    print('validation loss', np.mean(loss))\n",
    "    \n",
    "    return np.dot(testset.X_t, w_hat).round(0).astype(int)\n",
    "\n",
    "# y_pred = closed_form_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
