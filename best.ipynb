{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "np.set_printoptions(threshold=1e3, suppress=True, precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(s):\n",
    "    torch.manual_seed(s)\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.X_t = None\n",
    "        self.y_hat = None\n",
    "        self.df = None\n",
    "        self.w = None\n",
    "    def normalize(self):\n",
    "        mean_x = torch.mean(self.X, axis=0)\n",
    "        std_x = torch.mean(self.X, axis=0)\n",
    "        std_x[std_x == 0] = 1\n",
    "        self.X = (self.X - mean_x[None, :]) / std_x[None, :]\n",
    "\n",
    "trainset = Dataset()\n",
    "trainset.full_df0 = pd.read_csv('train_datas_0.csv', dtype='float', na_values='-',\n",
    "                                skiprows=[61-2, 86-2])\n",
    "trainset.full_df1 = pd.read_csv('train_datas_1.csv', dtype='float', na_values='-', \n",
    "                                skiprows=np.arange(2162-2, 2208-2))\n",
    "#.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "testset = Dataset()\n",
    "testset.full_df = pd.read_csv('test_datas.csv', dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correcting dataframe\n",
      "extracting feature\n",
      "i 0\n",
      "i 1000\n",
      "i 2000\n",
      "i 3000\n",
      "i 4000\n",
      "i 5000\n",
      "i 6000\n",
      "i 7000\n",
      "i 8000\n",
      "i 9000\n",
      "i 10000\n",
      "i 11000\n",
      "i 12000\n",
      "i 13000\n",
      "i 14000\n",
      "i 15000\n",
      "i 16000\n",
      "i 17000\n"
     ]
    }
   ],
   "source": [
    "def preprocess_training_data(sel_cols=['PM2.5']):\n",
    "    trainset.df = pd.concat([trainset.full_df0, trainset.full_df1])\n",
    "    \n",
    "    # add hour and day\n",
    "#     n0 = len(trainset.full_df0)\n",
    "#     n1 = len(trainset.full_df1)\n",
    "#     n = n0 + n1\n",
    "#     trainset.df['hour'] = np.tile(np.arange(24), (n+23)//24)[:n]\n",
    "#     trainset.df['day'] = np.tile(np.repeat(np.arange(365), 24), (n+364)//365)[:n]\n",
    "#     print(trainset.df)\n",
    "\n",
    "    print('correcting dataframe')\n",
    "    trainset.df.dropna(how='all', inplace=True)\n",
    "    trainset.df.drop(trainset.df.index[(trainset.df == 0).all(axis=1)], inplace=True)\n",
    "    for cnam in trainset.df.columns:\n",
    "        # fill NaN with mean\n",
    "        trainset.df[cnam].fillna(trainset.df[cnam].mean(), inplace=True)\n",
    "\n",
    "        # replace outlier with mean\n",
    "        cond = abs(trainset.df[cnam] - trainset.df[cnam].mean()) > 5 * trainset.df[cnam].std()\n",
    "        trainset.df[cnam][cond] = trainset.df[cnam].mean()\n",
    "\n",
    "    trainset.df.reindex()\n",
    "\n",
    "    print('extracting feature')\n",
    "    b = 9 # how many days before are used as feature\n",
    "    c = len(sel_cols)\n",
    "    d = c * b #+ b*c*b*c\n",
    "    n = len(trainset.df) - b\n",
    "    X = torch.zeros((n, d))\n",
    "    y_hat = torch.zeros((n, 1))\n",
    "    \n",
    "    for i in range(n):\n",
    "        if i % 1000 == 0:\n",
    "            print('i',i)\n",
    "        X[i, 0:c*b] = torch.tensor(trainset.df.iloc[i:i+b][sel_cols].values.flatten())\n",
    "#         for j in range(c*b):\n",
    "#             for k in range(c*b):\n",
    "#                 X[i, c*b*(j+1) + k] = X[i, j] * X[i, k]\n",
    "        y_hat[i] = trainset.df.iloc[i+b]['PM2.5']\n",
    "\n",
    "    trainset.X = X\n",
    "    trainset.y_hat = y_hat\n",
    "    #trainset.normalize()\n",
    "\n",
    "preprocess_training_data(trainset.full_df0.columns.difference(exclude_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(X, y_hat, model_path=None):\n",
    "    n, d = X.shape\n",
    "    print('n,d=',n,d)\n",
    "    \n",
    "    if model_path:\n",
    "        print('loading old model')\n",
    "        net = torch.load(model_path)\n",
    "        net.eval()\n",
    "    else:\n",
    "        net = torch.nn.Sequential(\n",
    "                torch.nn.Linear(d, 15),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(15, 1))\n",
    "#         net = torch.nn.Linear(d, 1, bias=True)\n",
    "#         net = Net(n_feature=d, n_hidden=1, n_output=1) #you can use different n_hidden & lr for test\n",
    "#         print(net)\n",
    "\n",
    "#     reset_seed(1383267)\n",
    "#     linear_module = torch.nn.Linear(d, 1, bias=True)\n",
    "#     loss_func = torch.nn.MSELoss()\n",
    "#     optim = torch.optim.SGD(linear_module.parameters(), lr=1e-7)#, betas=(0.99, 0.999))\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "#     plt.ion()\n",
    "\n",
    "    num_iter = 10000\n",
    "\n",
    "    print('iter,\\tloss,\\tw')\n",
    "\n",
    "    for i in range(num_iter+1):\n",
    "        y = net(X)\n",
    "        loss = loss_func(y, y_hat) #+ 1e-5 * torch.sum(net.weight ** 2)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "#             print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), net.weight.view(d).detach().numpy()))\n",
    "            print('{},\\t{:.2f}'.format(i, loss.item()))\n",
    "\n",
    "    _X = np.concatenate((X.view((n,d)).detach().numpy(), np.ones((n,1))), axis=1)\n",
    "    _y_hat = y_hat.view(n).detach().numpy()\n",
    "    true_w, residuals, rank, s = np.linalg.lstsq(_X, _y_hat)\n",
    "\n",
    "#     print()\n",
    "#     print('true w and bias\\t', true_w)\n",
    "#     print('true loss\\t', np.mean((_X @ true_w - _y_hat) ** 2))\n",
    "#     print('estimated w\\t', net.weight.view(d).detach().numpy())\n",
    "#     print('estimated bias\\t', net.bias.view(1).detach().numpy())\n",
    "    \n",
    "    testset.net = net\n",
    "    testset.true_w = true_w\n",
    "\n",
    "#train(trainset.X, trainset.y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n,d= 15403 135\n",
      "iter,\tloss,\tw\n",
      "0,\t562.92\n",
      "1000,\t26.62\n",
      "2000,\t26.53\n",
      "3000,\t25.56\n",
      "4000,\t24.87\n",
      "5000,\t24.17\n",
      "6000,\t23.78\n",
      "7000,\t23.48\n",
      "8000,\t23.44\n",
      "9000,\t23.23\n",
      "10000,\t23.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soyccan/anaconda3/envs/ml-hw1/lib/python3.6/site-packages/ipykernel_launcher.py:43: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate loss with estimated 76.8954086303711\n",
      "validate loss with true 72.56097581491089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def validate():\n",
    "    X = trainset.X\n",
    "    y_hat = trainset.y_hat\n",
    "    n, d = X.shape\n",
    "\n",
    "    validate_sz = 2000\n",
    "    losses = []\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    for i in range(0, n, validate_sz):\n",
    "        idx_validate = pd.Series([False] * n)\n",
    "        idx_validate[i:i+validate_sz] = True\n",
    "\n",
    "        train(X[~idx_validate], y_hat[~idx_validate], model_path=None)\n",
    "        y = testset.net(X[idx_validate])\n",
    "        l = loss_func(y, y_hat[idx_validate])\n",
    "        losses.append(l.item())\n",
    "        \n",
    "        break\n",
    "    \n",
    "    vn = validate_sz\n",
    "    _X = np.concatenate((X[idx_validate].numpy(), np.ones((vn, 1))), axis=1)\n",
    "    _y_hat = y_hat[idx_validate].view(vn).numpy()\n",
    "    true_loss = np.mean((_X @ testset.true_w - _y_hat) ** 2)\n",
    "\n",
    "    print('validate loss with estimated', np.mean(losses))\n",
    "    print('validate loss with true', true_loss)\n",
    "    print()\n",
    "\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(testset.net, 'model-ord1-all-hidlayer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_testing_data(sel_cols=['PM2.5']):\n",
    "    testset.df = testset.full_df.copy()\n",
    "\n",
    "    for cnam in testset.df.columns:\n",
    "        # fill NaN with mean\n",
    "        testset.df[cnam].fillna(testset.df[cnam].mean(), inplace=True)\n",
    "\n",
    "        # replace outlier with mean\n",
    "        cond = abs(testset.df[cnam] - testset.df[cnam].mean()) > 5 * testset.df[cnam].std()\n",
    "        testset.df[cnam][cond] = testset.df[cnam].mean()\n",
    "\n",
    "    # extract feature\n",
    "    c = len(sel_cols)\n",
    "    d = c * 9  + 9 * c * 9 * c\n",
    "    n = (len(testset.df) + 8) // 9\n",
    "    X = torch.zeros((n, d))\n",
    "\n",
    "    for i in range(n):\n",
    "        X[i, 0:c*9] = torch.tensor(testset.df.iloc[i*9:(i+1)*9][sel_cols].values.flatten())\n",
    "        for j in range(c*9):\n",
    "            for k in range(c*9):\n",
    "                X[i, c*9*(j+1) + k] = X[i, j] * X[i, k]\n",
    "    testset.X = X\n",
    "    #testset.normalize()\n",
    "\n",
    "preprocess_testing_data()#testset.full_df.columns.difference(exclude_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 17 20 34 24 40 62 64 65 57 41 35 58 55 40 46 28 30 21 32 30 33 26 20 24 15\n",
      "  6 10 21 20 22 19 17 18 23 27 17 19  8  6 11 22 20 24 20 27 27 34 33 30 47 28\n",
      " 28 38 22 25 23 13  6  4  4  2  5  8 10  7  4  8 22 21 26 29 23 23 46 26 19 13\n",
      " 17 16 19 14  5 11 18 15 12  8  9 10 13 12 14 19 25 26 39 34 30 25 47 32 24 11\n",
      "  3 29 27 18 15  6  3 10 15 15 13 19 22 22 23 16 18 23 25 30 22 26 22 23 39 53\n",
      " 37 14 14  9 24 18 16 18 29 19 28 30 27 10 12 16 21 24 26 14  4  7  9 19 22 25\n",
      " 10 15 25 21 23 19 12 10  7 12 27 31 28 27 36 19  4 14 15 20 22 20 29 27 21 27\n",
      " 27 38 29 26 20 27 32 33 22 24 23 17 22 24 20 25 23 25 23 24 22 23 19 12 10  5\n",
      "  3 16 15 18 16 16 20 24 15 17 20 26 24 27 22 15 20 21 23 17  2 20 14 17 26 24\n",
      " 24 20 28 37 26 28 32 16  8 14 16 24 33 26 47 42 30 27 40 25 25 31 34 25 27 17\n",
      " 18 23  5 29 33 22 12 15 15 21 18 24 22 38 34 34 25 22 26 37 32 29 33 35 39 36\n",
      " 25 37 21 20 20 16 18  9 11 14 11 14 13  9  9  8  9 13 12  9  7  9  7  5  8  4\n",
      "  9 21 22 14 13 24 23 24 13 17 17 19 11  5  6  7  7  9  7  6  7  8 14 13 13  7\n",
      " 10 10  8 11 10 12 12 10  9 11  8  4  9  7  6 11  6 14  9  8  9  4  6  6  9  4\n",
      "  8  5  9  9  7  5  5  9  4 10  5  6  5  4  6  7  6  4 14  7 11 14  9  5  9 12\n",
      "  8  6  6  5  5  8  8  9 10  9  9 13  7 11  9  7  9  9 21  7  6  6 10  9  7 15\n",
      "  6  7  6  6  8  7  8  8  8 10 10 12  5  9  4  6  7  7  8  9  9  9  9  8  8  9\n",
      " 10 14  7 10  7  6  8  6 10  6  9  4  6  8 10 10  7 12 12 10 11  8 10  3 13  7\n",
      "  6  9  4  4 11  9  4  4  7  5  6  6  8 10 13 13  7  8  9  5  4  5 10  6  4  7\n",
      "  7 10  6  7 12 12]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    #train(trainset.X, trainset.y_hat)\n",
    "\n",
    "    n, d = testset.X.shape\n",
    "\n",
    "#     y = testset.net(testset.X)\n",
    "#     y = y.view(n).detach().numpy()\n",
    "    #y = torch.round(y).view(n).detach().numpy().astype(int)\n",
    "    \n",
    "    _X = np.concatenate((testset.X.numpy(), np.ones((n, 1))), axis=1)\n",
    "    y = _X @ testset.true_w\n",
    "    y = np.rint(y).astype(int)\n",
    "\n",
    "    testset.y = y\n",
    "    print(y)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    'id': ['id_' + str(i) for i in range(500)],\n",
    "    'value': testset.y\n",
    "})\n",
    "pred_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
