{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import sklearn.model_selection\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    # global variables\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G.df_train_full = pd.read_csv('X_train', dtype=np.int32)\n",
    "G.df_test_full = pd.read_csv('X_test', dtype=np.int32)\n",
    "G.y_train = torch.tensor(\n",
    "    np.array(open('Y_train').read().strip('\\n').split('\\n'),\n",
    "             dtype=np.int8),\n",
    "    dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "    c = len(df.columns)\n",
    "    n = len(df)\n",
    "    d = 1 + c + 5\n",
    "\n",
    "    X = torch.zeros((n, d), dtype=torch.float64)\n",
    "    X[:, 0] = 1  # bias\n",
    "    X[:, 1:1+c] = torch.tensor(df.values)\n",
    "\n",
    "    # quadratic term\n",
    "    # ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']\n",
    "    idx = [1,2,4,5,6]\n",
    "    X[:, 1+c:1+c+5] = X[:, idx] ** 2\n",
    "\n",
    "    return X\n",
    "\n",
    "def preprocess(df_train, df_test):\n",
    "    X_train = extract(df_train)\n",
    "    X_test = extract(df_test)\n",
    "    X_full = torch.cat((X_train, X_test), dim=0)\n",
    "    \n",
    "    means = torch.mean(X_full, dim=0)\n",
    "    stds = torch.std(X_full, dim=0)\n",
    "\n",
    "    # normalize\n",
    "    # ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']\n",
    "    idx = [1,2,4,5,6]\n",
    "    X_train[:, idx] = (X_train[:, idx] - means[idx]) / stds[idx]\n",
    "    X_test[:, idx] = (X_test[:, idx] - means[idx]) / stds[idx]\n",
    "\n",
    "    return X_train, X_test, means, stds\n",
    "\n",
    "G.X_train, G.X_test, G.means, G.stds = preprocess(G.df_train_full, G.df_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('a.csv',G.X_train,fmt='%.2f',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(dim, 1, bias=False).type(torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fx = F.sigmoid(self.linear(x))\n",
    "        return fx\n",
    "    \n",
    "    def weights(self):\n",
    "        return (self.linear.weight, self.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, k, dim):\n",
    "        self.k = k\n",
    "        self.kfold = sklearn.model_selection.KFold(k)\n",
    "        self.models = [LogisticRegression(dim) for _ in range(k+1)]\n",
    "        self.optim = [torch.optim.Adam(\n",
    "                            self.models[i].parameters())\n",
    "                      for i in range(k+1)]\n",
    "        self.loss_func = torch.nn.BCELoss()\n",
    "        self.step_ctr = 0\n",
    "        self.train_loss = None\n",
    "        self.val_accur = None\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        # Copy the object's state from self.__dict__ which contains\n",
    "        # all our instance attributes. Always use the dict.copy()\n",
    "        # method to avoid modifying the original state.\n",
    "        state = self.__dict__.copy()\n",
    "        # Remove the unpicklable entries.\n",
    "        del state['X']\n",
    "        del state['Xval']\n",
    "        del state['y']\n",
    "        del state['yval']\n",
    "        return state\n",
    "    \n",
    "    def setdata(self, X, y):\n",
    "        self.n, self.d = X.shape\n",
    "        \n",
    "        # K-fold cross validation sets, index 0 is full dataset\n",
    "        self.X = [X]\n",
    "        self.Xval = [None]\n",
    "        self.y = [y]\n",
    "        self.yval = [None]\n",
    "        \n",
    "        for idx_train, idx_val in self.kfold.split(X, y):\n",
    "            self.X.append(X[idx_train])\n",
    "            self.y.append(y[idx_train])\n",
    "            self.Xval.append(X[idx_val])\n",
    "            self.yval.append(y[idx_val])\n",
    "        \n",
    "        # one-hot form of y\n",
    "#         self.y_oh = []\n",
    "#         self.yval_oh = []\n",
    "#         for i in range(self.k+1):\n",
    "#             self.y_oh.append(torch.zeros((len(self.y[i]), 2)))\n",
    "#             self.y_oh[i].index_select(0, self.y[i].type(torch.int64))\n",
    "#             if i == 0:\n",
    "#                 self.yval_oh.append(None)\n",
    "#             else:\n",
    "#                 self.yval_oh.append(torch.zeros((len(self.yval[i]), 2)))\n",
    "#                 self.yval_oh[i].index_select(0, self.yval[i].type(torch.int64))\n",
    "            \n",
    "    def _step(self, i, steps):\n",
    "        for j in range(steps):\n",
    "            fx = self.models[i](self.X[i])\n",
    "            loss = self.loss_func(fx, self.y[i])\n",
    "            self.optim[i].zero_grad()\n",
    "            loss.backward()\n",
    "            print(loss)\n",
    "            print(self.models[i].linear.weight.grad)\n",
    "            self.optim[i].step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def step(self, steps=1, log=True):\n",
    "        train_loss = [self._step(i, steps) for i in range(self.k+1)]\n",
    "        val_accur = []\n",
    "        for i in range(1, self.k+1):\n",
    "            y_pred = torch.round(torch.squeeze(self.models[i](self.Xval[i]))).type(torch.bool)\n",
    "            val_accur.append(torch.sum(y_pred == self.yval[i]) / (len(self.yval[i]) + 1e-10))\n",
    "            \n",
    "        if log:\n",
    "            print('train loss', np.mean(train_loss), train_loss)\n",
    "            print('validation accuracy', np.mean(val_accur), val_accur)\n",
    "            print(self.models[0].weights())\n",
    "            print()\n",
    "            \n",
    "        self.step_ctr += steps\n",
    "        self.train_loss = train_loss\n",
    "        self.val_accur = val_accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "23.77998218727926\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(112)\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_func = torch.nn.BCELoss() #lambda x, y: torch.mean(-y*torch.log(x+1e-10)-(1-y)*torch.log(1-x))\n",
    "fx = model(G.X_train)\n",
    "print(fx)\n",
    "fx = torch.squeeze(fx)\n",
    "print(fx)\n",
    "loss = loss_func(fx, G.y_train)\n",
    "print(loss.item())\n",
    "loss.backward()\n",
    "print(fx.grad)\n",
    "\n",
    "# optim.zero_grad()\n",
    "# loss.backward()\n",
    "# print(loss)\n",
    "# print(model.linear.weight.grad)\n",
    "# optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.9190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.2410, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(75.8834, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1148, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "train loss 63.03955612078507 [75.91904425539757, 24.241028239738334, 75.88335559957618, 76.11479638842823]\n",
      "validation accuracy 0.4157375 [tensor(0.7624), tensor(0.2401), tensor(0.2447)]\n",
      "(Parameter containing:\n",
      "tensor([[-7.3930e-04,  3.3454e-02,  3.1208e-02, -5.8433e-03,  5.5762e-03,\n",
      "         -8.5576e-02, -3.4404e-02,  8.8557e-02, -7.4190e-02,  9.0437e-04,\n",
      "          5.7940e-02,  5.5549e-02,  6.1362e-02,  4.4540e-03,  8.8055e-02,\n",
      "          6.0476e-02,  2.7813e-02, -2.3183e-03, -2.2626e-02,  2.2456e-02,\n",
      "          9.1980e-03,  8.5254e-02, -2.5694e-02,  3.8308e-02,  4.5930e-02,\n",
      "         -2.7286e-02,  9.2626e-02,  4.4477e-02,  4.0861e-03,  8.7226e-02,\n",
      "          6.4887e-02, -6.8341e-02, -1.6007e-02, -5.0826e-02, -2.2050e-02,\n",
      "          9.3341e-03, -1.1326e-02,  6.2293e-02, -1.3441e-02,  7.8299e-02,\n",
      "          3.3104e-02,  4.5387e-02,  2.4477e-02,  4.8910e-02,  3.7309e-02,\n",
      "         -5.9503e-02,  4.6570e-02,  7.3056e-02, -5.4684e-03, -3.5340e-02,\n",
      "          8.1735e-02,  1.0778e-02,  9.1600e-02, -1.9861e-02, -8.1417e-02,\n",
      "         -6.8424e-02,  3.3738e-02, -7.0701e-02, -1.1317e-02,  8.1142e-02,\n",
      "          2.9468e-02, -8.3487e-02, -3.2263e-02, -8.2316e-02, -2.7962e-02,\n",
      "          5.0743e-02,  2.6235e-02, -6.7145e-02,  6.6341e-02, -8.2204e-02,\n",
      "          4.9877e-02,  3.6692e-02, -5.7750e-02, -1.2117e-02,  3.8326e-02,\n",
      "         -1.9889e-02, -1.5663e-02, -8.3795e-02,  6.2178e-05,  5.6623e-03,\n",
      "          2.3467e-02, -2.7035e-02,  9.0460e-02,  3.4364e-02, -4.4064e-02,\n",
      "         -8.9772e-02, -3.5586e-02, -3.7419e-02, -1.1486e-02, -4.8876e-02,\n",
      "          7.7861e-02, -5.7592e-03,  4.7122e-02,  8.2539e-02, -1.4910e-02,\n",
      "          4.6358e-02, -3.9296e-02,  4.3209e-02, -1.6926e-04,  4.5261e-02,\n",
      "         -7.6614e-02, -2.6092e-02,  3.9800e-02, -1.2923e-02,  5.8064e-02,\n",
      "          6.4353e-02,  9.2593e-02, -5.1966e-02,  6.7837e-02,  4.1266e-02,\n",
      "          2.4646e-02, -4.1925e-02]], dtype=torch.float64, requires_grad=True), None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([32561])) that is different to the input size (torch.Size([32561, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([21707])) that is different to the input size (torch.Size([21707, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([21708])) that is different to the input size (torch.Size([21708, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "G.trainer = Trainer(3, G.X_train.shape[1])\n",
    "G.trainer.setdata(G.X_train, G.y_train)\n",
    "num_iter = 1\n",
    "for i in range(num_iter):\n",
    "    print('i', i)\n",
    "    G.trainer.step(10, True)\n",
    "#         joblib.dump(G.model, '2/'+str(i)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.16 0.31 0.83 0.   0.01 0.01 0.87 0.   0.04 0.68 0.6  0.01 0.25\n",
      " 0.6  0.86 0.   0.34 0.01 0.83 0.65 0.   0.   0.03 0.37 0.87 0.   0.01\n",
      " 0.3  0.07 0.91 0.01 0.05 0.17 0.01 0.21 0.6  0.   0.   0.   0.76 0.59\n",
      " 0.14 0.04 0.   0.41 0.06 0.77 0.   0.18 0.   0.01 0.   0.38 0.04 0.\n",
      " 0.28 0.86 0.9  0.12 0.09 0.11 0.06 0.   0.03 0.02 0.99 0.   0.07 0.42\n",
      " 1.   0.62 0.06 0.   0.06 0.   0.26 0.23 0.35 0.   0.42 0.08 0.03 1.\n",
      " 0.2  0.02 0.   0.51 0.01 0.86 0.1  0.01 0.8  0.27 0.04 0.   0.02 0.1\n",
      " 0.32 0.   0.28 0.01 0.   0.01 0.03 0.01 0.4  0.02 0.   0.   0.   0.18\n",
      " 0.41 0.   0.22 0.01 0.32 0.   0.03 0.1  0.08 0.   0.01 0.07 0.01 0.01\n",
      " 0.95 0.01 0.19 0.97 0.42 0.   0.   0.89 0.35 0.03 0.41 0.09 0.2  0.02\n",
      " 0.76 0.   0.94 0.85 0.03 0.06 0.09 0.25 1.   0.02 0.   0.03 0.05 0.01\n",
      " 0.78 0.   0.01 0.03 0.01 0.33 0.07 0.23 0.09 0.04 0.77 0.39 0.62 0.35\n",
      " 0.   0.1  0.79 0.22 0.02 0.48 0.06 0.54 0.13 0.25 0.35 0.59 0.39 1.\n",
      " 0.03 0.3  0.03 0.08 0.05 0.01 0.03 0.   0.88 0.29 0.04 0.01 0.01 0.03\n",
      " 0.1  0.94 0.   0.07 0.54 0.62 0.22 0.11 0.6  0.63 0.13 0.12 0.79 0.38\n",
      " 0.   0.   0.33 0.47 0.01 0.25 0.02 0.   0.06 0.03 0.52 0.01 0.05 0.5\n",
      " 0.55 0.4  1.   0.48 0.   0.1  0.   0.87 0.15 0.36 0.02 0.07 0.89 0.\n",
      " 0.02 0.15 0.   0.72 0.   0.21 0.   0.38 0.13 0.05 0.45 0.19 0.   0.09\n",
      " 0.36 0.25 0.06 0.   0.51 0.01 0.01 0.21 0.78 0.11 0.02 0.01 0.07 0.28\n",
      " 0.25 0.05 0.   0.1  0.3  0.16 0.66 0.3  0.26 0.   0.04 0.   1.   0.03\n",
      " 0.35 0.1  0.   0.04 0.57 0.03 0.   0.58 0.45 0.05 0.59 0.09 0.19 0.01\n",
      " 0.06 0.03 0.01 0.01 0.99 0.42 0.38 0.   0.02 0.01 0.   0.08 0.06 0.02\n",
      " 0.86 0.39 0.56 0.   0.25 0.54 0.6  0.12 0.01 0.   0.68 0.15 0.03 0.81\n",
      " 0.27 0.04 0.   0.68 0.13 0.   0.25 1.   0.   0.   0.32 0.09 0.92 0.\n",
      " 0.   0.01 0.2  0.22 0.12 0.18 0.02 0.77 0.96 0.05 1.   0.52 0.   0.05\n",
      " 0.02 0.   0.01 0.08 0.26 0.63 0.14 1.   0.11 0.02 0.15 0.18 0.01 0.12\n",
      " 0.42 0.8  0.57 0.53 0.27 0.   0.24 0.01 0.1  0.62 0.01 0.47 0.8  0.\n",
      " 0.04 0.   0.33 0.05 0.98 0.04 0.09 0.01 0.02 0.02 0.35 0.87 0.1  0.01\n",
      " 0.19 0.   0.02 0.02 0.84 0.09 0.65 0.75 0.09 0.   0.   0.04 0.33 0.02\n",
      " 0.07 0.01 0.01 0.64 0.01 0.29 0.   0.   0.12 0.2  0.07 0.54 1.   0.39\n",
      " 0.02 0.02 0.02 0.07 0.01 0.06 0.01 0.01 0.   0.   0.34 0.   0.31 0.01\n",
      " 0.   0.63 0.51 0.   0.53 0.88 0.33 0.28 0.01 0.5  0.   0.91 0.84 0.09\n",
      " 0.01 0.02 0.17 0.11 0.83 0.07 0.03 0.02 0.02 0.71 0.   0.25 0.23 0.14\n",
      " 0.72 0.08 0.14 0.01 0.87 0.25 0.13 0.   0.   0.02 0.02 0.34 0.02 0.02\n",
      " 0.1  0.02 0.43 0.05 0.54 0.02 0.   1.   0.02 0.08 0.   0.01 0.06 0.08\n",
      " 0.02 0.02 0.22 0.06 0.07 0.59 0.   0.12 0.   0.21 0.17 0.32 0.42 0.06\n",
      " 0.26 0.28 0.   0.99 0.   0.26 0.   0.01 0.   0.   0.02 0.   0.   0.03\n",
      " 0.98 0.   0.09 0.15 0.3  0.   0.63 0.03 0.65 0.38 0.15 0.99 0.28 0.01\n",
      " 0.02 0.09 0.22 0.6  0.14 0.78 0.43 0.   0.18 0.68 0.14 0.   0.83 0.43\n",
      " 0.72 0.17 0.11 0.32 0.   0.   0.71 0.63 0.43 0.15 0.36 0.73 0.72 0.01\n",
      " 0.02 0.01 0.47 0.03 0.01 0.04 0.17 0.02 0.73 0.   0.43 0.05 0.33 0.02\n",
      " 0.72 0.86 0.1  0.37 0.82 0.48 0.12 0.71 0.69 0.01 0.03 0.02 0.32 0.86\n",
      " 0.   0.02 0.   0.13 0.21 0.   0.82 0.02 0.01 0.65 0.82 0.   0.4  0.04\n",
      " 0.18 0.59 0.01 0.01 0.01 0.46 0.03 0.07 0.38 0.97 0.   0.02 0.21 0.11\n",
      " 0.   0.43 0.07 0.98 0.25 0.01 0.02 0.07 0.13 0.94 0.38 0.97 0.17 0.24\n",
      " 0.06 0.04 0.26 0.   0.1  0.96 0.1  0.01 0.59 0.   0.03 0.   0.9  1.\n",
      " 0.01 0.   0.   0.51 0.03 0.   0.13 0.   0.92 0.22 0.49 0.   0.83 0.01\n",
      " 0.12 0.06 0.64 0.06 0.01 0.   0.08 0.04 0.28 0.04 0.15 0.55 0.   0.02\n",
      " 0.05 0.87 0.   0.   0.04 0.01 0.02 0.98 0.21 0.02 0.3  0.44 0.6  0.07\n",
      " 0.64 0.   0.05 0.14 0.11 0.01 1.   0.2  0.34 0.   0.01 0.01 0.63 0.83\n",
      " 0.05 0.75 1.   0.   0.01 0.03 0.21 0.02 0.53 0.84 0.11 0.5  0.43 0.03\n",
      " 0.4  0.01 0.18 0.01 0.79 0.94 0.18 0.69 0.1  0.05 0.06 0.08 0.99 0.02\n",
      " 0.   0.1  0.15 0.25 0.78 0.01 0.   0.23 0.26 0.42 0.01 0.01 0.07 0.29\n",
      " 0.18 0.52 0.06 0.01 0.03 0.31 0.55 0.5  0.87 0.58 0.03 0.02 0.22 0.38\n",
      " 0.03 0.09 0.54 0.63 0.2  0.4  0.08 0.01 0.   0.   0.01 0.01 0.   0.47\n",
      " 0.   0.   0.02 0.   0.51 0.66 0.76 0.04 0.09 0.   0.01 0.63 0.33 0.05\n",
      " 0.67 0.86 0.67 0.23 0.27 0.04 0.14 0.   0.01 0.02 0.2  0.28 0.09 0.64\n",
      " 0.01 0.38 0.01 0.1  0.22 0.12 0.25 0.41 0.08 0.89 0.02 0.07 0.6  0.1\n",
      " 0.07 0.31 0.02 0.72 0.02 0.   0.   0.14 0.   0.02 0.04 0.03 0.51 0.01\n",
      " 0.02 0.   0.79 0.88 0.1  0.04 0.31 0.24 0.18 0.03 0.14 0.06 0.01 0.2\n",
      " 0.07 0.   0.   0.39 0.01 0.04 0.59 0.47 0.82 0.01 0.06 0.99 0.   0.44\n",
      " 0.01 0.12 0.32 0.2  0.74 0.15 0.02 0.32 0.02 0.03 0.06 0.06 0.79 0.13\n",
      " 0.92 0.02 0.06 0.11 0.49 0.21 0.02 0.25 0.06 0.01 0.68 0.66 0.03 0.07\n",
      " 1.   0.   0.4  0.75 0.11 0.77 0.43 0.72 0.12 0.22 0.34 0.   0.48 0.01\n",
      " 0.13 0.88 0.   0.16 0.61 0.83 0.02 0.   0.02 0.91 0.69 0.35 0.53 0.35\n",
      " 0.01 0.03 0.27 0.   0.53 0.   0.17 0.35 0.3  0.01 0.6  0.84 0.48 0.43\n",
      " 0.02 0.07 0.01 0.07 0.14 0.   0.01 0.66 0.16 0.   0.28 0.5  0.01 0.52\n",
      " 0.   0.01 0.23 0.56 0.01 0.39 0.   0.71 0.16 0.   0.13 0.35 0.05 0.\n",
      " 0.34 0.   0.56 0.   0.07 0.38 0.5  0.37 0.   0.01 0.05 0.   0.85 0.\n",
      " 0.02 0.49 0.07 0.   0.25 1.   0.31 0.07 0.06 0.1  0.01 0.62 1.   1.\n",
      " 0.32 0.   0.03 0.17 0.34 0.12 0.3  0.13 0.   0.   0.65 0.84 1.   0.41\n",
      " 0.33 0.   0.01 0.01 0.65 0.16]\n"
     ]
    }
   ],
   "source": [
    "def predict(X, w):\n",
    "    y = sigmoid(X @ w)\n",
    "    print(y[:100])\n",
    "    y = np.rint(y).astype(np.int8)\n",
    "    return y\n",
    "\n",
    "G.y_test = predict(G.X_test, G.model.w[0])#joblib.load('logistic-85589.pkl'))\n",
    "df_pred = pd.DataFrame({\n",
    "    'id': np.arange(1, len(G.X_test)+1),\n",
    "    'label': G.y_test\n",
    "})\n",
    "df_pred.to_csv('submission.csv', index=False)\n",
    "print(df_pred['label'].values[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
