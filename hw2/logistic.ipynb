{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    # global variables\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, b1=0.99, b2=0.999):\n",
    "        self.n = self.d = 0\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        self.step_ctr = 0\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        # Copy the object's state from self.__dict__ which contains\n",
    "        # all our instance attributes. Always use the dict.copy()\n",
    "        # method to avoid modifying the original state.\n",
    "        state = self.__dict__.copy()\n",
    "        # Remove the unpicklable entries.\n",
    "        del state['X']\n",
    "        del state['XT']\n",
    "        del state['Xval']\n",
    "        del state['y']\n",
    "        del state['yval']\n",
    "        return state\n",
    "    \n",
    "    def setdata(self, X, y):\n",
    "        self.n, self.d = X.shape\n",
    "\n",
    "        self.v = [0, 0, 0, 0]\n",
    "        self.w = [np.zeros(self.d) for _ in range(4)]\n",
    "        self.m = [np.zeros(self.d) for _ in range(4)]\n",
    "        \n",
    "        # 3-fold cross validation sets, 0 is full\n",
    "        ncv = (self.n + 2) // 3\n",
    "        mask = [np.zeros(self.n, dtype=np.bool_) for _ in range(4)]\n",
    "        for i in range(1, 4):\n",
    "            mask[i][(i-1)*ncv:i*ncv] = True  \n",
    "\n",
    "        self.X = [X[~mask[i], :] for i in range(4)]\n",
    "        self.XT = [self.X[i].T for i in range(len(self.X))]\n",
    "        self.Xval = [X[mask[i], :] for i in range(4)]\n",
    "        self.y = [y[~mask[i]] for i in range(4)]\n",
    "        self.yval = [y[mask[i]] for i in range(4)]      \n",
    "\n",
    "    def _step(self, i, steps):\n",
    "        for j in range(steps):\n",
    "            fx = sigmoid(self.X[i] @ self.w[i])\n",
    "            grad = self.XT[i] @ (fx - self.y[i])\n",
    "            \n",
    "            # Adam\n",
    "            self.m[i] = self.b1 * self.m[i] + (1 - self.b1) * grad\n",
    "            self.v[i] = self.b2 * self.v[i] + (1 - self.b2) * np.sum(grad ** 2)\n",
    "            self.w[i] = self.w[i] - self.m[i] / (1 - self.b1) / np.sqrt(self.v[i] / (1 - self.b2))\n",
    "\n",
    "        loss = - self.y[i] @ np.log(fx) - (1 - self.y[i]) @ np.log(1 - fx)\n",
    "        return loss\n",
    "\n",
    "    def step(self, steps=1, log=True):\n",
    "        train_loss = [self._step(i, steps) for i in range(4)]\n",
    "        val_accur = []\n",
    "        for i in range(1, 4):\n",
    "            y_pred = np.rint(sigmoid(self.Xval[i] @ self.w[i])).astype(np.int8)\n",
    "            val_accur.append(np.count_nonzero(y_pred == self.yval[i]) / (len(self.yval[i]) + 1e-10))\n",
    "            \n",
    "        if log:\n",
    "            print('train loss', np.mean(train_loss), train_loss)\n",
    "            print('validation accuracy', np.mean(val_accur[1:]), val_accur)\n",
    "            print(self.w[0])\n",
    "            print()\n",
    "            \n",
    "        self.step_ctr += steps\n",
    "        self.train_loss = train_loss\n",
    "        self.val_accur = val_accur\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.df_train_full = pd.read_csv('X_train', dtype=np.int32)\n",
    "G.df_test_full = pd.read_csv('X_test', dtype=np.int32)\n",
    "G.y_train = np.array(open('Y_train').read().strip('\\n').split('\\n'), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n,d (32561, 107)\n"
     ]
    }
   ],
   "source": [
    "def normalize(df, means, stds):\n",
    "#     cols = ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']\n",
    "    cols = df.columns\n",
    "    df = df.copy()\n",
    "    df[cols] = (df[cols] - means[cols]) / stds[cols]\n",
    "    return df\n",
    "\n",
    "def extract(df):\n",
    "    c = len(df.columns)\n",
    "    n = len(df)\n",
    "    d = 1 + c #+ 5*5 + 5\n",
    "\n",
    "    X = np.zeros((n, d), dtype=np.float64)\n",
    "    X[:, 0] = 1  # bias\n",
    "    X[:, 1:1+c] = df.values\n",
    "\n",
    "    # quadratic term (including cross product)\n",
    "    # ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']\n",
    "#     idx = np.array([1, 2, 4, 5, 6])\n",
    "#     st = 1 + c\n",
    "#     en = 1 + c + 5*5\n",
    "#     X[:, st:en] = (X[:, idx[:, None]] * X[:, idx[None, :]]).reshape((n, 5*5))\n",
    "    \n",
    "#     # cubic term\n",
    "#     st = 1 + c + 25\n",
    "#     en = 1 + c + 25 + 5\n",
    "#     X[:, st:en] = X[:, idx] ** 3\n",
    "\n",
    "    return X\n",
    "\n",
    "def preprocess(df_train, df_test):\n",
    "    df_all = pd.concat((df_train, df_test))\n",
    "    means = df_all.mean()\n",
    "    stds = df_all.std()\n",
    "\n",
    "    df_train = normalize(df_train, means, stds)\n",
    "    df_test = normalize(df_test, means, stds)\n",
    "    X_train = extract(df_train)\n",
    "    X_test = extract(df_test)\n",
    "    \n",
    "    print('n,d', X_train.shape)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "G.X_train, G.X_test = preprocess(G.df_train_full, G.df_test_full)\n",
    "# np.savetxt('a.csv',G.X_train,fmt='%.2f',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in log\n",
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in matmul\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss nan [nan, nan, nan, 7276.264864366456]\n",
      "validation accuracy 0.8465932602753259 [0.8423622627602649, 0.8466924636078786, 0.846494056942773]\n",
      "[-2.74  0.38  0.01  0.59  2.81  0.3   0.39  0.13 -0.01 -0.75  0.13  0.01\n",
      " -0.08 -0.05 -1.7  -0.02 -0.35 -0.25 -0.07 -0.24 -0.07  0.   -0.05  0.08\n",
      "  0.03  0.37  0.23  0.01  0.3  -4.22  0.15  0.1   0.04  0.06  0.52 -0.07\n",
      " -0.46 -0.06 -0.2   0.08  0.01  0.1   0.24 -0.18 -0.11 -0.12 -0.35 -1.06\n",
      "  0.26  0.08  0.09  0.11 -0.02 -0.07  0.07 -0.1  -0.34 -0.14  0.05  0.49\n",
      " -0.05  0.02 -0.05 -0.04  0.06  0.05  0.02 -0.02 -0.09  0.08 -0.41 -0.06\n",
      "  0.04  0.04  0.05  0.02 -0.07  0.04  0.03 -0.32 -0.04  0.02 -0.03  0.04\n",
      "  0.01 -0.01  0.07 -0.01  0.09 -0.04 -0.01 -0.01 -1.52 -0.02  0.07 -0.\n",
      " -0.02 -0.04  0.03 -0.07  0.03  0.08 -0.06  0.16 -0.04  0.04 -0.06]\n",
      "\n",
      "i 1\n",
      "train loss nan [nan, nan, nan, 6955.2605687092]\n",
      "validation accuracy 0.8506472945291856 [0.8474295190713023, 0.849824949327429, 0.8514696397309421]\n",
      "[-2.62  0.38  0.07  0.39  2.8   0.28  0.4   0.14  0.02 -0.83  0.09  0.07\n",
      " -0.09  0.01 -1.87 -0.04 -0.16 -0.2  -0.05 -0.12 -0.14 -0.15 -0.16  0.07\n",
      "  0.11  0.38  0.21 -0.03  0.28 -4.76  0.24  0.12 -0.27  0.06  0.73 -0.06\n",
      " -0.5  -0.15 -0.04 -0.04 -0.02  0.04  0.27 -0.19 -0.12 -0.09 -0.28 -0.27\n",
      "  0.16  0.1   0.09  0.11  0.01 -0.09  0.07  0.26 -0.12 -0.65  0.11  0.36\n",
      " -0.05  0.05 -0.05 -0.05  0.04  0.04  0.03 -0.04 -0.13  0.01 -0.09 -0.\n",
      " -0.05 -0.    0.03  0.05 -0.03 -0.04 -0.02 -0.36 -0.04 -0.   -0.01  0.\n",
      "  0.    0.03  0.04 -0.01 -0.01  0.02 -0.   -0.03 -1.67 -0.02  0.07  0.03\n",
      " -0.02 -0.   -0.   -0.03  0.01 -0.02 -0.04  0.14 -0.05  0.01  0.04]\n",
      "\n",
      "i 2\n",
      "train loss nan [nan, nan, nan, 6910.9630637023565]\n",
      "validation accuracy 0.8522135798343367 [0.8486272341993657, 0.8520361157176999, 0.8523910439509734]\n",
      "[-2.45  0.35  0.06  0.49  2.53  0.27  0.36  0.13  0.01 -0.84  0.1   0.07\n",
      " -0.08 -0.01 -1.9  -0.03 -0.18 -0.15 -0.05 -0.09 -0.13 -0.17 -0.12  0.08\n",
      "  0.1   0.38  0.22 -0.04  0.31 -4.84  0.24  0.1  -0.2   0.05  0.74 -0.06\n",
      " -0.54 -0.15 -0.07 -0.01 -0.02  0.02  0.27 -0.15 -0.14 -0.09 -0.31 -0.22\n",
      "  0.18  0.07  0.1   0.09 -0.03 -0.08 -0.03  0.2  -0.08 -0.41  0.08  0.32\n",
      " -0.06  0.03 -0.03 -0.02  0.03  0.04  0.03 -0.03 -0.07  0.04 -0.06 -0.01\n",
      " -0.03  0.01  0.03  0.04 -0.02 -0.    0.   -0.36 -0.02  0.   -0.   -0.\n",
      "  0.02  0.02  0.05  0.02  0.02 -0.01 -0.06 -0.01 -1.7  -0.02  0.06  0.01\n",
      " -0.01 -0.   -0.   -0.03  0.   -0.   -0.    0.12 -0.03  0.02  0.02]\n",
      "\n",
      "i 3\n",
      "train loss nan [10284.017466888097, nan, 6823.1735466816845, 6902.15231845657]\n",
      "validation accuracy 0.8523978309665798 [0.8494564215957172, 0.8526810392481956, 0.8521146226849641]\n",
      "[-2.39  0.35  0.07  0.42  2.4   0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.04 -0.14 -0.16 -0.05 -0.1  -0.12 -0.2  -0.13  0.07\n",
      "  0.09  0.39  0.23 -0.05  0.32 -4.85  0.24  0.1  -0.21  0.05  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.   -0.02  0.02  0.25 -0.18 -0.14 -0.07 -0.25 -0.33\n",
      "  0.16  0.08  0.09  0.11 -0.03 -0.09 -0.06  0.18 -0.08 -0.32  0.08  0.27\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.04 -0.02 -0.08  0.04 -0.08 -0.\n",
      " -0.02  0.03  0.03  0.04 -0.03 -0.    0.01 -0.36 -0.02  0.01  0.   -0.01\n",
      "  0.01  0.02  0.05  0.02  0.03 -0.01 -0.05 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.14 -0.04  0.02  0.01]\n",
      "\n",
      "i 4\n",
      "train loss 7699.114708664294 [10282.888807354417, 6790.660608596267, 6821.883886506663, 6901.025532199827]\n",
      "validation accuracy 0.8519371415901769 [0.8495485535286452, 0.8524046434494117, 0.8514696397309421]\n",
      "[-2.37  0.35  0.07  0.41  2.35  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.11 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.05  0.76 -0.07\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.26 -0.28\n",
      "  0.16  0.08  0.09  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.28  0.08  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.05 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.    0.01 -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 5\n",
      "train loss 7698.894150684126 [10282.555425749351, 6790.4651862466935, 6821.743002311672, 6900.812988428784]\n",
      "validation accuracy 0.85202928201218 [0.8493642896627893, 0.8524046434494117, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.1  -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.3\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.08 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02  0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.01 -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 6\n",
      "train loss 7698.866180404256 [10282.51576501083, 6790.438432261537, 6821.721327509223, 6900.789196835435]\n",
      "validation accuracy 0.8520292905012552 [0.8491800257969334, 0.8522203795835558, 0.8518382014189546]\n",
      "[-2.37  0.35  0.07  0.4   2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.29  0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.01 -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 7\n",
      "train loss 7698.862825873462 [10282.511391844018, 6790.435826027955, 6821.717383488502, 6900.786702133369]\n",
      "validation accuracy 0.8518450139017866 [0.8493642896627893, 0.8521282476506279, 0.8515617801529453]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.29  0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 8\n",
      "train loss 7698.862231909145 [10282.510742366121, 6790.435221839573, 6821.716893838509, 6900.7860695923755]\n",
      "validation accuracy 0.8518450139017866 [0.8492721577298613, 0.8521282476506279, 0.8515617801529453]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 9\n",
      "train loss 7698.862156934462 [10282.510606814718, 6790.43517852562, 6821.716834068153, 6900.78600832936]\n",
      "validation accuracy 0.8519371500792521 [0.8492721577298613, 0.8522203795835558, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 7698.8621476478165 [10282.510594691603, 6790.435170099066, 6821.716823934049, 6900.786001866547]\n",
      "validation accuracy 0.8519371500792521 [0.8492721577298613, 0.8522203795835558, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 11\n",
      "train loss 7698.862146126678 [10282.510593197734, 6790.435168620346, 6821.716822267511, 6900.786000421122]\n",
      "validation accuracy 0.8519371500792521 [0.8492721577298613, 0.8522203795835558, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 12\n",
      "train loss 7698.862145892964 [10282.51059290401, 6790.435168422167, 6821.716822055136, 6900.786000190543]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 13\n",
      "train loss 7698.862145861475 [10282.510592859944, 6790.435168390024, 6821.7168220330095, 6900.786000162922]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 14\n",
      "train loss 7698.8621458578755 [10282.510592854687, 6790.43516838682, 6821.716822030216, 6900.78600015978]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 15\n",
      "train loss 7698.862145857332 [10282.51059285401, 6790.43516838637, 6821.716822029721, 6900.786000159227]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 16\n",
      "train loss 7698.862145857238 [10282.510592853843, 6790.435168386301, 6821.716822029659, 6900.786000159147]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 17\n",
      "train loss 7698.862145857246 [10282.51059285389, 6790.4351683863115, 6821.716822029649, 6900.7860001591325]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 18\n",
      "train loss 7698.862145857271 [10282.510592853869, 6790.435168386449, 6821.716822029647, 6900.786000159116]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 19\n",
      "train loss 7698.862145857267 [10282.51059285382, 6790.435168386465, 6821.716822029648, 6900.786000159138]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 7698.862145857265 [10282.510592853887, 6790.435168386377, 6821.716822029647, 6900.786000159152]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 21\n",
      "train loss 7698.862145857234 [10282.510592853852, 6790.435168386293, 6821.716822029646, 6900.786000159149]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 22\n",
      "train loss 7698.862145857245 [10282.510592853858, 6790.435168386339, 6821.716822029646, 6900.786000159142]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 23\n",
      "train loss 7698.862145857255 [10282.510592853889, 6790.435168386328, 6821.716822029647, 6900.786000159154]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 24\n",
      "train loss 7698.862145857237 [10282.510592853847, 6790.435168386311, 6821.716822029648, 6900.786000159143]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 25\n",
      "train loss 7698.862145857263 [10282.510592853854, 6790.435168386401, 6821.716822029647, 6900.7860001591525]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 26\n",
      "train loss 7698.862145886351 [10282.51059285382, 6790.435168386448, 6821.716822029647, 6900.786000275487]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 27\n",
      "train loss 7700.15505253103 [10282.767346888977, 6793.849515088559, 6821.796689818776, 6902.206658327812]\n",
      "validation accuracy 0.8513843245253836 [0.8490878938640054, 0.851851851851844, 0.8509167971989233]\n",
      "[-2.36  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.08\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.78 -0.08\n",
      " -0.55 -0.14 -0.1  -0.01 -0.02  0.02  0.26 -0.17 -0.14 -0.07 -0.26 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.09 -0.06  0.17 -0.09 -0.3   0.08  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.04 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.05 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.01 -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 28\n",
      "train loss 7699.287411744566 [10282.978590908606, 6791.121988806979, 6821.753897596696, 6901.295169665986]\n",
      "validation accuracy 0.8520292862567176 [0.8492721577298613, 0.8523125115164838, 0.8517460609969515]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.16  0.08  0.08  0.11 -0.03 -0.08 -0.07  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 29\n",
      "train loss 7698.923678173924 [10282.669743837054, 6790.468711992091, 6821.717213399066, 6900.839043467481]\n",
      "validation accuracy 0.8518910841127881 [0.8494564215957172, 0.8521282476506279, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 7698.873332434666 [10282.534683053611, 6790.441285974624, 6821.730392668929, 6900.786968041499]\n",
      "validation accuracy 0.851706811757857 [0.8494564215957172, 0.851943983784772, 0.8514696397309421]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 31\n",
      "train loss 7698.864407381008 [10282.514247374147, 6790.437095202043, 6821.71997814284, 6900.786308805002]\n",
      "validation accuracy 0.8518450139017866 [0.8493642896627893, 0.8521282476506279, 0.8515617801529453]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 32\n",
      "train loss 7698.862383025038 [10282.510649063763, 6790.435333162106, 6821.717263656723, 6900.786286217562]\n",
      "validation accuracy 0.8519832160457161 [0.8493642896627893, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 33\n",
      "train loss 7698.862184776835 [10282.510656694925, 6790.435191326255, 6821.716842522215, 6900.786048563947]\n",
      "validation accuracy 0.8519371458347145 [0.8492721577298613, 0.8523125115164838, 0.8515617801529453]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 34\n",
      "train loss 7698.862166693001 [10282.510644579972, 6790.4351734848715, 6821.716840432984, 6900.786008274174]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 35\n",
      "train loss 7700.5150895627785 [10283.78275657356, 6794.380735495869, 6822.56289222195, 6901.333973959732]\n",
      "validation accuracy 0.851384341503534 [0.8488114980652216, 0.8514833241201322, 0.8512853588869359]\n",
      "[-2.36  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.55 -0.14 -0.1  -0.01 -0.02  0.02  0.26 -0.17 -0.14 -0.07 -0.26 -0.29\n",
      "  0.16  0.08  0.08  0.11 -0.03 -0.09 -0.07  0.18 -0.09 -0.3   0.08  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 36\n",
      "train loss 7698.989498238655 [10282.511095073372, 6790.574353276377, 6822.082740921367, 6900.789803683503]\n",
      "validation accuracy 0.8515686181030027 [0.8490878938640054, 0.8515754560530602, 0.8515617801529453]\n",
      "[-2.37  0.35  0.07  0.4   2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.29  0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 37\n",
      "train loss 7698.925468729419 [10282.54257318216, 6790.464613236491, 6821.884943133702, 6900.809745365321]\n",
      "validation accuracy 0.8520753522231816 [0.8490878938640054, 0.8524046434494117, 0.8517460609969515]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 38\n",
      "train loss 7698.880722784594 [10282.522267964647, 6790.456822739607, 6821.743759218853, 6900.800041215267]\n",
      "validation accuracy 0.8517528819688587 [0.8492721577298613, 0.851943983784772, 0.8515617801529453]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 39\n",
      "train loss 7699.54724277157 [10283.363447761283, 6790.661320845124, 6821.722858103774, 6902.4413443761005]\n",
      "validation accuracy 0.851845009657249 [0.8495485535286452, 0.8522203795835558, 0.8514696397309421]\n",
      "[-2.37  0.35  0.07  0.4   2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.29  0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 7698.954713577719 [10282.698735764643, 6790.515101992634, 6821.717932885746, 6900.887083667853]\n",
      "validation accuracy 0.8518450139017866 [0.8490878938640054, 0.8521282476506279, 0.8515617801529453]\n",
      "[-2.37  0.35  0.07  0.4   2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 41\n",
      "train loss 7699.124425336464 [10283.319500023184, 6790.635333442023, 6821.750996237356, 6900.791871643294]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.08  0.4   2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.05  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.   -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.29  0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 42\n",
      "train loss 7698.950271317612 [10282.515068384386, 6790.645784681556, 6821.767709720415, 6900.872522484088]\n",
      "validation accuracy 0.8521674884006472 [0.8492721577298613, 0.8524967753823397, 0.8518382014189546]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 43\n",
      "train loss 7699.139592234725 [10282.966979835375, 6790.920941711443, 6821.725231361072, 6900.945216031006]\n",
      "validation accuracy 0.8518450181463242 [0.8493642896627893, 0.8520361157176999, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.4   2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.05  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.   -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.29  0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 44\n",
      "train loss 7699.357086332213 [10282.510858948071, 6790.804759267613, 6823.194128046834, 6900.918599066333]\n",
      "validation accuracy 0.8519832160457161 [0.8492721577298613, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 45\n",
      "train loss 7699.391522465909 [10283.100740005708, 6791.086490525187, 6822.101423612735, 6901.277435720006]\n",
      "validation accuracy 0.851568613858465 [0.8491800257969334, 0.8516675879859881, 0.8514696397309421]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.16  0.08  0.08  0.11 -0.03 -0.08 -0.07  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 46\n",
      "train loss 7699.336080695331 [10283.437594538098, 6790.435243398093, 6822.200543093631, 6901.2709417515]\n",
      "validation accuracy 0.8519832160457161 [0.8491800257969334, 0.8523125115164838, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.16  0.08  0.08  0.11 -0.03 -0.08 -0.07  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 47\n",
      "train loss 7699.073485085295 [10282.673350665955, 6791.056630171166, 6821.776609441232, 6900.787350062828]\n",
      "validation accuracy 0.8519371500792521 [0.8491800257969334, 0.8522203795835558, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.41  2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.77 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.3   0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 48\n",
      "train loss 7699.073464011496 [10282.720467899297, 6790.498090356474, 6821.774938185783, 6901.300359604428]\n",
      "validation accuracy 0.8518910841127881 [0.8491800257969334, 0.8521282476506279, 0.8516539205749484]\n",
      "[-2.37  0.35  0.07  0.4   2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.04  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.01 -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.29  0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n",
      "i 49\n",
      "train loss 7699.466600492954 [10283.442292920205, 6790.948110065963, 6822.2635412268255, 6901.212457758826]\n",
      "validation accuracy 0.8520292862567176 [0.8491800257969334, 0.8523125115164838, 0.8517460609969515]\n",
      "[-2.37  0.35  0.08  0.4   2.38  0.26  0.37  0.12  0.01 -0.84  0.1   0.07\n",
      " -0.07 -0.02 -1.9  -0.03 -0.15 -0.16 -0.05 -0.1  -0.12 -0.19 -0.14  0.08\n",
      "  0.09  0.38  0.23 -0.05  0.31 -4.86  0.24  0.1  -0.23  0.06  0.76 -0.08\n",
      " -0.54 -0.14 -0.09 -0.   -0.02  0.02  0.25 -0.17 -0.14 -0.07 -0.25 -0.29\n",
      "  0.17  0.08  0.08  0.11 -0.03 -0.08 -0.08  0.18 -0.09 -0.29  0.09  0.26\n",
      " -0.05  0.03 -0.03 -0.03  0.03  0.04  0.03 -0.02 -0.08  0.03 -0.07 -0.\n",
      " -0.02  0.03  0.02  0.04 -0.02 -0.    0.01 -0.36 -0.02  0.    0.   -0.01\n",
      "  0.01  0.02  0.05  0.01  0.03 -0.01 -0.04 -0.02 -1.7  -0.02  0.05  0.01\n",
      "  0.01 -0.01  0.   -0.04  0.01 -0.01 -0.    0.13 -0.04  0.02  0.01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "G.model = LogisticRegression()\n",
    "G.model.setdata(G.X_train, G.y_train)\n",
    "num_iter = 50\n",
    "for i in range(num_iter):\n",
    "    print('i', i)\n",
    "    G.model.step(200, True)\n",
    "#     joblib.dump(G.model, '1/'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/ipykernel_launcher.py:68: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(X, w):\n",
    "    y = sigmoid(X @ w)\n",
    "    print(y[:100])\n",
    "    y = np.rint(y).astype(np.int8)\n",
    "    return y\n",
    "\n",
    "G.y_test = test(G.X_test, G.model.w[0])\n",
    "df_pred = pd.DataFrame({\n",
    "    'id': np.arange(1, len(G.X_test)+1),\n",
    "    'label': G.y_test\n",
    "})\n",
    "df_pred.to_csv('submission.csv', index=False)\n",
    "df_pred['label'].values[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.74  0.79  0.09  0.89  2.53  0.05  0.4   0.8   0.14 -1.48  0.38  0.59\n",
      " -0.05  0.03 -4.02  0.88 -0.47 -0.38 -0.05 -1.04 -0.75 -0.89 -0.67  0.76\n",
      "  0.77  1.39  2.5   0.27  1.7  -8.84  2.32  0.62 -1.24  2.07  1.1  -1.18\n",
      " -1.44 -1.35 -0.7   0.17 -0.98  0.19  0.96 -0.69 -0.48 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.6  -0.77 -0.14 -0.98 -1.15 -0.35  0.66\n",
      " -0.92 -0.23 -0.55 -0.72 -0.32  1.4   0.58 -0.52 -1.81  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.78  0.69 -0.76  0.01  0.15 -0.39 -1.13  0.22  0.29 -0.17\n",
      "  0.22  0.98  0.97  0.27  0.56 -0.27 -0.32 -0.5  -3.54 -0.56  0.61  0.33\n",
      "  0.26 -0.22  0.08 -0.82  0.33 -0.17 -0.25  0.44 -0.86  0.9   0.03 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n"
     ]
    }
   ],
   "source": [
    "yyy = joblib.load('1/49.pkl')\n",
    "print(yyy.w[0])\n",
    "import pickle\n",
    "pickle.dump(yyy.w[0], open('log/1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
