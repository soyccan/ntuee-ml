{
 "cells": [
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import torch.nn\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import sys\n",
    "import math\n",
    "import torch  \n",
    "import torch.nn as nn\n",
    "import time\n",
    "class UNet_down_block(torch.nn.Module):\n",
    "    def __init__(self, input_channel, output_channel, down_size):\n",
    "        super(UNet_down_block, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(input_channel, output_channel, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.max_pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.down_size = down_size\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.down_size:\n",
    "            x = self.max_pool(x)\n",
    "        x = self.elu(self.bn1(self.conv1(x)))\n",
    "        x = self.elu(self.bn2(self.conv2(x)))\n",
    "        #x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "class UNet_up_block(torch.nn.Module):\n",
    "    def __init__(self, prev_channel, input_channel, output_channel):\n",
    "        super(UNet_up_block, self).__init__()\n",
    "        #self.up_sampling = torch.nn.Upsample(scale_factor=2, mode='bilinear',align_corners=False)\n",
    "        self.up_sampling = torch.nn.ConvTranspose2d(input_channel,input_channel, 2,stride = 2)\n",
    "        self.conv1 = torch.nn.Conv2d(prev_channel + input_channel, output_channel, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "    def forward(self, prev_feature_map, x):\n",
    "        x = self.up_sampling(x)\n",
    "        x = torch.cat((x, prev_feature_map), dim=1)\n",
    "        x = self.elu(self.bn1(self.conv1(x)))\n",
    "        x = self.elu(self.bn2(self.conv2(x)))\n",
    "        #x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.down_block1 = UNet_down_block(1, 8, False)\n",
    "        self.down_block2 = UNet_down_block(8, 16, True)\n",
    "        self.down_block3 = UNet_down_block(16, 32, True)\n",
    "        self.down_block4 = UNet_down_block(32, 64, True)\n",
    "        self.down_block5 = UNet_down_block(64, 128, True)\n",
    "\n",
    "        self.mid_conv1 = torch.nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(128)\n",
    "        self.mid_conv2 = torch.nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(128)\n",
    "        self.mid_conv3 = torch.nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(128)\n",
    "\n",
    "        self.up_block1 = UNet_up_block(64, 128, 64)\n",
    "        self.up_block2 = UNet_up_block(32, 64, 32)\n",
    "        self.up_block3 = UNet_up_block(16, 32, 16)\n",
    "        self.up_block4 = UNet_up_block(8, 16, 8)\n",
    "\n",
    "\n",
    "        self.last_conv1 = torch.nn.Conv2d(8, 8, 3, padding=1)\n",
    "        self.last_bn = torch.nn.BatchNorm2d(8)\n",
    "        self.last_conv2 = torch.nn.Conv2d(8, 4, 1, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.down_block1(x)\n",
    "        self.x2 = self.down_block2(self.x1)\n",
    "        self.x3 = self.down_block3(self.x2)\n",
    "        self.x4 = self.down_block4(self.x3)\n",
    "        self.x5 = self.down_block5(self.x4)\n",
    "        self.x5 = self.elu(self.bn1(self.mid_conv1(self.x5)))\n",
    "        self.x5 = self.elu(self.bn2(self.mid_conv2(self.x5)))\n",
    "        #self.x5 = self.relu(self.bn3(self.mid_conv3(self.x5)))\n",
    "        x = self.up_block1(self.x4, self.x5)\n",
    "        x = self.up_block2(self.x3, x)\n",
    "        x = self.up_block3(self.x2, x)\n",
    "        x = self.up_block4(self.x1, x)\n",
    "        x = self.elu(self.last_bn(self.last_conv1(x)))\n",
    "        x = self.last_conv2(x)\n",
    "        return x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "class SteelDataset(torch.utils.data.Dataset):\n",
    "\n",
    "\tdef __init__(self,folder, pathlist, labeled , Y_dict = None ,transform = None):\n",
    "\n",
    "\t\tself.labeled = labeled\n",
    "\t\tself.X_path = pathlist\n",
    "\t\tself.folder = folder\n",
    "\t\tif self.labeled:\n",
    "\t\t\tself.Y_dict = Y_dict\n",
    "\t\t#self.X_test_path = get_data_path(test_folder)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.X_path)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tpath = self.X_path[idx]\n",
    "\t\ttry:\n",
    "\t\t\tX = get_img(self.folder + '/' + path)\n",
    "\t\t\timg = torch.FloatTensor(X).view(1,256,1600)\n",
    "\t\texcept:\n",
    "\t\t\tprint(self.X_path)\n",
    "\t\t\tprint(idx)\n",
    "\t\t\tprint(self.X_path[idx])\n",
    "\t\t\tprint(path)\n",
    "\n",
    "\n",
    "\t\tif self.labeled:\n",
    "\t\t\tlabels = (np.zeros([4,256,1600]))\n",
    "\t\t\tif path in self.Y_dict:\n",
    "\t\t\t\tfor classID in range(4):\n",
    "\t\t\t\t\tlabels[classID,:,:] = rle2mask((self.Y_dict[path])[classID])\n",
    "\t\t\tlabel = torch.FloatTensor(labels).view(4,256,1600)\n",
    "\t\t\treturn tuple([img , label])\n",
    "\t\telse:\n",
    "\t\t\treturn tuple([img , path])\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    " \n",
    "def rle2mask(mask_rle, shape=(1600,256)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width,height) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "def add_weight_decay(net, l2_value, skip_list=()):\n",
    "\tdecay, no_decay = [], []\n",
    "\tfor name, param in net.named_parameters():\n",
    "\t\tif not param.requires_grad: continue # frozen weights\t\t            \n",
    "\t\tif len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list: no_decay.append(param)\n",
    "\t\telse: decay.append(param)\n",
    "\treturn [{'params': no_decay, 'weight_decay': 0.}, {'params': decay, 'weight_decay': l2_value}]\n",
    "\n",
    "def dice_channel_torch(probability, truth, threshold):\n",
    "\tbatch_size = truth.shape[0]\n",
    "\tchannel_num = truth.shape[1]\n",
    "\tmean_dice_channel = 0.\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i in range(batch_size):\n",
    "\t\t\tfor j in range(channel_num):\n",
    "\t\t\t\tchannel_dice = dice_single_channel(probability[i, j,:,:], truth[i, j, :, :], threshold[j])\n",
    "\t\t\t\tmean_dice_channel += channel_dice/(batch_size * channel_num)\n",
    "\treturn mean_dice_channel\n",
    "\n",
    "\n",
    "def dice_single_channel(probability, truth, threshold, eps = 1E-9):\n",
    "\tp = (probability.view(-1) > threshold).float()\n",
    "\tt = (truth.view(-1) > 0.5).float()\n",
    "\tdice = (2.0 * (p * t).sum() + eps)/ (p.sum() + t.sum() + eps)\n",
    "\treturn dice\n",
    "\n",
    "def run_length_decode(rle, height=256, width=1600, fill_value=1):\n",
    "\tmask = np.zeros((height,width), np.float32)\n",
    "\tif rle != '':\n",
    "\t\tmask=mask.reshape(-1)\n",
    "\t\tr = [int(r) for r in rle.split(' ')]\n",
    "\t\tr = np.array(r).reshape(-1, 2)\n",
    "\t\tfor start,length in r:\n",
    "\t\t\tstart = start-1  #???? 0 or 1 index ???\n",
    "\t\t\tmask[start:(start + length)] = fill_value\n",
    "\t\tmask=mask.reshape(width, height).T\n",
    "\treturn mask\n",
    "\n",
    "def run_length_encode(mask):\n",
    "#possible bug for here\n",
    "\tm = mask.T.flatten()\n",
    "\tif m.sum()==0:\n",
    "\t\trle=''\n",
    "\telse:\n",
    "\t\tm   = np.concatenate([[0], m, [0]])\n",
    "\t\trun = np.where(m[1:] != m[:-1])[0] + 1\n",
    "\t\trun[1::2] -= run[::2]\n",
    "\t\trle = ' '.join(str(r) for r in run)\n",
    "\treturn rle\n",
    "\n",
    "\n",
    "def dice_loss( y_pred,y_true):\n",
    "\tweight = [1,1,1,1]\n",
    "\tsmooth = 1e-9\n",
    "\ty_pred = sigmoid(y_pred)\n",
    "\ty_true_f = y_true.view(-1,4,256,1600)\n",
    "\ty_pred_f = y_pred.view(-1,4,256,1600)\n",
    "\tscore = 0\n",
    "\tbatch_size = y_true_f.shape[0]\n",
    "\tchannel_num = y_true_f.shape[1]\n",
    "\tfor i in range(batch_size):\n",
    "\t\tfor j in range(channel_num):\n",
    "\t\t\tintersection = y_true_f[i,j,:,:] * y_pred_f[i,j,:,:] \n",
    "\t\t\tscore += weight[j] * ( (2. * intersection.sum() + smooth) / (y_true_f[i,j,:,:].sum() + y_pred_f[i,j,:,:].sum() + smooth) ) \n",
    "\tscore /= (batch_size )\n",
    "\treturn - score\n",
    "\n",
    "def bce_dice_loss( y_pred,y_true):\n",
    "\treturn weighted_bceloss(y_pred,y_true) + dice_loss(y_pred,y_true)\n",
    "\n",
    "def weighted_bceloss(y_pred,y_true):\n",
    "\tweight = [1,1,1,1]\n",
    "\tloss = 0\n",
    "    \n",
    "\tfor c in range(4):\n",
    "\t\tloss += bceloss(y_pred[:,c,:,:] ,y_true[:,c,:,:]) * weight[c] \n",
    "\treturn loss "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "#import pyvips\n",
    "from PIL import Image\n",
    "#from utils import *\n",
    "#from Unet.py import *\n",
    "def get_data_path(folder):\n",
    "\tX_path = []\n",
    "\t#print(os.listdir(folder))\n",
    "\tfor filename in (os.listdir(folder)):\n",
    "\t\t#print(filename)\n",
    "\t\tX_path.append(filename)\n",
    "\n",
    "\tX_path = np.array(X_path)\n",
    "\treturn X_path\n",
    "\n",
    "def get_label(path):\n",
    "\tdf = pd.read_csv(path)\n",
    "\tYdict = {}\n",
    "\tfor image_id in df.ImageId.unique():\n",
    "\t\trle = [\n",
    "\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 1) , 'EncodedPixels'].values,\n",
    "\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 2) , 'EncodedPixels'].values,\n",
    "\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 3) , 'EncodedPixels'].values,\n",
    "\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 4) , 'EncodedPixels'].values\n",
    "\t\t]\n",
    "\t\tfor classID in range(4):\n",
    "\t\t\tif len(rle[classID]) == 0:\n",
    "\t\t\t\trle[classID] = ''\n",
    "\t\t\telse:\n",
    "\t\t\t\trle[classID] = rle[classID][0]\n",
    "\n",
    "\t\t#print(y[0])\n",
    "\t\t#print(y[1])\n",
    "\t\t#print(y[2])\n",
    "\t\tYdict[image_id ] =  rle\n",
    "\tdel df\n",
    "\treturn Ydict \n",
    "\n",
    "\n",
    "def get_img(path):\n",
    "\twith Image.open(path) as f:\n",
    "\t\timg = np.array(list(f.getdata()))\n",
    "\tf.close()\n",
    "\t#print('img shape',len(img),img[:,1])\n",
    "\treturn img[:,1].reshape(256,1600)\n",
    "\n",
    "\n",
    "def valid_test(epoch):\n",
    "\tmodel.eval()\n",
    "\tbatch_size = 10\n",
    "\tTotaldice = 0\n",
    "\tTotalloss = 0\n",
    "\tfor i , (batch_x,batch_y) in enumerate(validloader):\n",
    "\t\tbatch_x = batch_x.cuda() \n",
    "\t\tbatch_y = batch_y.cuda()\n",
    "\t\tpV =  model(batch_x)\n",
    "\t\tloss = weighted_bceloss(pV,batch_y).item()\n",
    "\t\t#loss = bce_dice_loss(pV,batch_y).item() \n",
    "\t\tdice = dice_channel_torch( sigmoid(pV) , batch_y , [0.5,0.5,0.5,0.5] )\n",
    "\t\tTotalloss += loss * len(batch_x)\n",
    "\t\tTotaldice += dice * len(batch_x)\n",
    "\tmeandice = Totaldice / V\n",
    "\tmeanloss = Totalloss / V\n",
    "\t#print(pV)\n",
    "\tprint('epoch:{}   Valid: dice {:.3f} loss: {:.3f}'.format(epoch, meandice,meanloss )) #time.time()-start_time  \n",
    "\tmodel.train()\n",
    "\treturn meanloss"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "bceloss = nn.BCEWithLogitsLoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "train_folder = \"../input/severstal-steel-defect-detection/train_images\"\n",
    "label_path = \"../input/severstal-steel-defect-detection/train.csv\"\n",
    "\n",
    "X_train_path = get_data_path(train_folder)\n",
    "Y_train_dict = get_label(label_path)\n",
    "\n",
    "validDataset = SteelDataset(train_folder,X_train_path,labeled=1,Y_dict = Y_train_dict)\n",
    "\n",
    "V = len(X_train_path)\n",
    "validloader = torch.utils.data.DataLoader(validDataset , batch_size = 4, shuffle=False,num_workers=4)\n",
    "model = torch.load(\"../input/model/model2.3.pth\")\n",
    "valid_test(0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "trusted": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "def Train(model):\n",
    "\tepochs = 3\n",
    "\tbest = 100\n",
    "\tdecay = 1e-4\n",
    "\tLR = 0.001\n",
    "\t#optim = torch.optim.Adam( add_weight_decay(model,decay) , lr= LR)\n",
    "\toptim = torch.optim.Adam( model.parameters(), lr= LR)\n",
    "\tprint('train-------------lr:',LR ,'decay:',decay )\n",
    "\tmodel.cuda()\n",
    "\tfor epoch in range(int(epochs)):\n",
    "\t\tmodel.train()\n",
    "\t\tfor i , (batch_x , batch_y )in enumerate(trainloader):\n",
    "\n",
    "\t\t\tbatch_x = batch_x.cuda()\n",
    "\t\t\tbatch_y = batch_y.cuda()\n",
    "\t\t\t\n",
    "\t\t\toptim.zero_grad()\n",
    "\t\t\ty_hat = model(batch_x)\n",
    "\t\t\tloss = weighted_bceloss(y_hat,batch_y)\n",
    "            #loss = bce_dice_loss(y_hat,batch_y)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptim.step()\n",
    "\n",
    "\t\t\tif i % 100 == 99:\n",
    "\t\t\t\tloss = valid_test(epoch)\n",
    "\t\t\t\tif loss < best:\n",
    "\t\t\t\t\tbest = loss\n",
    "\t\t\t\t\tprint(\"saving model with loss: {:.3f}\".format(loss))\n",
    "\t\t\t\t\ttorch.save(model, 'model2.pth')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t#load = 0\n",
    "\tisGPU = torch.cuda.is_available()\n",
    "\tprint ('PyTorch GPU device is available: {}'.format(isGPU))\n",
    "\ttrain_folder = \"../input/severstal-steel-defect-detection/train_images\"\n",
    "\tlabel_path = \"../input/severstal-steel-defect-detection/train.csv\"\n",
    "\t\n",
    "\t#train_folder , test_folder, label_path = sys.argv[1:]\n",
    "\t\n",
    "\tX_train_path = get_data_path(train_folder)\n",
    "\tY_train_dict = get_label(label_path)\n",
    "\t\n",
    "        \n",
    "\t#print(X_train_path)\n",
    "\t#print(Y_train_dict)\n",
    "    \n",
    "\tV = 100\n",
    "\tX_valid_path = X_train_path[:V]\n",
    "\tX_train_path = X_train_path[V:]\n",
    "\n",
    "\ttrainDataset = SteelDataset(train_folder,X_train_path,labeled=1,Y_dict = Y_train_dict)\n",
    "\tvalidDataset = SteelDataset(train_folder,X_valid_path,labeled=1,Y_dict = Y_train_dict)\n",
    "\n",
    "\ttrainloader = torch.utils.data.DataLoader(trainDataset , batch_size = 4, shuffle=True,num_workers=4)\n",
    "\tvalidloader = torch.utils.data.DataLoader(validDataset , batch_size = 4, shuffle=False,num_workers=4)\n",
    "\n",
    "\t#model = UNet()\n",
    "\tmodel = torch.load(\"../input/model/model2.3.pth\")\n",
    "\tTrain(model)\n",
    "\t#Test(model)\n"
   ]
  },
  {
   "metadata": {
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "trusted": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "def Train(model):\n",
    "\tepochs = 3\n",
    "\tbest = 100\n",
    "\tdecay = 1e-4\n",
    "\tLR = 0.001\n",
    "\t#optim = torch.optim.Adam( add_weight_decay(model,decay) , lr= LR)\n",
    "\toptim = torch.optim.Adam( model.parameters(), lr= LR)\n",
    "\tprint('train-------------lr:',LR ,'decay:',decay )\n",
    "\tmodel.cuda()\n",
    "\tfor epoch in range(int(epochs)):\n",
    "\t\tmodel.train()\n",
    "\t\tfor i , (batch_x , batch_y )in enumerate(trainloader):\n",
    "\n",
    "\t\t\tbatch_x = batch_x.cuda()\n",
    "\t\t\tbatch_y = batch_y.cuda()\n",
    "\t\t\t\n",
    "\t\t\toptim.zero_grad()\n",
    "\t\t\ty_hat = model(batch_x)\n",
    "\t\t\tloss = weighted_bceloss(y_hat,batch_y)\n",
    "            #loss = bce_dice_loss(y_hat,batch_y)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptim.step()\n",
    "\n",
    "\t\t\tif i % 100 == 99:\n",
    "\t\t\t\tloss = valid_test(epoch)\n",
    "\t\t\t\tif loss < best:\n",
    "\t\t\t\t\tbest = loss\n",
    "\t\t\t\t\tprint(\"saving model with loss: {:.3f}\".format(loss))\n",
    "\t\t\t\t\ttorch.save(model, 'model2.pth')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t#load = 0\n",
    "\tisGPU = torch.cuda.is_available()\n",
    "\tprint ('PyTorch GPU device is available: {}'.format(isGPU))\n",
    "\ttrain_folder = \"../input/severstal-steel-defect-detection/train_images\"\n",
    "\tlabel_path = \"../input/severstal-steel-defect-detection/train.csv\"\n",
    "\t\n",
    "\t#train_folder , test_folder, label_path = sys.argv[1:]\n",
    "\t\n",
    "\tX_train_path = get_data_path(train_folder)\n",
    "\tY_train_dict = get_label(label_path)\n",
    "\t\n",
    "        \n",
    "\t#print(X_train_path)\n",
    "\t#print(Y_train_dict)\n",
    "    \n",
    "\tV = 100\n",
    "\tX_valid_path = X_train_path[:V]\n",
    "\tX_train_path = X_train_path[V:]\n",
    "\n",
    "\ttrainDataset = SteelDataset(train_folder,X_train_path,labeled=1,Y_dict = Y_train_dict)\n",
    "\tvalidDataset = SteelDataset(train_folder,X_valid_path,labeled=1,Y_dict = Y_train_dict)\n",
    "\n",
    "\ttrainloader = torch.utils.data.DataLoader(trainDataset , batch_size = 4, shuffle=True,num_workers=4)\n",
    "\tvalidloader = torch.utils.data.DataLoader(validDataset , batch_size = 4, shuffle=False,num_workers=4)\n",
    "\n",
    "\t#model = UNet()\n",
    "\tmodel = torch.load(\"../input/model/model2.3.pth\")\n",
    "\tTrain(model)\n",
    "\t#Test(model)\n"
   ]
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "def Test(model):\n",
    "\tmodel.eval()\n",
    "\t#test_folder = \"../input/severstal-steel-defect-detection/test_images\"\n",
    "\t#X_test_path = get_data_path(test_folder)\n",
    "\t#X_test_path.sort()\n",
    "\tprint(\"X_test size:{}\".format(len(X_test_path)))\n",
    "\tprint(X_test_path)\n",
    "\ttestDataset = SteelDataset(test_folder,X_test_path,labeled=0)\n",
    "\ttestloader = torch.utils.data.DataLoader(testDataset , batch_size = 4, shuffle=False,num_workers=4)\n",
    "\toutpath = 'submission.csv'\n",
    "\tf=open(outpath,\"w\")\n",
    "\tf.write(\"ImageId_ClassId,EncodedPixels\\n\")\n",
    "\tthreshhold = [0.5,0.5,0.5,0.5]\n",
    "\tfor i , (img,path) in enumerate(testloader):\n",
    "\t\tpredlist = sigmoid(model(img.cuda()))\n",
    "\t\t#print(len(predlist))\n",
    "\t\t#print(predlist)\n",
    "\t\tfor n in range(len(predlist)):\n",
    "\t\t\t#print(predlist.shape)\n",
    "\t\t\tpred = predlist[n]\n",
    "\t\t\tfor ClassId in range(0,4):\n",
    "\t\t\t\tp = (pred[ClassId].flatten(1) > threshhold[ClassId]).float()\n",
    "\t\t\t\tencoded_value = mask2rle(p.cpu())\n",
    "\t\t\t\t#if len(encoded_value) > 0:\n",
    "\t\t\t\tf.write(\"{}_{},{}\\n\".format(path[n],ClassId + 1,encoded_value ))\n",
    "\tf.close()\n",
    "\tmodel.train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_folder = \"../input/severstal-steel-defect-detection/test_images\"\n",
    "    X_test_path = get_data_path(test_folder)\n",
    "    testDataset = SteelDataset(test_folder,X_test_path,labeled=0)\n",
    "    testloader = torch.utils.data.DataLoader(testDataset , batch_size = 4, shuffle=False,num_workers=4)\n",
    "\n",
    "    model = torch.load(\"../input/model/model2.3.pth\")\n",
    "    Test(model)"
   ]
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#model = torch.load(\"../input/model/model2.3.pth\")\n",
    "fig, axs = plt.subplots(5, figsize=(12, 12))\n",
    "\n",
    "sample_img = get_img('../input/severstal-steel-defect-detection/train_images/0025bde0c.jpg')\n",
    "#predlist = sigmoid(model(torch.from_numpy(sample_img.astype('float32')).view(-1,1,256,1600).cuda()))\n",
    "\n",
    "label_path = \"../input/severstal-steel-defect-detection/train.csv\"\n",
    "path = \"0025bde0c.jpg\"\n",
    "Y_dict = get_label(label_path)\n",
    "\n",
    "print(Y_dict[path])\n",
    "labels = (np.zeros([4,256,1600]))\n",
    "for classID in range(4):\n",
    "\trle = (Y_dict[path])[classID]\n",
    "\tprint(rle)\n",
    "\tlabels[classID,:,:] = rle2mask( (Y_dict[path])[classID] )\n",
    "    \n",
    "predlist = labels\n",
    "\n",
    "#print(predlist)\n",
    "for n in range(len(predlist)):\n",
    "\tprint(predlist.shape)\n",
    "\tpred = predlist[n]\n",
    "\tfor ClassId in range(0,4):\n",
    "\t\tprint(labels[ClassId].sum())\n",
    "\t\t#p = (pred[ClassId].flatten(1) > 0.5).float()\n",
    "\t\t#img = np.array(p.cpu()).reshape(256,1600)\n",
    "\t\t#encoded_value = mask2rle(p.cpu())\n",
    "\t\t\t\t#if len(encoded_value) > 0:\n",
    "\t\t#img = rle2mask(encoded_value)\n",
    "        #print(img)\n",
    "\t\taxs[ClassId+1].imshow(pred)\n",
    "\t\taxs[ClassId+1].axis('off')\n",
    "axs[0].imshow(sample_img)\n",
    "axs[0].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}