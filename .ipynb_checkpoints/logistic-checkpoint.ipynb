{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    # global variables\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, X, y, b1=0.99, b2=0.999):\n",
    "        self.n = self.d = 0\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "\n",
    "        self.w = [np.zeros(self.d) for _ in range(4)]\n",
    "        self.m = [np.zeros(self.d) for _ in range(4)]\n",
    "        self.v = [0, 0, 0, 0]\n",
    "        self.step_ctr = 0\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        # Copy the object's state from self.__dict__ which contains\n",
    "        # all our instance attributes. Always use the dict.copy()\n",
    "        # method to avoid modifying the original state.\n",
    "        state = self.__dict__.copy()\n",
    "        # Remove the unpicklable entries.\n",
    "        del state['X']\n",
    "        del state['XT']\n",
    "        del state['Xval']\n",
    "        del state['y']\n",
    "        del state['yval']\n",
    "        return state\n",
    "    \n",
    "    def setdata(self, X, y):\n",
    "        self.n, self.d = X.shape\n",
    "\n",
    "        self.X = [X[~mask[i], :] for i in range(4)]\n",
    "        self.XT = [self.X[i].T for i in range(len(self.X))]\n",
    "        self.Xval = [X[mask[i], :] for i in range(4)]\n",
    "        self.y = [y[~mask[i]] for i in range(4)]\n",
    "        self.yval = [y[mask[i]] for i in range(4)]\n",
    "        \n",
    "        # 3-fold cross validation sets, 0 is full\n",
    "        ncv = (self.n + 2) // 3\n",
    "        mask = [np.zeros(self.n, dtype=np.bool_) for _ in range(4)]\n",
    "        for i in range(1, 4):\n",
    "            mask[i][(i-1)*ncv:i*ncv] = True        \n",
    "\n",
    "    def _step(self, i, steps):\n",
    "        for j in range(steps):\n",
    "            fx = sigmoid(self.X[i] @ self.w[i])\n",
    "            grad = self.XT[i] @ (fx - self.y[i])\n",
    "            self.m[i] = self.b1 * self.m[i] + (1 - self.b1) * grad\n",
    "            self.v[i] = self.b2 * self.v[i] + (1 - self.b2) * np.sum(grad ** 2)\n",
    "            self.w[i] = self.w[i] - self.m[i] / (1 - self.b1) / np.sqrt(self.v[i] / (1 - self.b2))\n",
    "        loss = - self.y[i] @ np.log(fx) - (1 - self.y[i]) @ np.log(1 - fx)\n",
    "        return loss\n",
    "    \n",
    "    def step(self, steps=1, log=True):\n",
    "        train_loss = [self._step(i, steps) for i in range(4)]\n",
    "        val_accur = []\n",
    "        for i in range(4):\n",
    "            y_pred = np.rint(sigmoid(self.Xval[i] @ self.w[i])).astype(np.int8)\n",
    "            val_accur.append(np.count_nonzero(y_pred == self.yval[i]) / (len(self.yval[i]) + 1e-10))\n",
    "            \n",
    "        if log:\n",
    "            print('train loss', np.mean(train_loss), train_loss)\n",
    "            print('validation accuracy', np.mean(val_accur[1:]), val_accur)\n",
    "            print(self.w[0])\n",
    "            print()\n",
    "            \n",
    "        self.step_ctr += steps\n",
    "        self.train_loss = train_loss\n",
    "        self.val_accur = val_accur\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.df_train_full = pd.read_csv('X_train', dtype=np.int32)\n",
    "G.df_test_full = pd.read_csv('X_test', dtype=np.int32)\n",
    "G.y_train = np.array(open('Y_train').read().strip('\\n').split('\\n'), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "    c = len(df.columns)\n",
    "    n = len(df)\n",
    "    d = 1 + c + 5\n",
    "\n",
    "    X = np.zeros((n, d))\n",
    "    X[:, 0] = 1  # bias\n",
    "    X[:, 1:1+c] = df.values\n",
    "\n",
    "    # ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']\n",
    "    idx = [1,2,4,5,6]\n",
    "    X[:, 1+c:1+c+5] = X[:, idx] ** 2\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def preprocess_train(df):\n",
    "    df = df.copy()\n",
    "    col_mean = df.mean()\n",
    "    col_std = df.std()\n",
    "\n",
    "    # normalize\n",
    "    normcols = ['age', 'fnlwgt', 'hours_per_week']\n",
    "    normcols += ['capital_gain', 'capital_loss']\n",
    "    df[normcols] = (df[normcols] - df[normcols].mean()) / df[normcols].std()\n",
    "#     scale_down_cols = ['capital_gain', 'capital_loss']\n",
    "#     df[scale_down_cols] = df[scale_down_cols] / df[scale_down_cols].mean()\n",
    "\n",
    "    return extract(df), normcols, col_mean, col_std\n",
    "\n",
    "G.X_train, G.normcols, G.col_mean, G.col_std = preprocess_train(G.df_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('a.csv',G.X_train,fmt='%.2f',delimiter=',')\n",
    "#print(G.X_train[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.model = joblib.load('1/49.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: divide by zero encountered in log\n",
      "/home/soyccan/anaconda3/envs/ml_hw2/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in matmul\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss nan [nan, nan, nan, nan]\n",
      "validation accuracy 0.847394119627802 [0.0, 0.8471531232725185, 0.8477059148700862, 0.8473233207408012]\n",
      "[-2.51  0.83  0.09  0.5  -0.31  0.09  0.23  0.14 -0.65 -0.03  0.2   0.16\n",
      " -1.22 -0.54 -0.2  -0.37 -1.38 -1.32 -0.89 -1.22 -1.76 -2.35 -1.8   0.36\n",
      "  0.23  1.18  3.17  0.13  1.35 -0.71  2.4   0.09 -0.91  0.69  1.11 -1.02\n",
      " -0.87 -1.39 -0.13  0.07 -0.09 -0.26  0.65 -0.98 -0.58 -0.52 -0.38 -0.63\n",
      "  0.19  0.27  0.37  0.09 -0.34 -0.39 -0.32 -0.18 -1.32 -1.58 -0.53  1.42\n",
      " -1.29 -0.17 -0.   -0.91 -0.14  0.3   0.43 -0.55 -0.68  0.34 -0.6  -0.07\n",
      " -0.43  0.37  0.28  0.55 -0.43 -0.09 -0.06 -0.01 -0.03  0.01  0.03 -0.32\n",
      " -0.02  0.22  0.53  0.02  0.33 -0.06 -1.38 -0.25 -0.14 -0.17  0.76  0.04\n",
      " -0.09 -0.54 -0.01 -0.64  0.16 -0.07 -0.1   0.33 -0.49  0.17 -0.14 -0.56\n",
      " -0.06  4.14  0.08 -0.14]\n",
      "\n",
      "i 1\n",
      "train loss nan [nan, nan, nan, nan]\n",
      "validation accuracy 0.8535057783691529 [0.0, 0.8525889073152676, 0.8527731711811235, 0.8551552566110674]\n",
      "[-2.13  0.76  0.08  0.89  0.42 -0.08  0.41  0.22 -0.47 -0.06 -0.17  0.02\n",
      " -0.46 -0.52 -0.48 -0.21 -0.92 -0.88 -0.45 -1.49 -1.31 -1.06 -0.97  0.24\n",
      "  0.33  0.76  1.76 -0.1   1.2  -1.3   1.85  0.18 -0.92  1.45  1.15 -0.86\n",
      " -1.34 -1.07 -0.52  0.02 -0.17 -0.07  0.65 -1.16 -0.86 -0.41 -0.66 -1.13\n",
      "  0.47  0.75  0.29  0.56 -0.15 -0.27 -0.53  0.01 -0.88 -1.35 -0.37  0.98\n",
      " -0.68 -0.27 -0.42 -0.48 -0.28  0.69  0.48 -0.81 -1.21  0.53 -0.96 -0.06\n",
      " -0.61  0.51  0.5   0.54 -0.75 -0.07 -0.08 -0.01 -0.08  0.05  0.08 -0.32\n",
      " -0.01  0.47  0.95  0.08  0.52 -0.13 -0.22 -0.43 -0.29 -0.34  0.49  0.14\n",
      " -0.04 -0.47 -0.02 -0.98  0.19 -0.14 -0.18  0.48 -0.84  0.38 -0.14 -0.42\n",
      " -0.04  1.08  0.08 -0.06]\n",
      "\n",
      "i 2\n",
      "train loss nan [nan, nan, 6677.642953387567, 6744.545260666249]\n",
      "validation accuracy 0.8556863246652496 [0.0, 0.8529574350469794, 0.8559977888336019, 0.8581037501151676]\n",
      "[-2.02  0.85  0.09  0.91  1.99  0.08  0.4   0.28 -0.32 -0.1  -0.04  0.09\n",
      " -0.53 -0.51 -0.73 -0.14 -0.84 -0.76 -0.5  -1.52 -1.15 -1.41 -1.14  0.29\n",
      "  0.34  1.    2.14 -0.1   1.31 -1.8   1.93  0.19 -1.12  1.93  1.1  -1.\n",
      " -1.31 -1.14 -0.48  0.   -0.26 -0.02  0.76 -0.95 -0.71 -0.33 -0.74 -1.49\n",
      "  0.49  0.72  0.3   0.61 -0.15 -0.24 -0.59 -0.08 -0.91 -0.96 -0.3   0.82\n",
      " -0.85 -0.05 -0.38 -0.59 -0.14  0.94  0.51 -0.69 -1.5   0.55 -1.19 -0.\n",
      " -0.59  0.59  0.65  0.6  -0.85 -0.07 -0.04 -0.02 -0.12  0.07  0.13 -0.27\n",
      "  0.08  0.68  0.94  0.16  0.51 -0.19 -0.52 -0.52 -0.44 -0.44  0.47  0.23\n",
      "  0.04 -0.34 -0.02 -0.99  0.21 -0.19 -0.23  0.31 -0.98  0.57 -0.08 -0.46\n",
      "  0.01  0.51  0.04 -0.07]\n",
      "\n",
      "i 3\n",
      "train loss 7502.389177654946 [10020.57977023892, 6629.126236038929, 6661.680879040849, 6698.169825301085]\n",
      "validation accuracy 0.8549185161121408 [0.0, 0.8524046434494117, 0.8556292611018901, 0.8567216437851206]\n",
      "[-2.02  0.79  0.09  0.89  2.33  0.04  0.39  0.35 -0.33 -0.14 -0.06  0.15\n",
      " -0.5  -0.43 -0.96 -0.1  -0.89 -0.79 -0.44 -1.45 -1.12 -1.24 -1.04  0.35\n",
      "  0.39  0.98  2.13 -0.12  1.3  -2.23  1.94  0.22 -1.14  2.13  1.15 -1.06\n",
      " -1.31 -1.24 -0.56  0.01 -0.34  0.02  0.78 -0.87 -0.64 -0.32 -0.76 -1.77\n",
      "  0.52  0.7   0.31  0.66 -0.09 -0.24 -0.64 -0.02 -0.89 -1.04 -0.23  0.81\n",
      " -0.76 -0.1  -0.42 -0.57 -0.18  1.09  0.48 -0.64 -1.67  0.52 -1.32  0.06\n",
      " -0.57  0.55  0.7   0.58 -0.87 -0.07  0.   -0.02 -0.17  0.08  0.16 -0.29\n",
      "  0.12  0.8   0.86  0.18  0.45 -0.25 -0.44 -0.56 -0.59 -0.51  0.51  0.25\n",
      "  0.11 -0.3  -0.01 -0.95  0.21 -0.23 -0.27  0.37 -1.    0.69 -0.05 -0.42\n",
      " -0.01 -0.12  0.05 -0.07]\n",
      "\n",
      "i 4\n",
      "train loss 7498.284074954776 [10015.059693232835, 6627.502769815044, 6658.451839853378, 6692.12199691785]\n",
      "validation accuracy 0.8552256310443092 [0.0, 0.8525889073152676, 0.8560899207665298, 0.8569980650511301]\n",
      "[-2.07  0.79  0.09  0.88  2.59  0.05  0.41  0.37 -0.29 -0.18 -0.06  0.16\n",
      " -0.47 -0.4  -1.15 -0.06 -0.83 -0.73 -0.42 -1.4  -1.12 -1.25 -1.05  0.4\n",
      "  0.4   1.02  2.11 -0.1   1.33 -2.63  1.95  0.26 -1.14  2.17  1.19 -1.08\n",
      " -1.34 -1.25 -0.61  0.04 -0.42  0.05  0.82 -0.84 -0.62 -0.31 -0.75 -2.\n",
      "  0.55  0.7   0.34  0.68 -0.08 -0.24 -0.62 -0.04 -0.91 -1.06 -0.24  0.81\n",
      " -0.79 -0.08 -0.42 -0.58 -0.19  1.17  0.49 -0.62 -1.77  0.52 -1.41  0.12\n",
      " -0.55  0.56  0.7   0.6  -0.86 -0.07  0.03 -0.03 -0.22  0.1   0.17 -0.27\n",
      "  0.13  0.86  0.87  0.18  0.45 -0.29 -0.45 -0.58 -0.73 -0.56  0.51  0.24\n",
      "  0.15 -0.31 -0.01 -0.91  0.22 -0.25 -0.29  0.34 -0.98  0.76 -0.07 -0.42\n",
      " -0.01 -0.14  0.05 -0.08]\n",
      "\n",
      "i 5\n",
      "train loss 7496.988836568963 [10013.049874244021, 6626.608732257457, 6657.400478840578, 6690.896260933793]\n",
      "validation accuracy 0.8553177827850792 [0.0, 0.8521282476506279, 0.8561820526994578, 0.857643048005152]\n",
      "[-2.1   0.79  0.09  0.88  2.51  0.05  0.41  0.39 -0.26 -0.22 -0.02  0.18\n",
      " -0.45 -0.37 -1.33 -0.02 -0.82 -0.72 -0.4  -1.38 -1.09 -1.24 -1.02  0.42\n",
      "  0.42  1.04  2.15 -0.07  1.35 -3.01  1.97  0.28 -1.15  2.16  1.16 -1.08\n",
      " -1.33 -1.25 -0.61  0.05 -0.49  0.07  0.83 -0.82 -0.6  -0.29 -0.73 -2.2\n",
      "  0.57  0.73  0.36  0.71 -0.06 -0.24 -0.64 -0.04 -0.91 -1.05 -0.25  0.79\n",
      " -0.79 -0.1  -0.43 -0.59 -0.2   1.22  0.5  -0.62 -1.83  0.53 -1.48  0.15\n",
      " -0.55  0.57  0.69  0.6  -0.85 -0.08  0.05 -0.03 -0.27  0.11  0.18 -0.26\n",
      "  0.13  0.88  0.89  0.18  0.46 -0.31 -0.44 -0.59 -0.86 -0.59  0.52  0.24\n",
      "  0.16 -0.31 -0.01 -0.91  0.23 -0.26 -0.31  0.35 -0.96  0.79 -0.06 -0.42\n",
      " -0.01 -0.14  0.05 -0.08]\n",
      "\n",
      "i 6\n",
      "train loss 7496.229153773724 [10012.176853645218, 6626.049076925483, 6656.620594701373, 6690.070089822822]\n",
      "validation accuracy 0.855072083482146 [0.0, 0.8520361157176999, 0.8559977888336019, 0.8571823458951363]\n",
      "[-2.15  0.79  0.09  0.88  2.52  0.05  0.4   0.41 -0.25 -0.26 -0.    0.21\n",
      " -0.43 -0.36 -1.5   0.02 -0.8  -0.7  -0.38 -1.36 -1.07 -1.21 -1.    0.44\n",
      "  0.45  1.07  2.17 -0.05  1.37 -3.37  1.99  0.3  -1.15  2.14  1.16 -1.08\n",
      " -1.34 -1.26 -0.61  0.07 -0.56  0.09  0.85 -0.81 -0.59 -0.27 -0.71 -2.37\n",
      "  0.59  0.74  0.38  0.72 -0.04 -0.24 -0.64 -0.05 -0.92 -1.06 -0.26  0.78\n",
      " -0.8  -0.11 -0.44 -0.6  -0.21  1.25  0.5  -0.61 -1.86  0.54 -1.52  0.17\n",
      " -0.54  0.57  0.7   0.61 -0.84 -0.07  0.06 -0.03 -0.32  0.13  0.19 -0.25\n",
      "  0.14  0.89  0.89  0.19  0.47 -0.33 -0.44 -0.59 -0.99 -0.61  0.53  0.25\n",
      "  0.17 -0.3  -0.01 -0.9   0.24 -0.26 -0.32  0.36 -0.95  0.81 -0.05 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 7\n",
      "train loss 7495.652577743373 [10011.509748086984, 6625.65201173214, 6655.963178360958, 6689.48537279341]\n",
      "validation accuracy 0.8551335047707647 [0.0, 0.8522203795835558, 0.8559977888336019, 0.8571823458951363]\n",
      "[-2.19  0.79  0.09  0.88  2.52  0.05  0.4   0.43 -0.23 -0.3   0.02  0.22\n",
      " -0.41 -0.34 -1.65  0.06 -0.78 -0.68 -0.36 -1.34 -1.05 -1.19 -0.98  0.46\n",
      "  0.47  1.09  2.19 -0.03  1.39 -3.73  2.01  0.32 -1.16  2.13  1.15 -1.09\n",
      " -1.35 -1.27 -0.62  0.08 -0.63  0.1   0.86 -0.79 -0.57 -0.26 -0.7  -2.52\n",
      "  0.6   0.76  0.39  0.74 -0.03 -0.24 -0.65 -0.06 -0.92 -1.06 -0.27  0.78\n",
      " -0.81 -0.12 -0.45 -0.61 -0.21  1.28  0.5  -0.6  -1.87  0.54 -1.55  0.18\n",
      " -0.54  0.58  0.7   0.61 -0.83 -0.07  0.07 -0.04 -0.37  0.14  0.2  -0.25\n",
      "  0.14  0.9   0.89  0.19  0.48 -0.34 -0.43 -0.58 -1.12 -0.62  0.53  0.25\n",
      "  0.18 -0.29 -0.   -0.9   0.25 -0.26 -0.32  0.36 -0.94  0.82 -0.05 -0.42\n",
      " -0.01 -0.14  0.05 -0.08]\n",
      "\n",
      "i 8\n",
      "train loss 7495.166245070367 [10010.94226816102, 6625.340416484212, 6655.367131175484, 6689.015164460755]\n",
      "validation accuracy 0.8551335047707647 [0.0, 0.8521282476506279, 0.8560899207665298, 0.8571823458951363]\n",
      "[-2.23  0.79  0.09  0.88  2.52  0.05  0.4   0.45 -0.21 -0.35  0.04  0.24\n",
      " -0.39 -0.32 -1.8   0.1  -0.76 -0.66 -0.34 -1.32 -1.03 -1.17 -0.95  0.48\n",
      "  0.49  1.11  2.22 -0.01  1.42 -4.09  2.04  0.34 -1.16  2.13  1.15 -1.1\n",
      " -1.35 -1.27 -0.62  0.1  -0.69  0.11  0.88 -0.78 -0.56 -0.25 -0.68 -2.65\n",
      "  0.62  0.77  0.4   0.75 -0.01 -0.25 -0.66 -0.07 -0.92 -1.07 -0.28  0.77\n",
      " -0.82 -0.12 -0.45 -0.61 -0.22  1.3   0.51 -0.6  -1.88  0.54 -1.57  0.18\n",
      " -0.53  0.58  0.71  0.62 -0.83 -0.07  0.07 -0.04 -0.42  0.14  0.21 -0.24\n",
      "  0.15  0.9   0.9   0.2   0.48 -0.34 -0.42 -0.58 -1.25 -0.63  0.54  0.26\n",
      "  0.19 -0.29  0.   -0.89  0.25 -0.26 -0.32  0.37 -0.94  0.82 -0.04 -0.42\n",
      " -0.01 -0.14  0.05 -0.08]\n",
      "\n",
      "i 9\n",
      "train loss 7494.750562000186 [10010.450699084984, 6625.091618729084, 6654.8244286063, 6688.635501580375]\n",
      "validation accuracy 0.8551335047707647 [0.0, 0.8521282476506279, 0.8560899207665298, 0.8571823458951363]\n",
      "[-2.27  0.79  0.09  0.88  2.52  0.05  0.4   0.47 -0.19 -0.39  0.05  0.26\n",
      " -0.37 -0.3  -1.94  0.14 -0.73 -0.64 -0.31 -1.3  -1.   -1.15 -0.93  0.5\n",
      "  0.51  1.13  2.24  0.01  1.44 -4.45  2.06  0.36 -1.17  2.12  1.15 -1.1\n",
      " -1.36 -1.28 -0.63  0.11 -0.74  0.13  0.89 -0.76 -0.55 -0.23 -0.67 -2.77\n",
      "  0.63  0.79  0.42  0.77 -0.   -0.26 -0.67 -0.07 -0.93 -1.08 -0.28  0.76\n",
      " -0.82 -0.13 -0.46 -0.62 -0.23  1.31  0.51 -0.59 -1.88  0.55 -1.59  0.19\n",
      " -0.53  0.58  0.71  0.62 -0.82 -0.06  0.08 -0.05 -0.48  0.15  0.21 -0.24\n",
      "  0.15  0.91  0.9   0.2   0.49 -0.34 -0.42 -0.57 -1.37 -0.63  0.54  0.26\n",
      "  0.19 -0.29  0.01 -0.89  0.26 -0.25 -0.32  0.37 -0.93  0.83 -0.04 -0.42\n",
      " -0.01 -0.14  0.05 -0.08]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 10\n",
      "train loss 7494.394894621808 [10010.026886241196, 6624.889347532362, 6654.331244056241, 6688.332100657433]\n",
      "validation accuracy 0.855194928889075 [0.0, 0.8521282476506279, 0.8561820526994578, 0.8572744863171394]\n",
      "[-2.3   0.79  0.09  0.88  2.52  0.05  0.4   0.49 -0.17 -0.44  0.07  0.28\n",
      " -0.35 -0.28 -2.07  0.17 -0.71 -0.62 -0.29 -1.28 -0.98 -1.12 -0.91  0.52\n",
      "  0.53  1.15  2.26  0.03  1.46 -4.8   2.08  0.38 -1.17  2.12  1.15 -1.11\n",
      " -1.37 -1.28 -0.63  0.12 -0.79  0.14  0.9  -0.75 -0.54 -0.22 -0.66 -2.88\n",
      "  0.64  0.8   0.43  0.78  0.01 -0.26 -0.68 -0.08 -0.93 -1.08 -0.29  0.75\n",
      " -0.83 -0.14 -0.47 -0.63 -0.24  1.32  0.52 -0.59 -1.88  0.55 -1.6   0.19\n",
      " -0.52  0.59  0.72  0.62 -0.82 -0.06  0.08 -0.06 -0.53  0.15  0.22 -0.23\n",
      "  0.15  0.91  0.9   0.2   0.49 -0.34 -0.41 -0.57 -1.49 -0.62  0.55  0.27\n",
      "  0.19 -0.28  0.01 -0.88  0.26 -0.25 -0.32  0.37 -0.93  0.83 -0.04 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 11\n",
      "train loss 7494.091568481148 [10009.666496838783, 6624.722771494544, 6653.885822841925, 6688.09118274934]\n",
      "validation accuracy 0.8552256395333844 [0.0, 0.8522203795835558, 0.8561820526994578, 0.8572744863171394]\n",
      "[-2.34  0.79  0.09  0.88  2.52  0.05  0.4   0.5  -0.16 -0.49  0.09  0.3\n",
      " -0.34 -0.26 -2.19  0.21 -0.69 -0.6  -0.27 -1.26 -0.96 -1.1  -0.89  0.54\n",
      "  0.55  1.17  2.28  0.06  1.48 -5.15  2.1   0.4  -1.18  2.12  1.14 -1.11\n",
      " -1.37 -1.29 -0.64  0.13 -0.84  0.15  0.91 -0.74 -0.53 -0.21 -0.65 -2.98\n",
      "  0.65  0.81  0.44  0.79  0.02 -0.27 -0.69 -0.08 -0.93 -1.09 -0.29  0.74\n",
      " -0.84 -0.15 -0.47 -0.64 -0.24  1.33  0.52 -0.58 -1.87  0.55 -1.6   0.19\n",
      " -0.52  0.59  0.72  0.63 -0.82 -0.05  0.09 -0.06 -0.59  0.16  0.22 -0.23\n",
      "  0.16  0.92  0.91  0.21  0.5  -0.33 -0.4  -0.56 -1.61 -0.62  0.55  0.27\n",
      "  0.2  -0.28  0.02 -0.88  0.26 -0.24 -0.31  0.38 -0.92  0.84 -0.03 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 12\n",
      "train loss 7493.834225910943 [10009.365737693888, 6624.58404227165, 6653.487427299139, 6687.899696379096]\n",
      "validation accuracy 0.8551949260593833 [0.0, 0.8522203795835558, 0.8561820526994578, 0.8571823458951363]\n",
      "[-2.37  0.79  0.09  0.88  2.53  0.05  0.4   0.52 -0.14 -0.53  0.11  0.31\n",
      " -0.32 -0.25 -2.31  0.25 -0.67 -0.58 -0.25 -1.24 -0.94 -1.08 -0.87  0.56\n",
      "  0.57  1.19  2.3   0.08  1.5  -5.49  2.12  0.42 -1.19  2.11  1.14 -1.12\n",
      " -1.38 -1.29 -0.65  0.14 -0.87  0.15  0.92 -0.73 -0.52 -0.21 -0.64 -3.06\n",
      "  0.66  0.82  0.45  0.8   0.03 -0.29 -0.69 -0.09 -0.94 -1.09 -0.3   0.74\n",
      " -0.84 -0.15 -0.48 -0.64 -0.25  1.34  0.52 -0.58 -1.87  0.56 -1.61  0.2\n",
      " -0.52  0.59  0.72  0.63 -0.81 -0.05  0.09 -0.07 -0.64  0.16  0.23 -0.23\n",
      "  0.16  0.92  0.91  0.21  0.5  -0.33 -0.4  -0.56 -1.73 -0.62  0.55  0.27\n",
      "  0.2  -0.28  0.02 -0.88  0.27 -0.24 -0.31  0.38 -0.92  0.84 -0.03 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 13\n",
      "train loss 7493.6170606057185 [10009.11935268607, 6624.467340173402, 6653.135215018212, 6687.746334545191]\n",
      "validation accuracy 0.8551335047707647 [0.0, 0.8521282476506279, 0.8560899207665298, 0.8571823458951363]\n",
      "[-2.4   0.79  0.09  0.88  2.53  0.05  0.4   0.54 -0.12 -0.58  0.12  0.33\n",
      " -0.3  -0.23 -2.43  0.28 -0.65 -0.56 -0.23 -1.22 -0.92 -1.06 -0.85  0.58\n",
      "  0.59  1.21  2.32  0.1   1.52 -5.81  2.14  0.44 -1.19  2.11  1.14 -1.13\n",
      " -1.38 -1.3  -0.65  0.15 -0.9   0.16  0.93 -0.72 -0.51 -0.2  -0.64 -3.14\n",
      "  0.66  0.82  0.45  0.8   0.04 -0.3  -0.7  -0.09 -0.94 -1.1  -0.3   0.73\n",
      " -0.85 -0.16 -0.49 -0.65 -0.25  1.34  0.53 -0.58 -1.86  0.56 -1.61  0.2\n",
      " -0.51  0.6   0.73  0.64 -0.81 -0.04  0.09 -0.08 -0.7   0.16  0.23 -0.22\n",
      "  0.17  0.92  0.91  0.22  0.5  -0.33 -0.39 -0.55 -1.84 -0.61  0.56  0.28\n",
      "  0.2  -0.27  0.02 -0.87  0.27 -0.23 -0.31  0.38 -0.91  0.84 -0.03 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 14\n",
      "train loss 7493.434510729585 [10008.920341215708, 6624.36826435971, 6652.8273679130525, 6687.62206942987]\n",
      "validation accuracy 0.8551335047707647 [0.0, 0.8521282476506279, 0.8560899207665298, 0.8571823458951363]\n",
      "[-2.43  0.79  0.09  0.88  2.53  0.05  0.4   0.55 -0.11 -0.63  0.14  0.35\n",
      " -0.29 -0.21 -2.55  0.32 -0.63 -0.54 -0.21 -1.2  -0.91 -1.05 -0.83  0.6\n",
      "  0.61  1.23  2.34  0.11  1.54 -6.11  2.16  0.46 -1.2   2.11  1.14 -1.13\n",
      " -1.39 -1.31 -0.66  0.15 -0.93  0.17  0.93 -0.71 -0.51 -0.19 -0.63 -3.21\n",
      "  0.67  0.83  0.46  0.81  0.04 -0.31 -0.71 -0.09 -0.94 -1.1  -0.3   0.72\n",
      " -0.86 -0.17 -0.49 -0.66 -0.26  1.35  0.53 -0.57 -1.86  0.56 -1.61  0.2\n",
      " -0.51  0.6   0.73  0.64 -0.81 -0.04  0.1  -0.09 -0.75  0.17  0.23 -0.22\n",
      "  0.17  0.93  0.92  0.22  0.51 -0.32 -0.38 -0.55 -1.96 -0.61  0.56  0.28\n",
      "  0.21 -0.27  0.03 -0.87  0.28 -0.23 -0.3   0.39 -0.91  0.85 -0.02 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 15\n",
      "train loss 7499.3046307613085 [10013.754970401544, 6635.726110307174, 6652.560955560101, 6695.176486776414]\n",
      "validation accuracy 0.855287060822003 [0.0, 0.8525889073152676, 0.8559977888336019, 0.8572744863171394]\n",
      "[-2.46  0.79  0.09  0.88  2.53  0.04  0.4   0.57 -0.09 -0.68  0.15  0.36\n",
      " -0.27 -0.2  -2.65  0.36 -0.62 -0.52 -0.2  -1.19 -0.9  -1.03 -0.82  0.62\n",
      "  0.63  1.25  2.36  0.13  1.56 -6.37  2.18  0.48 -1.2   2.11  1.13 -1.14\n",
      " -1.39 -1.31 -0.66  0.16 -0.95  0.17  0.94 -0.71 -0.5  -0.19 -0.62 -3.26\n",
      "  0.67  0.83  0.46  0.81  0.05 -0.33 -0.71 -0.1  -0.95 -1.11 -0.31  0.72\n",
      " -0.86 -0.17 -0.5  -0.66 -0.26  1.35  0.53 -0.57 -1.86  0.57 -1.62  0.21\n",
      " -0.5   0.61  0.73  0.64 -0.81 -0.04  0.1  -0.1  -0.8   0.17  0.24 -0.22\n",
      "  0.17  0.93  0.92  0.22  0.51 -0.32 -0.38 -0.55 -2.07 -0.6   0.57  0.28\n",
      "  0.21 -0.27  0.03 -0.86  0.28 -0.22 -0.3   0.39 -0.91  0.85 -0.02 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n",
      "i 16\n",
      "train loss 7495.044054159709 [10012.244476847294, 6624.61562642259, 6655.809626666958, 6687.50648670199]\n",
      "validation accuracy 0.8552870749704615 [0.0, 0.8520361157176999, 0.8560899207665298, 0.8577351884271551]\n",
      "[-2.48  0.79  0.09  0.88  2.53  0.05  0.4   0.58 -0.08 -0.73  0.17  0.38\n",
      " -0.26 -0.19 -2.74  0.39 -0.6  -0.51 -0.18 -1.17 -0.88 -1.02 -0.8   0.63\n",
      "  0.64  1.26  2.37  0.14  1.57 -6.59  2.19  0.49 -1.2   2.11  1.13 -1.14\n",
      " -1.4  -1.31 -0.66  0.16 -0.96  0.18  0.94 -0.71 -0.5  -0.18 -0.62 -3.3\n",
      "  0.68  0.84  0.47  0.82  0.05 -0.34 -0.72 -0.1  -0.95 -1.11 -0.31  0.71\n",
      " -0.87 -0.18 -0.5  -0.67 -0.27  1.35  0.54 -0.57 -1.85  0.57 -1.62  0.21\n",
      " -0.5   0.61  0.74  0.65 -0.8  -0.03  0.11 -0.11 -0.84  0.18  0.24 -0.21\n",
      "  0.18  0.93  0.93  0.23  0.51 -0.31 -0.37 -0.54 -2.16 -0.6   0.57  0.29\n",
      "  0.22 -0.26  0.03 -0.86  0.28 -0.22 -0.29  0.4  -0.9   0.85 -0.02 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 17\n",
      "train loss 7493.927269641552 [10010.736815273278, 6624.592777914253, 6652.395794200255, 6687.983691178419]\n",
      "validation accuracy 0.8551335047707647 [0.0, 0.8522203795835558, 0.8559977888336019, 0.8571823458951363]\n",
      "[-2.5   0.79  0.09  0.88  2.53  0.05  0.4   0.6  -0.06 -0.77  0.18  0.39\n",
      " -0.25 -0.17 -2.83  0.42 -0.59 -0.5  -0.17 -1.16 -0.87 -1.01 -0.79  0.64\n",
      "  0.65  1.27  2.38  0.15  1.58 -6.79  2.2   0.5  -1.21  2.1   1.13 -1.14\n",
      " -1.4  -1.32 -0.67  0.16 -0.97  0.18  0.94 -0.7  -0.5  -0.18 -0.62 -3.33\n",
      "  0.68  0.84  0.47  0.82  0.05 -0.35 -0.73 -0.11 -0.95 -1.11 -0.31  0.71\n",
      " -0.87 -0.18 -0.51 -0.67 -0.27  1.36  0.54 -0.56 -1.85  0.57 -1.62  0.21\n",
      " -0.5   0.61  0.74  0.65 -0.8  -0.03  0.11 -0.12 -0.88  0.18  0.24 -0.21\n",
      "  0.18  0.94  0.93  0.23  0.52 -0.31 -0.37 -0.54 -2.25 -0.6   0.57  0.29\n",
      "  0.22 -0.26  0.04 -0.86  0.29 -0.22 -0.29  0.4  -0.9   0.86 -0.01 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 18\n",
      "train loss 7497.013484885163 [10014.387678743886, 6628.192865668348, 6657.945874538219, 6687.527520590198]\n",
      "validation accuracy 0.8552256423630761 [0.0, 0.8522203795835558, 0.8560899207665298, 0.8573666267391425]\n",
      "[-2.52  0.79  0.09  0.88  2.53  0.05  0.4   0.61 -0.05 -0.81  0.19  0.4\n",
      " -0.23 -0.16 -2.91  0.44 -0.58 -0.49 -0.16 -1.15 -0.86 -1.   -0.78  0.65\n",
      "  0.66  1.28  2.39  0.16  1.59 -6.96  2.21  0.51 -1.21  2.1   1.13 -1.15\n",
      " -1.4  -1.32 -0.67  0.17 -0.97  0.18  0.95 -0.7  -0.49 -0.18 -0.62 -3.36\n",
      "  0.68  0.84  0.47  0.82  0.06 -0.37 -0.73 -0.11 -0.95 -1.12 -0.32  0.71\n",
      " -0.87 -0.18 -0.51 -0.67 -0.28  1.36  0.54 -0.56 -1.85  0.58 -1.62  0.22\n",
      " -0.5   0.61  0.74  0.65 -0.8  -0.03  0.11 -0.13 -0.91  0.18  0.25 -0.21\n",
      "  0.18  0.94  0.93  0.23  0.52 -0.31 -0.36 -0.54 -2.33 -0.59  0.57  0.29\n",
      "  0.22 -0.26  0.04 -0.86  0.29 -0.21 -0.29  0.4  -0.9   0.86 -0.01 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n",
      "i 19\n",
      "train loss 7496.098660195934 [10013.296933065412, 6630.079990633934, 6651.94575301491, 6689.07196406948]\n",
      "validation accuracy 0.8551642239041491 [0.0, 0.8520361157176999, 0.8559977888336019, 0.8574587671611457]\n",
      "[-2.53  0.79  0.09  0.88  2.53  0.04  0.4   0.62 -0.04 -0.85  0.2   0.41\n",
      " -0.22 -0.15 -2.98  0.47 -0.57 -0.48 -0.15 -1.14 -0.85 -0.99 -0.77  0.66\n",
      "  0.67  1.29  2.4   0.17  1.6  -7.11  2.22  0.52 -1.21  2.1   1.13 -1.15\n",
      " -1.41 -1.32 -0.67  0.17 -0.97  0.18  0.95 -0.7  -0.49 -0.18 -0.62 -3.38\n",
      "  0.69  0.84  0.47  0.82  0.06 -0.38 -0.73 -0.11 -0.95 -1.12 -0.32  0.7\n",
      " -0.88 -0.19 -0.51 -0.68 -0.28  1.36  0.54 -0.56 -1.85  0.58 -1.62  0.22\n",
      " -0.49  0.62  0.74  0.65 -0.79 -0.02  0.11 -0.14 -0.94  0.19  0.25 -0.21\n",
      "  0.18  0.94  0.93  0.23  0.52 -0.3  -0.36 -0.53 -2.4  -0.59  0.58  0.3\n",
      "  0.22 -0.25  0.04 -0.85  0.29 -0.21 -0.29  0.4  -0.9   0.86 -0.01 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 20\n",
      "train loss 7495.335591811208 [10013.211371980018, 6628.702564993711, 6652.138585205531, 6687.28984506557]\n",
      "validation accuracy 0.8553484934293886 [0.0, 0.8523125115164838, 0.8560899207665298, 0.857643048005152]\n",
      "[-2.55  0.79  0.09  0.89  2.53  0.05  0.4   0.63 -0.03 -0.88  0.22  0.42\n",
      " -0.21 -0.14 -3.05  0.49 -0.57 -0.47 -0.14 -1.14 -0.84 -0.98 -0.77  0.67\n",
      "  0.68  1.3   2.41  0.18  1.61 -7.24  2.23  0.53 -1.21  2.1   1.13 -1.15\n",
      " -1.41 -1.32 -0.67  0.17 -0.98  0.18  0.95 -0.7  -0.49 -0.18 -0.61 -3.39\n",
      "  0.69  0.85  0.47  0.83  0.06 -0.39 -0.74 -0.11 -0.95 -1.12 -0.32  0.7\n",
      " -0.88 -0.19 -0.52 -0.68 -0.28  1.36  0.55 -0.56 -1.84  0.58 -1.62  0.22\n",
      " -0.49  0.62  0.75  0.66 -0.79 -0.02  0.12 -0.15 -0.96  0.19  0.25 -0.2\n",
      "  0.19  0.94  0.94  0.24  0.52 -0.3  -0.35 -0.53 -2.47 -0.59  0.58  0.3\n",
      "  0.23 -0.25  0.04 -0.85  0.29 -0.21 -0.28  0.41 -0.89  0.87 -0.01 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n",
      "i 21\n",
      "train loss 7494.7402859694885 [10010.26691601196, 6628.944072045899, 6652.396820136721, 6687.353335683376]\n",
      "validation accuracy 0.855102796956147 [0.0, 0.8521282476506279, 0.8559056569006739, 0.8572744863171394]\n",
      "[-2.56  0.79  0.09  0.88  2.53  0.04  0.4   0.64 -0.02 -0.92  0.23  0.43\n",
      " -0.2  -0.13 -3.11  0.51 -0.56 -0.46 -0.14 -1.13 -0.84 -0.97 -0.76  0.68\n",
      "  0.68  1.31  2.41  0.19  1.61 -7.36  2.24  0.54 -1.22  2.1   1.12 -1.15\n",
      " -1.41 -1.33 -0.68  0.17 -0.98  0.18  0.95 -0.69 -0.49 -0.18 -0.61 -3.4\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.4  -0.74 -0.11 -0.96 -1.12 -0.32  0.7\n",
      " -0.88 -0.19 -0.52 -0.68 -0.29  1.37  0.55 -0.55 -1.84  0.58 -1.62  0.22\n",
      " -0.49  0.62  0.75  0.66 -0.79 -0.02  0.12 -0.16 -0.99  0.19  0.25 -0.2\n",
      "  0.19  0.95  0.94  0.24  0.53 -0.3  -0.35 -0.53 -2.54 -0.59  0.58  0.3\n",
      "  0.23 -0.25  0.05 -0.85  0.3  -0.21 -0.28  0.41 -0.89  0.87 -0.   -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 22\n",
      "train loss 7494.717236591349 [10008.915150759854, 6627.929844510689, 6653.752219335838, 6688.271731759017]\n",
      "validation accuracy 0.8551949373781502 [0.0, 0.8521282476506279, 0.8559056569006739, 0.8575509075831488]\n",
      "[-2.57  0.79  0.09  0.89  2.53  0.05  0.4   0.65 -0.01 -0.95  0.23  0.44\n",
      " -0.19 -0.12 -3.16  0.54 -0.55 -0.46 -0.13 -1.12 -0.83 -0.96 -0.75  0.68\n",
      "  0.69  1.31  2.42  0.19  1.62 -7.47  2.24  0.54 -1.22  2.09  1.12 -1.15\n",
      " -1.41 -1.33 -0.68  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.41\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.41 -0.74 -0.12 -0.96 -1.13 -0.33  0.69\n",
      " -0.88 -0.19 -0.52 -0.69 -0.29  1.37  0.55 -0.55 -1.84  0.59 -1.62  0.23\n",
      " -0.49  0.62  0.75  0.66 -0.79 -0.02  0.12 -0.17 -1.01  0.19  0.26 -0.2\n",
      "  0.19  0.95  0.94  0.24  0.53 -0.3  -0.35 -0.53 -2.6  -0.59  0.58  0.3\n",
      "  0.23 -0.25  0.05 -0.85  0.3  -0.2  -0.28  0.41 -0.89  0.87 -0.   -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 23\n",
      "train loss nan [10008.30485138415, 6627.641678134351, nan, 6689.863971172859]\n",
      "validation accuracy 0.8550720778227626 [0.0, 0.8522203795835558, 0.8559977888336019, 0.8569980650511301]\n",
      "[-2.58  0.79  0.09  0.88  2.53  0.05  0.4   0.66 -0.   -0.98  0.24  0.45\n",
      " -0.18 -0.11 -3.22  0.56 -0.55 -0.45 -0.13 -1.12 -0.82 -0.96 -0.75  0.69\n",
      "  0.7   1.32  2.43  0.2   1.63 -7.57  2.25  0.55 -1.22  2.09  1.12 -1.16\n",
      " -1.41 -1.33 -0.68  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.42\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.42 -0.74 -0.12 -0.96 -1.13 -0.33  0.69\n",
      " -0.89 -0.2  -0.52 -0.69 -0.29  1.37  0.55 -0.55 -1.84  0.59 -1.62  0.23\n",
      " -0.49  0.62  0.75  0.66 -0.79 -0.01  0.12 -0.18 -1.02  0.19  0.26 -0.2\n",
      "  0.19  0.95  0.94  0.24  0.53 -0.29 -0.35 -0.52 -2.66 -0.58  0.58  0.3\n",
      "  0.23 -0.25  0.05 -0.84  0.3  -0.2  -0.28  0.41 -0.89  0.87  0.   -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 24\n",
      "train loss nan [10008.8608168149, 6626.801560320938, nan, 6691.320837456831]\n",
      "validation accuracy 0.8551027941264554 [0.0, 0.8521282476506279, 0.8559977888336019, 0.8571823458951363]\n",
      "[-2.59  0.79  0.09  0.88  2.53  0.05  0.4   0.67  0.01 -1.01  0.25  0.46\n",
      " -0.17 -0.1  -3.27  0.57 -0.54 -0.45 -0.12 -1.11 -0.82 -0.95 -0.74  0.69\n",
      "  0.7   1.32  2.43  0.21  1.63 -7.66  2.25  0.55 -1.22  2.09  1.12 -1.16\n",
      " -1.41 -1.33 -0.68  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.43\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.43 -0.74 -0.12 -0.96 -1.13 -0.33  0.69\n",
      " -0.89 -0.2  -0.52 -0.69 -0.29  1.37  0.55 -0.55 -1.84  0.59 -1.62  0.23\n",
      " -0.48  0.63  0.75  0.66 -0.78 -0.01  0.12 -0.19 -1.04  0.2   0.26 -0.2\n",
      "  0.19  0.95  0.94  0.24  0.53 -0.29 -0.35 -0.52 -2.71 -0.58  0.59  0.31\n",
      "  0.23 -0.24  0.05 -0.84  0.3  -0.2  -0.27  0.41 -0.88  0.87  0.   -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 25\n",
      "train loss nan [10010.44115109598, 6626.345153427568, nan, 6692.68720896162]\n",
      "validation accuracy 0.8548570976532138 [0.0, 0.851943983784772, 0.855813524967746, 0.8568137842071237]\n",
      "[-2.6   0.79  0.09  0.89  2.53  0.05  0.4   0.67  0.02 -1.04  0.26  0.47\n",
      " -0.17 -0.09 -3.31  0.59 -0.54 -0.44 -0.12 -1.11 -0.81 -0.95 -0.74  0.7\n",
      "  0.71  1.33  2.44  0.21  1.64 -7.74  2.26  0.56 -1.22  2.09  1.12 -1.16\n",
      " -1.42 -1.33 -0.68  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.43\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.44 -0.75 -0.12 -0.96 -1.13 -0.33  0.69\n",
      " -0.89 -0.2  -0.53 -0.69 -0.29  1.37  0.56 -0.55 -1.83  0.59 -1.61  0.23\n",
      " -0.48  0.63  0.76  0.66 -0.78 -0.01  0.13 -0.2  -1.05  0.2   0.26 -0.19\n",
      "  0.2   0.95  0.94  0.25  0.53 -0.29 -0.34 -0.52 -2.76 -0.58  0.59  0.31\n",
      "  0.24 -0.24  0.05 -0.84  0.3  -0.2  -0.27  0.41 -0.88  0.87  0.   -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 26\n",
      "train loss nan [10012.91053477316, 6625.671250922112, nan, 6691.87619795642]\n",
      "validation accuracy 0.8553177771256957 [0.0, 0.8522203795835558, 0.8562741846323857, 0.8574587671611457]\n",
      "[-2.61  0.79  0.09  0.88  2.53  0.04  0.4   0.68  0.02 -1.06  0.27  0.47\n",
      " -0.16 -0.09 -3.36  0.61 -0.53 -0.44 -0.11 -1.1  -0.81 -0.94 -0.73  0.7\n",
      "  0.71  1.33  2.44  0.22  1.64 -7.82  2.26  0.56 -1.23  2.09  1.12 -1.16\n",
      " -1.42 -1.33 -0.68  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.44\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.45 -0.75 -0.12 -0.96 -1.13 -0.33  0.69\n",
      " -0.89 -0.2  -0.53 -0.69 -0.3   1.38  0.56 -0.54 -1.83  0.59 -1.61  0.23\n",
      " -0.48  0.63  0.76  0.67 -0.78 -0.01  0.13 -0.2  -1.06  0.2   0.26 -0.19\n",
      "  0.2   0.95  0.95  0.25  0.54 -0.29 -0.34 -0.52 -2.81 -0.58  0.59  0.31\n",
      "  0.24 -0.24  0.06 -0.84  0.3  -0.2  -0.27  0.42 -0.88  0.88  0.01 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 27\n",
      "train loss nan [10014.717384984724, 6625.217070816929, nan, 6690.676766712904]\n",
      "validation accuracy 0.8550413756675285 [0.0, 0.851943983784772, 0.8559056569006739, 0.8572744863171394]\n",
      "[-2.62  0.79  0.09  0.89  2.53  0.05  0.4   0.69  0.03 -1.09  0.27  0.48\n",
      " -0.15 -0.08 -3.4   0.63 -0.53 -0.43 -0.11 -1.1  -0.8  -0.94 -0.73  0.71\n",
      "  0.72  1.34  2.45  0.22  1.65 -7.89  2.27  0.57 -1.23  2.09  1.12 -1.16\n",
      " -1.42 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.44\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.46 -0.75 -0.12 -0.96 -1.13 -0.33  0.68\n",
      " -0.89 -0.2  -0.53 -0.7  -0.3   1.38  0.56 -0.54 -1.83  0.59 -1.61  0.23\n",
      " -0.48  0.63  0.76  0.67 -0.78 -0.01  0.13 -0.21 -1.07  0.2   0.26 -0.19\n",
      "  0.2   0.96  0.95  0.25  0.54 -0.29 -0.34 -0.52 -2.86 -0.58  0.59  0.31\n",
      "  0.24 -0.24  0.06 -0.84  0.31 -0.2  -0.27  0.42 -0.88  0.88  0.01 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n",
      "i 28\n",
      "train loss nan [10016.428207361903, 6624.739759234076, nan, 6688.74766850602]\n",
      "validation accuracy 0.8554406197029331 [0.0, 0.8524046434494117, 0.8564584484982416, 0.8574587671611457]\n",
      "[-2.63  0.79  0.09  0.88  2.53  0.04  0.4   0.7   0.04 -1.11  0.28  0.49\n",
      " -0.15 -0.07 -3.44  0.64 -0.52 -0.43 -0.1  -1.09 -0.8  -0.94 -0.72  0.71\n",
      "  0.72  1.34  2.45  0.22  1.65 -7.96  2.27  0.57 -1.23  2.09  1.12 -1.16\n",
      " -1.42 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.44\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.47 -0.75 -0.13 -0.97 -1.14 -0.33  0.68\n",
      " -0.9  -0.21 -0.53 -0.7  -0.3   1.38  0.56 -0.54 -1.83  0.6  -1.61  0.24\n",
      " -0.48  0.63  0.76  0.67 -0.78 -0.01  0.13 -0.22 -1.08  0.2   0.27 -0.19\n",
      "  0.2   0.96  0.95  0.25  0.54 -0.29 -0.34 -0.52 -2.9  -0.58  0.59  0.31\n",
      "  0.24 -0.24  0.06 -0.84  0.31 -0.19 -0.27  0.42 -0.88  0.88  0.01 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 29\n",
      "train loss nan [10015.328827479152, 6624.3944580385305, nan, 6687.521687367582]\n",
      "validation accuracy 0.8550106621935275 [0.0, 0.851943983784772, 0.8559056569006739, 0.8571823458951363]\n",
      "[-2.64  0.79  0.09  0.89  2.53  0.05  0.4   0.7   0.04 -1.14  0.29  0.49\n",
      " -0.14 -0.07 -3.48  0.66 -0.52 -0.42 -0.1  -1.09 -0.8  -0.93 -0.72  0.72\n",
      "  0.72  1.34  2.45  0.23  1.65 -8.03  2.27  0.58 -1.23  2.09  1.12 -1.16\n",
      " -1.42 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.44\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.48 -0.75 -0.13 -0.97 -1.14 -0.34  0.68\n",
      " -0.9  -0.21 -0.53 -0.7  -0.3   1.38  0.56 -0.54 -1.83  0.6  -1.61  0.24\n",
      " -0.48  0.63  0.76  0.67 -0.78 -0.01  0.13 -0.23 -1.09  0.2   0.27 -0.19\n",
      "  0.2   0.96  0.95  0.25  0.54 -0.28 -0.34 -0.52 -2.94 -0.57  0.59  0.31\n",
      "  0.24 -0.24  0.06 -0.83  0.31 -0.19 -0.27  0.42 -0.88  0.88  0.01 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 30\n",
      "train loss nan [10013.997655455052, 6624.1197032871205, nan, 6687.090302236726]\n",
      "validation accuracy 0.855164215415074 [0.0, 0.8521282476506279, 0.8561820526994578, 0.8571823458951363]\n",
      "[-2.65  0.79  0.09  0.88  2.53  0.04  0.4   0.71  0.05 -1.16  0.29  0.5\n",
      " -0.13 -0.06 -3.52  0.67 -0.52 -0.42 -0.1  -1.09 -0.79 -0.93 -0.72  0.72\n",
      "  0.73  1.35  2.46  0.23  1.66 -8.09  2.28  0.58 -1.23  2.09  1.11 -1.17\n",
      " -1.42 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.49 -0.76 -0.13 -0.97 -1.14 -0.34  0.68\n",
      " -0.9  -0.21 -0.54 -0.7  -0.3   1.38  0.56 -0.54 -1.83  0.6  -1.61  0.24\n",
      " -0.48  0.63  0.76  0.67 -0.78 -0.    0.13 -0.24 -1.09  0.2   0.27 -0.19\n",
      "  0.2   0.96  0.95  0.25  0.54 -0.28 -0.34 -0.51 -2.98 -0.57  0.59  0.31\n",
      "  0.24 -0.24  0.06 -0.83  0.31 -0.19 -0.27  0.42 -0.88  0.88  0.01 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 31\n",
      "train loss nan [10011.409324159657, 6623.943264166245, nan, 6687.5327502498985]\n",
      "validation accuracy 0.8552870693110782 [0.0, 0.8521282476506279, 0.8561820526994578, 0.8575509075831488]\n",
      "[-2.65  0.79  0.09  0.89  2.53  0.05  0.4   0.71  0.06 -1.18  0.3   0.51\n",
      " -0.13 -0.05 -3.55  0.68 -0.51 -0.42 -0.09 -1.08 -0.79 -0.93 -0.71  0.72\n",
      "  0.73  1.35  2.46  0.23  1.66 -8.14  2.28  0.58 -1.23  2.09  1.11 -1.17\n",
      " -1.42 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.5  -0.76 -0.13 -0.97 -1.14 -0.34  0.68\n",
      " -0.9  -0.21 -0.54 -0.7  -0.3   1.38  0.56 -0.54 -1.83  0.6  -1.61  0.24\n",
      " -0.47  0.64  0.76  0.67 -0.77 -0.    0.13 -0.25 -1.1   0.21  0.27 -0.19\n",
      "  0.2   0.96  0.95  0.25  0.54 -0.28 -0.33 -0.51 -3.02 -0.57  0.6   0.31\n",
      "  0.24 -0.24  0.06 -0.83  0.31 -0.19 -0.26  0.42 -0.87  0.88  0.01 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n",
      "i 32\n",
      "train loss nan [10009.51120587664, 6623.862963950631, nan, 6688.798794070177]\n",
      "validation accuracy 0.8551335076004564 [0.0, 0.851851851851844, 0.8562741846323857, 0.8572744863171394]\n",
      "[-2.66  0.79  0.09  0.88  2.53  0.04  0.4   0.72  0.06 -1.2   0.31  0.51\n",
      " -0.12 -0.05 -3.59  0.7  -0.51 -0.41 -0.09 -1.08 -0.79 -0.92 -0.71  0.73\n",
      "  0.73  1.35  2.46  0.24  1.66 -8.2   2.28  0.59 -1.23  2.08  1.11 -1.17\n",
      " -1.42 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.5  -0.76 -0.13 -0.97 -1.14 -0.34  0.68\n",
      " -0.9  -0.21 -0.54 -0.7  -0.31  1.38  0.56 -0.54 -1.83  0.6  -1.61  0.24\n",
      " -0.47  0.64  0.77  0.67 -0.77 -0.    0.13 -0.26 -1.1   0.21  0.27 -0.19\n",
      "  0.21  0.96  0.95  0.26  0.54 -0.28 -0.33 -0.51 -3.06 -0.57  0.6   0.32\n",
      "  0.24 -0.23  0.06 -0.83  0.31 -0.19 -0.26  0.42 -0.87  0.88  0.01 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 33\n",
      "train loss nan [10008.337447224407, 6623.877312886983, nan, 6690.348045375641]\n",
      "validation accuracy 0.8551027941264554 [0.0, 0.8521282476506279, 0.8559977888336019, 0.8571823458951363]\n",
      "[-2.67  0.79  0.09  0.89  2.53  0.05  0.4   0.73  0.07 -1.22  0.31  0.52\n",
      " -0.12 -0.04 -3.62  0.71 -0.51 -0.41 -0.09 -1.08 -0.78 -0.92 -0.71  0.73\n",
      "  0.74  1.36  2.47  0.24  1.67 -8.25  2.29  0.59 -1.23  2.08  1.11 -1.17\n",
      " -1.43 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.51 -0.76 -0.13 -0.97 -1.14 -0.34  0.68\n",
      " -0.9  -0.21 -0.54 -0.7  -0.31  1.39  0.57 -0.54 -1.82  0.6  -1.61  0.24\n",
      " -0.47  0.64  0.77  0.67 -0.77 -0.    0.14 -0.27 -1.11  0.21  0.27 -0.18\n",
      "  0.21  0.96  0.96  0.26  0.54 -0.28 -0.33 -0.51 -3.09 -0.57  0.6   0.32\n",
      "  0.25 -0.23  0.07 -0.83  0.31 -0.19 -0.26  0.42 -0.87  0.89  0.01 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 34\n",
      "train loss nan [10008.261513438902, 6623.984258668788, nan, 6692.149274699781]\n",
      "validation accuracy 0.8550106537044521 [0.0, 0.851851851851844, 0.8562741846323857, 0.8569059246291268]\n",
      "[-2.67  0.79  0.09  0.89  2.53  0.05  0.4   0.73  0.07 -1.24  0.32  0.52\n",
      " -0.11 -0.04 -3.65  0.72 -0.5  -0.41 -0.08 -1.07 -0.78 -0.92 -0.7   0.73\n",
      "  0.74  1.36  2.47  0.24  1.67 -8.3   2.29  0.59 -1.23  2.08  1.11 -1.17\n",
      " -1.43 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.52 -0.76 -0.13 -0.97 -1.14 -0.34  0.68\n",
      " -0.9  -0.22 -0.54 -0.71 -0.31  1.39  0.57 -0.54 -1.82  0.6  -1.61  0.24\n",
      " -0.47  0.64  0.77  0.68 -0.77  0.    0.14 -0.27 -1.11  0.21  0.27 -0.18\n",
      "  0.21  0.96  0.96  0.26  0.55 -0.28 -0.33 -0.51 -3.13 -0.57  0.6   0.32\n",
      "  0.25 -0.23  0.07 -0.83  0.31 -0.19 -0.26  0.43 -0.87  0.89  0.01 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 35\n",
      "train loss nan [10009.326767502564, 6624.181251234946, nan, 6692.142117157584]\n",
      "validation accuracy 0.8550720863118376 [0.0, 0.8520361157176999, 0.8559056569006739, 0.8572744863171394]\n",
      "[-2.68  0.79  0.09  0.89  2.53  0.05  0.4   0.74  0.08 -1.26  0.32  0.53\n",
      " -0.1  -0.03 -3.68  0.74 -0.5  -0.41 -0.08 -1.07 -0.78 -0.91 -0.7   0.73\n",
      "  0.74  1.36  2.47  0.25  1.67 -8.34  2.29  0.59 -1.23  2.08  1.11 -1.17\n",
      " -1.43 -1.34 -0.69  0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.52 -0.76 -0.13 -0.97 -1.14 -0.34  0.67\n",
      " -0.91 -0.22 -0.54 -0.71 -0.31  1.39  0.57 -0.53 -1.82  0.6  -1.61  0.24\n",
      " -0.47  0.64  0.77  0.68 -0.77  0.    0.14 -0.28 -1.12  0.21  0.27 -0.18\n",
      "  0.21  0.97  0.96  0.26  0.55 -0.28 -0.33 -0.51 -3.16 -0.57  0.6   0.32\n",
      "  0.25 -0.23  0.07 -0.83  0.32 -0.19 -0.26  0.43 -0.87  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 36\n",
      "train loss nan [10011.232566868006, 6624.474947512963, nan, 6691.584103897227]\n",
      "validation accuracy 0.8552256367036927 [0.0, 0.8521282476506279, 0.8563663165653137, 0.8571823458951363]\n",
      "[-2.68  0.79  0.09  0.89  2.53  0.05  0.4   0.74  0.08 -1.28  0.33  0.53\n",
      " -0.1  -0.03 -3.71  0.75 -0.5  -0.4  -0.08 -1.07 -0.78 -0.91 -0.7   0.74\n",
      "  0.75  1.37  2.47  0.25  1.67 -8.39  2.3   0.6  -1.24  2.08  1.11 -1.17\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.53 -0.76 -0.13 -0.97 -1.14 -0.34  0.67\n",
      " -0.91 -0.22 -0.54 -0.71 -0.31  1.39  0.57 -0.53 -1.82  0.6  -1.6   0.24\n",
      " -0.47  0.64  0.77  0.68 -0.77  0.    0.14 -0.29 -1.12  0.21  0.28 -0.18\n",
      "  0.21  0.97  0.96  0.26  0.55 -0.28 -0.33 -0.51 -3.19 -0.57  0.6   0.32\n",
      "  0.25 -0.23  0.07 -0.83  0.32 -0.18 -0.26  0.43 -0.87  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 37\n",
      "train loss nan [10013.877823294366, 6624.819278665429, nan, 6689.596880641952]\n",
      "validation accuracy 0.8551028054452222 [0.0, 0.851943983784772, 0.855813524967746, 0.8575509075831488]\n",
      "[-2.69  0.79  0.09  0.88  2.53  0.04  0.4   0.75  0.09 -1.3   0.33  0.54\n",
      " -0.1  -0.02 -3.74  0.76 -0.5  -0.4  -0.08 -1.07 -0.77 -0.91 -0.7   0.74\n",
      "  0.75  1.37  2.48  0.25  1.68 -8.43  2.3   0.6  -1.24  2.08  1.11 -1.17\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.54 -0.76 -0.14 -0.97 -1.15 -0.34  0.67\n",
      " -0.91 -0.22 -0.54 -0.71 -0.31  1.39  0.57 -0.53 -1.82  0.6  -1.6   0.24\n",
      " -0.47  0.64  0.77  0.68 -0.77  0.    0.14 -0.3  -1.12  0.21  0.28 -0.18\n",
      "  0.21  0.97  0.96  0.26  0.55 -0.28 -0.33 -0.51 -3.22 -0.57  0.6   0.32\n",
      "  0.25 -0.23  0.07 -0.83  0.32 -0.18 -0.26  0.43 -0.87  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 38\n",
      "train loss nan [10015.248341075081, 6625.301216664602, nan, 6688.075535989328]\n",
      "validation accuracy 0.8551027941264554 [0.0, 0.8521282476506279, 0.8559977888336019, 0.8571823458951363]\n",
      "[-2.69  0.79  0.09  0.89  2.53  0.05  0.4   0.75  0.09 -1.31  0.34  0.54\n",
      " -0.09 -0.02 -3.77  0.77 -0.49 -0.4  -0.07 -1.06 -0.77 -0.91 -0.69  0.74\n",
      "  0.75  1.37  2.48  0.25  1.68 -8.47  2.3   0.6  -1.24  2.08  1.11 -1.17\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.54 -0.76 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.91 -0.22 -0.54 -0.71 -0.31  1.39  0.57 -0.53 -1.82  0.61 -1.6   0.25\n",
      " -0.47  0.64  0.77  0.68 -0.77  0.    0.14 -0.31 -1.12  0.21  0.28 -0.18\n",
      "  0.21  0.97  0.96  0.26  0.55 -0.27 -0.33 -0.51 -3.25 -0.56  0.6   0.32\n",
      "  0.25 -0.23  0.07 -0.83  0.32 -0.18 -0.26  0.43 -0.87  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n",
      "i 39\n",
      "train loss nan [10016.331975730922, 6625.727751320832, nan, 6687.151345574015]\n",
      "validation accuracy 0.855164215415074 [0.0, 0.8521282476506279, 0.8561820526994578, 0.8571823458951363]\n",
      "[-2.7   0.79  0.09  0.88  2.53  0.04  0.4   0.76  0.1  -1.33  0.34  0.55\n",
      " -0.09 -0.01 -3.79  0.78 -0.49 -0.4  -0.07 -1.06 -0.77 -0.9  -0.69  0.74\n",
      "  0.75  1.37  2.48  0.26  1.68 -8.51  2.3   0.6  -1.24  2.08  1.11 -1.17\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.55 -0.76 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.91 -0.22 -0.55 -0.71 -0.31  1.39  0.57 -0.53 -1.82  0.61 -1.6   0.25\n",
      " -0.47  0.64  0.77  0.68 -0.77  0.01  0.14 -0.32 -1.12  0.21  0.28 -0.18\n",
      "  0.21  0.97  0.96  0.26  0.55 -0.27 -0.33 -0.51 -3.28 -0.56  0.6   0.32\n",
      "  0.25 -0.23  0.07 -0.82  0.32 -0.18 -0.26  0.43 -0.87  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 40\n",
      "train loss nan [10014.6196615714, 6626.386813080211, nan, 6687.115932376668]\n",
      "validation accuracy 0.8552563586667689 [0.0, 0.8522203795835558, 0.8559977888336019, 0.8575509075831488]\n",
      "[-2.7   0.79  0.09  0.89  2.53  0.05  0.4   0.76  0.1  -1.35  0.35  0.55\n",
      " -0.08 -0.01 -3.82  0.79 -0.49 -0.39 -0.07 -1.06 -0.77 -0.9  -0.69  0.75\n",
      "  0.75  1.38  2.48  0.26  1.68 -8.55  2.31  0.61 -1.24  2.08  1.11 -1.17\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.56 -0.77 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.91 -0.22 -0.55 -0.71 -0.31  1.39  0.57 -0.53 -1.82  0.61 -1.6   0.25\n",
      " -0.47  0.64  0.77  0.68 -0.77  0.01  0.14 -0.32 -1.13  0.21  0.28 -0.18\n",
      "  0.21  0.97  0.96  0.26  0.55 -0.27 -0.32 -0.5  -3.31 -0.56  0.6   0.32\n",
      "  0.25 -0.23  0.07 -0.82  0.32 -0.18 -0.26  0.43 -0.87  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n",
      "i 41\n",
      "train loss nan [10012.868394338631, 6626.797697642041, nan, 6687.940350624745]\n",
      "validation accuracy 0.8552256423630761 [0.0, 0.8521282476506279, 0.8561820526994578, 0.8573666267391425]\n",
      "[-2.71  0.79  0.09  0.88  2.53  0.04  0.4   0.76  0.11 -1.36  0.35  0.56\n",
      " -0.08 -0.   -3.84  0.8  -0.49 -0.39 -0.07 -1.06 -0.77 -0.9  -0.69  0.75\n",
      "  0.76  1.38  2.49  0.26  1.69 -8.59  2.31  0.61 -1.24  2.08  1.11 -1.17\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.56 -0.77 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.91 -0.22 -0.55 -0.71 -0.32  1.39  0.57 -0.53 -1.82  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.77  0.68 -0.77  0.01  0.14 -0.33 -1.13  0.22  0.28 -0.18\n",
      "  0.21  0.97  0.96  0.26  0.55 -0.27 -0.32 -0.5  -3.34 -0.56  0.61  0.32\n",
      "  0.25 -0.23  0.07 -0.82  0.32 -0.18 -0.25  0.43 -0.87  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 42\n",
      "train loss nan [10010.424009441464, 6627.590150880643, nan, 6689.355998054012]\n",
      "validation accuracy 0.855256355837077 [0.0, 0.8521282476506279, 0.8561820526994578, 0.8574587671611457]\n",
      "[-2.71  0.79  0.09  0.89  2.53  0.05  0.4   0.77  0.11 -1.38  0.35  0.56\n",
      " -0.07  0.   -3.87  0.81 -0.49 -0.39 -0.06 -1.06 -0.76 -0.9  -0.68  0.75\n",
      "  0.76  1.38  2.49  0.26  1.69 -8.62  2.31  0.61 -1.24  2.08  1.11 -1.18\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.49 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.57 -0.77 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.91 -0.22 -0.55 -0.71 -0.32  1.39  0.57 -0.53 -1.82  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.77  0.68 -0.76  0.01  0.14 -0.34 -1.13  0.22  0.28 -0.18\n",
      "  0.21  0.97  0.96  0.26  0.55 -0.27 -0.32 -0.5  -3.37 -0.56  0.61  0.32\n",
      "  0.25 -0.22  0.07 -0.82  0.32 -0.18 -0.25  0.43 -0.86  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 43\n",
      "train loss nan [10008.805932163694, 6627.862723133041, nan, 6691.290038099541]\n",
      "validation accuracy 0.8549492324158336 [0.0, 0.851943983784772, 0.8559977888336019, 0.8569059246291268]\n",
      "[-2.72  0.79  0.09  0.88  2.53  0.04  0.4   0.77  0.11 -1.39  0.36  0.57\n",
      " -0.07  0.   -3.89  0.82 -0.48 -0.39 -0.06 -1.05 -0.76 -0.9  -0.68  0.75\n",
      "  0.76  1.38  2.49  0.26  1.69 -8.66  2.31  0.61 -1.24  2.08  1.11 -1.18\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.48 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.57 -0.77 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.91 -0.22 -0.55 -0.72 -0.32  1.39  0.57 -0.53 -1.81  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.78  0.68 -0.76  0.01  0.14 -0.35 -1.13  0.22  0.28 -0.18\n",
      "  0.22  0.97  0.96  0.26  0.55 -0.27 -0.32 -0.5  -3.39 -0.56  0.61  0.33\n",
      "  0.25 -0.22  0.07 -0.82  0.32 -0.18 -0.25  0.43 -0.86  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 44\n",
      "train loss nan [10008.103390394626, 6628.696192501431, nan, 6692.029838917153]\n",
      "validation accuracy 0.855164215415074 [0.0, 0.8520361157176999, 0.8562741846323857, 0.8571823458951363]\n",
      "[-2.72  0.79  0.09  0.89  2.53  0.05  0.4   0.78  0.12 -1.41  0.36  0.57\n",
      " -0.06  0.01 -3.92  0.83 -0.48 -0.39 -0.06 -1.05 -0.76 -0.89 -0.68  0.75\n",
      "  0.76  1.38  2.49  0.27  1.69 -8.69  2.31  0.61 -1.24  2.08  1.1  -1.18\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.48 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.58 -0.77 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.91 -0.23 -0.55 -0.72 -0.32  1.39  0.58 -0.53 -1.81  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.78  0.68 -0.76  0.01  0.15 -0.35 -1.13  0.22  0.28 -0.17\n",
      "  0.22  0.97  0.96  0.27  0.55 -0.27 -0.32 -0.5  -3.42 -0.56  0.61  0.33\n",
      "  0.26 -0.22  0.07 -0.82  0.32 -0.18 -0.25  0.43 -0.86  0.89  0.02 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 45\n",
      "train loss nan [10008.52770252309, 6628.711977815954, nan, 6692.271610393865]\n",
      "validation accuracy 0.8550720806524543 [0.0, 0.851851851851844, 0.8562741846323857, 0.8570902054731332]\n",
      "[-2.73  0.79  0.09  0.89  2.53  0.05  0.4   0.78  0.12 -1.42  0.37  0.57\n",
      " -0.06  0.01 -3.94  0.84 -0.48 -0.38 -0.06 -1.05 -0.76 -0.89 -0.68  0.76\n",
      "  0.76  1.39  2.49  0.27  1.69 -8.72  2.32  0.62 -1.24  2.08  1.1  -1.18\n",
      " -1.43 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.48 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.58 -0.77 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.92 -0.23 -0.55 -0.72 -0.32  1.4   0.58 -0.53 -1.81  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.78  0.69 -0.76  0.01  0.15 -0.36 -1.13  0.22  0.28 -0.17\n",
      "  0.22  0.97  0.97  0.27  0.55 -0.27 -0.32 -0.5  -3.44 -0.56  0.61  0.33\n",
      "  0.26 -0.22  0.08 -0.82  0.32 -0.18 -0.25  0.43 -0.86  0.9   0.02 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 46\n",
      "train loss nan [10010.073222224451, 6629.450703730474, nan, 6690.522267013198]\n",
      "validation accuracy 0.8551642267338408 [0.0, 0.8520361157176999, 0.8559056569006739, 0.8575509075831488]\n",
      "[-2.73  0.79  0.09  0.89  2.53  0.05  0.4   0.78  0.13 -1.44  0.37  0.58\n",
      " -0.06  0.02 -3.96  0.85 -0.48 -0.38 -0.06 -1.05 -0.76 -0.89 -0.68  0.76\n",
      "  0.77  1.39  2.5   0.27  1.7  -8.75  2.32  0.62 -1.24  2.07  1.1  -1.18\n",
      " -1.44 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.48 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.59 -0.77 -0.14 -0.98 -1.15 -0.35  0.67\n",
      " -0.92 -0.23 -0.55 -0.72 -0.32  1.4   0.58 -0.53 -1.81  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.78  0.69 -0.76  0.01  0.15 -0.37 -1.13  0.22  0.28 -0.17\n",
      "  0.22  0.97  0.97  0.27  0.56 -0.27 -0.32 -0.5  -3.47 -0.56  0.61  0.33\n",
      "  0.26 -0.22  0.08 -0.82  0.33 -0.18 -0.25  0.43 -0.86  0.9   0.02 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 47\n",
      "train loss nan [10012.181628803082, 6629.141678017698, nan, 6688.907494409912]\n",
      "validation accuracy 0.855164215415074 [0.0, 0.8520361157176999, 0.8562741846323857, 0.8571823458951363]\n",
      "[-2.74  0.79  0.09  0.89  2.53  0.05  0.4   0.79  0.13 -1.45  0.37  0.58\n",
      " -0.05  0.02 -3.98  0.86 -0.48 -0.38 -0.05 -1.05 -0.75 -0.89 -0.67  0.76\n",
      "  0.77  1.39  2.5   0.27  1.7  -8.78  2.32  0.62 -1.24  2.07  1.1  -1.18\n",
      " -1.44 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.48 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.59 -0.77 -0.14 -0.98 -1.15 -0.35  0.66\n",
      " -0.92 -0.23 -0.55 -0.72 -0.32  1.4   0.58 -0.52 -1.81  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.78  0.69 -0.76  0.01  0.15 -0.38 -1.13  0.22  0.28 -0.17\n",
      "  0.22  0.98  0.97  0.27  0.56 -0.27 -0.32 -0.5  -3.49 -0.56  0.61  0.33\n",
      "  0.26 -0.22  0.08 -0.82  0.33 -0.18 -0.25  0.44 -0.86  0.9   0.03 -0.42\n",
      " -0.01 -0.13  0.05 -0.08]\n",
      "\n",
      "i 48\n",
      "train loss nan [10014.81932933478, 6629.643736254741, nan, 6687.514427047634]\n",
      "validation accuracy 0.8552563586667689 [0.0, 0.8521282476506279, 0.8560899207665298, 0.8575509075831488]\n",
      "[-2.74  0.79  0.09  0.88  2.53  0.04  0.4   0.79  0.13 -1.47  0.38  0.58\n",
      " -0.05  0.02 -4.    0.87 -0.47 -0.38 -0.05 -1.04 -0.75 -0.89 -0.67  0.76\n",
      "  0.77  1.39  2.5   0.27  1.7  -8.81  2.32  0.62 -1.24  2.07  1.1  -1.18\n",
      " -1.44 -1.35 -0.7   0.17 -0.98  0.19  0.95 -0.69 -0.48 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.6  -0.77 -0.14 -0.98 -1.15 -0.35  0.66\n",
      " -0.92 -0.23 -0.55 -0.72 -0.32  1.4   0.58 -0.52 -1.81  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.78  0.69 -0.76  0.01  0.15 -0.38 -1.13  0.22  0.29 -0.17\n",
      "  0.22  0.98  0.97  0.27  0.56 -0.27 -0.32 -0.5  -3.51 -0.56  0.61  0.33\n",
      "  0.26 -0.22  0.08 -0.82  0.33 -0.18 -0.25  0.44 -0.86  0.9   0.03 -0.42\n",
      " -0.01 -0.13  0.04 -0.08]\n",
      "\n",
      "i 49\n",
      "train loss nan [10015.583352138721, 6629.030906688108, nan, 6686.98909735027]\n",
      "validation accuracy 0.8552256480224596 [0.0, 0.8521282476506279, 0.8559977888336019, 0.8575509075831488]\n",
      "[-2.74  0.79  0.09  0.89  2.53  0.05  0.4   0.8   0.14 -1.48  0.38  0.59\n",
      " -0.05  0.03 -4.02  0.88 -0.47 -0.38 -0.05 -1.04 -0.75 -0.89 -0.67  0.76\n",
      "  0.77  1.39  2.5   0.27  1.7  -8.84  2.32  0.62 -1.24  2.07  1.1  -1.18\n",
      " -1.44 -1.35 -0.7   0.17 -0.98  0.19  0.96 -0.69 -0.48 -0.17 -0.61 -3.45\n",
      "  0.69  0.85  0.48  0.83  0.06 -0.6  -0.77 -0.14 -0.98 -1.15 -0.35  0.66\n",
      " -0.92 -0.23 -0.55 -0.72 -0.32  1.4   0.58 -0.52 -1.81  0.61 -1.6   0.25\n",
      " -0.46  0.65  0.78  0.69 -0.76  0.01  0.15 -0.39 -1.13  0.22  0.29 -0.17\n",
      "  0.22  0.98  0.97  0.27  0.56 -0.27 -0.32 -0.5  -3.54 -0.56  0.61  0.33\n",
      "  0.26 -0.22  0.08 -0.82  0.33 -0.17 -0.25  0.44 -0.86  0.9   0.03 -0.42\n",
      " -0.01 -0.13  0.06 -0.08]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "G.model = LogisticRegression()\n",
    "G.model.setdata(G.X_train, G.y_train)\n",
    "num_iter = 50\n",
    "for i in range(num_iter):\n",
    "    print('i', i)\n",
    "    G.model.step(200, True)\n",
    "    joblib.dump(G.model, '1/'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df, normcols, col_mean, col_std):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # normalize\n",
    "    for cnam in normcols:\n",
    "        df[cnam] = (df[cnam] - col_mean[cnam]) / col_std[cnam]\n",
    "    \n",
    "    return extract(df)\n",
    "\n",
    "G.X_test = preprocess_test(G.df_test_full, G.normcols, G.col_mean, G.col_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.16 0.31 0.83 0.   0.01 0.01 0.87 0.   0.04 0.68 0.6  0.01 0.25\n",
      " 0.6  0.86 0.   0.34 0.01 0.83 0.65 0.   0.   0.03 0.37 0.87 0.   0.01\n",
      " 0.3  0.07 0.91 0.01 0.05 0.17 0.01 0.21 0.6  0.   0.   0.   0.76 0.59\n",
      " 0.14 0.04 0.   0.41 0.06 0.77 0.   0.18 0.   0.01 0.   0.38 0.04 0.\n",
      " 0.28 0.86 0.9  0.12 0.09 0.11 0.06 0.   0.03 0.02 0.99 0.   0.07 0.42\n",
      " 1.   0.62 0.06 0.   0.06 0.   0.26 0.23 0.35 0.   0.42 0.08 0.03 1.\n",
      " 0.2  0.02 0.   0.51 0.01 0.86 0.1  0.01 0.8  0.27 0.04 0.   0.02 0.1\n",
      " 0.32 0.   0.28 0.01 0.   0.01 0.03 0.01 0.4  0.02 0.   0.   0.   0.18\n",
      " 0.41 0.   0.22 0.01 0.32 0.   0.03 0.1  0.08 0.   0.01 0.07 0.01 0.01\n",
      " 0.95 0.01 0.19 0.97 0.42 0.   0.   0.89 0.35 0.03 0.41 0.09 0.2  0.02\n",
      " 0.76 0.   0.94 0.85 0.03 0.06 0.09 0.25 1.   0.02 0.   0.03 0.05 0.01\n",
      " 0.78 0.   0.01 0.03 0.01 0.33 0.07 0.23 0.09 0.04 0.77 0.39 0.62 0.35\n",
      " 0.   0.1  0.79 0.22 0.02 0.48 0.06 0.54 0.13 0.25 0.35 0.59 0.39 1.\n",
      " 0.03 0.3  0.03 0.08 0.05 0.01 0.03 0.   0.88 0.29 0.04 0.01 0.01 0.03\n",
      " 0.1  0.94 0.   0.07 0.54 0.62 0.22 0.11 0.6  0.63 0.13 0.12 0.79 0.38\n",
      " 0.   0.   0.33 0.47 0.01 0.25 0.02 0.   0.06 0.03 0.52 0.01 0.05 0.5\n",
      " 0.55 0.4  1.   0.48 0.   0.1  0.   0.87 0.15 0.36 0.02 0.07 0.89 0.\n",
      " 0.02 0.15 0.   0.72 0.   0.21 0.   0.38 0.13 0.05 0.45 0.19 0.   0.09\n",
      " 0.36 0.25 0.06 0.   0.51 0.01 0.01 0.21 0.78 0.11 0.02 0.01 0.07 0.28\n",
      " 0.25 0.05 0.   0.1  0.3  0.16 0.66 0.3  0.26 0.   0.04 0.   1.   0.03\n",
      " 0.35 0.1  0.   0.04 0.57 0.03 0.   0.58 0.45 0.05 0.59 0.09 0.19 0.01\n",
      " 0.06 0.03 0.01 0.01 0.99 0.42 0.38 0.   0.02 0.01 0.   0.08 0.06 0.02\n",
      " 0.86 0.39 0.56 0.   0.25 0.54 0.6  0.12 0.01 0.   0.68 0.15 0.03 0.81\n",
      " 0.27 0.04 0.   0.68 0.13 0.   0.25 1.   0.   0.   0.32 0.09 0.92 0.\n",
      " 0.   0.01 0.2  0.22 0.12 0.18 0.02 0.77 0.96 0.05 1.   0.52 0.   0.05\n",
      " 0.02 0.   0.01 0.08 0.26 0.63 0.14 1.   0.11 0.02 0.15 0.18 0.01 0.12\n",
      " 0.42 0.8  0.57 0.53 0.27 0.   0.24 0.01 0.1  0.62 0.01 0.47 0.8  0.\n",
      " 0.04 0.   0.33 0.05 0.98 0.04 0.09 0.01 0.02 0.02 0.35 0.87 0.1  0.01\n",
      " 0.19 0.   0.02 0.02 0.84 0.09 0.65 0.75 0.09 0.   0.   0.04 0.33 0.02\n",
      " 0.07 0.01 0.01 0.64 0.01 0.29 0.   0.   0.12 0.2  0.07 0.54 1.   0.39\n",
      " 0.02 0.02 0.02 0.07 0.01 0.06 0.01 0.01 0.   0.   0.34 0.   0.31 0.01\n",
      " 0.   0.63 0.51 0.   0.53 0.88 0.33 0.28 0.01 0.5  0.   0.91 0.84 0.09\n",
      " 0.01 0.02 0.17 0.11 0.83 0.07 0.03 0.02 0.02 0.71 0.   0.25 0.23 0.14\n",
      " 0.72 0.08 0.14 0.01 0.87 0.25 0.13 0.   0.   0.02 0.02 0.34 0.02 0.02\n",
      " 0.1  0.02 0.43 0.05 0.54 0.02 0.   1.   0.02 0.08 0.   0.01 0.06 0.08\n",
      " 0.02 0.02 0.22 0.06 0.07 0.59 0.   0.12 0.   0.21 0.17 0.32 0.42 0.06\n",
      " 0.26 0.28 0.   0.99 0.   0.26 0.   0.01 0.   0.   0.02 0.   0.   0.03\n",
      " 0.98 0.   0.09 0.15 0.3  0.   0.63 0.03 0.65 0.38 0.15 0.99 0.28 0.01\n",
      " 0.02 0.09 0.22 0.6  0.14 0.78 0.43 0.   0.18 0.68 0.14 0.   0.83 0.43\n",
      " 0.72 0.17 0.11 0.32 0.   0.   0.71 0.63 0.43 0.15 0.36 0.73 0.72 0.01\n",
      " 0.02 0.01 0.47 0.03 0.01 0.04 0.17 0.02 0.73 0.   0.43 0.05 0.33 0.02\n",
      " 0.72 0.86 0.1  0.37 0.82 0.48 0.12 0.71 0.69 0.01 0.03 0.02 0.32 0.86\n",
      " 0.   0.02 0.   0.13 0.21 0.   0.82 0.02 0.01 0.65 0.82 0.   0.4  0.04\n",
      " 0.18 0.59 0.01 0.01 0.01 0.46 0.03 0.07 0.38 0.97 0.   0.02 0.21 0.11\n",
      " 0.   0.43 0.07 0.98 0.25 0.01 0.02 0.07 0.13 0.94 0.38 0.97 0.17 0.24\n",
      " 0.06 0.04 0.26 0.   0.1  0.96 0.1  0.01 0.59 0.   0.03 0.   0.9  1.\n",
      " 0.01 0.   0.   0.51 0.03 0.   0.13 0.   0.92 0.22 0.49 0.   0.83 0.01\n",
      " 0.12 0.06 0.64 0.06 0.01 0.   0.08 0.04 0.28 0.04 0.15 0.55 0.   0.02\n",
      " 0.05 0.87 0.   0.   0.04 0.01 0.02 0.98 0.21 0.02 0.3  0.44 0.6  0.07\n",
      " 0.64 0.   0.05 0.14 0.11 0.01 1.   0.2  0.34 0.   0.01 0.01 0.63 0.83\n",
      " 0.05 0.75 1.   0.   0.01 0.03 0.21 0.02 0.53 0.84 0.11 0.5  0.43 0.03\n",
      " 0.4  0.01 0.18 0.01 0.79 0.94 0.18 0.69 0.1  0.05 0.06 0.08 0.99 0.02\n",
      " 0.   0.1  0.15 0.25 0.78 0.01 0.   0.23 0.26 0.42 0.01 0.01 0.07 0.29\n",
      " 0.18 0.52 0.06 0.01 0.03 0.31 0.55 0.5  0.87 0.58 0.03 0.02 0.22 0.38\n",
      " 0.03 0.09 0.54 0.63 0.2  0.4  0.08 0.01 0.   0.   0.01 0.01 0.   0.47\n",
      " 0.   0.   0.02 0.   0.51 0.66 0.76 0.04 0.09 0.   0.01 0.63 0.33 0.05\n",
      " 0.67 0.86 0.67 0.23 0.27 0.04 0.14 0.   0.01 0.02 0.2  0.28 0.09 0.64\n",
      " 0.01 0.38 0.01 0.1  0.22 0.12 0.25 0.41 0.08 0.89 0.02 0.07 0.6  0.1\n",
      " 0.07 0.31 0.02 0.72 0.02 0.   0.   0.14 0.   0.02 0.04 0.03 0.51 0.01\n",
      " 0.02 0.   0.79 0.88 0.1  0.04 0.31 0.24 0.18 0.03 0.14 0.06 0.01 0.2\n",
      " 0.07 0.   0.   0.39 0.01 0.04 0.59 0.47 0.82 0.01 0.06 0.99 0.   0.44\n",
      " 0.01 0.12 0.32 0.2  0.74 0.15 0.02 0.32 0.02 0.03 0.06 0.06 0.79 0.13\n",
      " 0.92 0.02 0.06 0.11 0.49 0.21 0.02 0.25 0.06 0.01 0.68 0.66 0.03 0.07\n",
      " 1.   0.   0.4  0.75 0.11 0.77 0.43 0.72 0.12 0.22 0.34 0.   0.48 0.01\n",
      " 0.13 0.88 0.   0.16 0.61 0.83 0.02 0.   0.02 0.91 0.69 0.35 0.53 0.35\n",
      " 0.01 0.03 0.27 0.   0.53 0.   0.17 0.35 0.3  0.01 0.6  0.84 0.48 0.43\n",
      " 0.02 0.07 0.01 0.07 0.14 0.   0.01 0.66 0.16 0.   0.28 0.5  0.01 0.52\n",
      " 0.   0.01 0.23 0.56 0.01 0.39 0.   0.71 0.16 0.   0.13 0.35 0.05 0.\n",
      " 0.34 0.   0.56 0.   0.07 0.38 0.5  0.37 0.   0.01 0.05 0.   0.85 0.\n",
      " 0.02 0.49 0.07 0.   0.25 1.   0.31 0.07 0.06 0.1  0.01 0.62 1.   1.\n",
      " 0.32 0.   0.03 0.17 0.34 0.12 0.3  0.13 0.   0.   0.65 0.84 1.   0.41\n",
      " 0.33 0.   0.01 0.01 0.65 0.16]\n"
     ]
    }
   ],
   "source": [
    "def test(X, w):\n",
    "    y = sigmoid(X @ w)\n",
    "    print(y[:1000])\n",
    "    y = np.rint(y).astype(np.int8)\n",
    "    return y\n",
    "\n",
    "G.y_test = test(G.X_test, G.model.w[0])#joblib.load('logistic-85589.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame({\n",
    "    'id': np.arange(1, len(G.X_test)+1),\n",
    "    'label': G.y_test\n",
    "})\n",
    "df_pred.to_csv('submission.csv', index=False)\n",
    "df_pred['label'].values[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
