{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import sklearn.model_selection\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G:\n",
    "    # global variables\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G.df_train_full = pd.read_csv('X_train', dtype=np.int32)\n",
    "G.df_test_full = pd.read_csv('X_test', dtype=np.int32)\n",
    "G.y_train = torch.tensor(\n",
    "    np.array(open('Y_train').read().strip('\\n').split('\\n'),\n",
    "             dtype=np.int8),\n",
    "    dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "    c = len(df.columns)\n",
    "    n = len(df)\n",
    "    d = 1 + c + 5\n",
    "\n",
    "    X = torch.zeros((n, d), dtype=torch.float64)\n",
    "    X[:, 0] = 1  # bias\n",
    "    X[:, 1:1+c] = torch.tensor(df.values)\n",
    "\n",
    "    # quadratic term\n",
    "    # ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']\n",
    "    idx = [1,2,4,5,6]\n",
    "    X[:, 1+c:1+c+5] = X[:, idx] ** 2\n",
    "\n",
    "    return X\n",
    "\n",
    "def preprocess(df_train, df_test):\n",
    "    X_train = extract(df_train)\n",
    "    X_test = extract(df_test)\n",
    "    X_full = torch.cat((X_train, X_test), dim=0)\n",
    "    \n",
    "    means = torch.mean(X_full, dim=0)\n",
    "    stds = torch.std(X_full, dim=0)\n",
    "\n",
    "    # normalize\n",
    "    # ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']\n",
    "    idx = [1,2,4,5,6]\n",
    "    X_train[:, idx] = (X_train[:, idx] - means[idx]) / stds[idx]\n",
    "    X_test[:, idx] = (X_test[:, idx] - means[idx]) / stds[idx]\n",
    "\n",
    "    return X_train, X_test, means, stds\n",
    "\n",
    "G.X_train, G.X_test, G.means, G.stds = preprocess(G.df_train_full, G.df_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('a.csv',G.X_train,fmt='%.2f',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(dim, 1, bias=False).type(torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fx = F.sigmoid(self.linear(x))\n",
    "        return fx\n",
    "    \n",
    "    def weights(self):\n",
    "        return (self.linear.weight, self.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, k, dim):\n",
    "        self.k = k\n",
    "        self.kfold = sklearn.model_selection.KFold(k)\n",
    "        self.models = [LogisticRegression(dim) for _ in range(k+1)]\n",
    "        self.optim = [torch.optim.Adam(\n",
    "                            self.models[i].parameters())\n",
    "                      for i in range(k+1)]\n",
    "        self.loss_func = torch.nn.BCELoss()\n",
    "        self.step_ctr = 0\n",
    "        self.train_loss = None\n",
    "        self.val_accur = None\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        # Copy the object's state from self.__dict__ which contains\n",
    "        # all our instance attributes. Always use the dict.copy()\n",
    "        # method to avoid modifying the original state.\n",
    "        state = self.__dict__.copy()\n",
    "        # Remove the unpicklable entries.\n",
    "        del state['X']\n",
    "        del state['Xval']\n",
    "        del state['y']\n",
    "        del state['yval']\n",
    "        return state\n",
    "    \n",
    "    def setdata(self, X, y):\n",
    "        self.n, self.d = X.shape\n",
    "        \n",
    "        # K-fold cross validation sets, index 0 is full dataset\n",
    "        self.X = [X]\n",
    "        self.Xval = [None]\n",
    "        self.y = [y]\n",
    "        self.yval = [None]\n",
    "        \n",
    "        for idx_train, idx_val in self.kfold.split(X, y):\n",
    "            self.X.append(X[idx_train])\n",
    "            self.y.append(y[idx_train])\n",
    "            self.Xval.append(X[idx_val])\n",
    "            self.yval.append(y[idx_val])\n",
    "        \n",
    "        # one-hot form of y\n",
    "#         self.y_oh = []\n",
    "#         self.yval_oh = []\n",
    "#         for i in range(self.k+1):\n",
    "#             self.y_oh.append(torch.zeros((len(self.y[i]), 2)))\n",
    "#             self.y_oh[i].index_select(0, self.y[i].type(torch.int64))\n",
    "#             if i == 0:\n",
    "#                 self.yval_oh.append(None)\n",
    "#             else:\n",
    "#                 self.yval_oh.append(torch.zeros((len(self.yval[i]), 2)))\n",
    "#                 self.yval_oh[i].index_select(0, self.yval[i].type(torch.int64))\n",
    "            \n",
    "    def _step(self, i, steps):\n",
    "        for j in range(steps):\n",
    "            fx = self.models[i](self.X[i])\n",
    "            loss = self.loss_func(fx, self.y[i])\n",
    "            self.optim[i].zero_grad()\n",
    "            loss.backward()\n",
    "            print(loss)\n",
    "            print(self.models[i].linear.weight.grad)\n",
    "            self.optim[i].step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def step(self, steps=1, log=True):\n",
    "        train_loss = [self._step(i, steps) for i in range(self.k+1)]\n",
    "        val_accur = []\n",
    "        for i in range(1, self.k+1):\n",
    "            y_pred = torch.round(torch.squeeze(self.models[i](self.Xval[i]))).type(torch.bool)\n",
    "            val_accur.append(torch.sum(y_pred == self.yval[i]) / (len(self.yval[i]) + 1e-10))\n",
    "            \n",
    "        if log:\n",
    "            print('train loss', np.mean(train_loss), train_loss)\n",
    "            print('validation accuracy', np.mean(val_accur), val_accur)\n",
    "            print(self.models[0].weights())\n",
    "            print()\n",
    "            \n",
    "        self.step_ctr += steps\n",
    "        self.train_loss = train_loss\n",
    "        self.val_accur = val_accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.0634, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(24.1996, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.4131, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(76.1240, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "train loss 63.20002596928233 [76.06338871656276, 24.19956695996683, 76.4131386188787, 76.12400958172103]\n",
      "validation accuracy 0.41417125 [tensor(0.7628), tensor(0.2350), tensor(0.2447)]\n",
      "(Parameter containing:\n",
      "tensor([[-0.0584, -0.0840, -0.0170,  0.0511,  0.0246, -0.0302, -0.0250, -0.0292,\n",
      "         -0.0856, -0.0449,  0.0024,  0.0911,  0.0350, -0.0275,  0.0322, -0.0145,\n",
      "         -0.0008, -0.0485,  0.0825, -0.0718, -0.0735,  0.0191, -0.0477, -0.0138,\n",
      "         -0.0941, -0.0827, -0.0234, -0.0767, -0.0681, -0.0756, -0.0412,  0.0482,\n",
      "         -0.0927,  0.0244, -0.0041,  0.0936, -0.0563, -0.0539, -0.0448,  0.0309,\n",
      "         -0.0900,  0.0121, -0.0792,  0.0484, -0.0764,  0.0870, -0.0721, -0.0168,\n",
      "         -0.0401,  0.0571, -0.0366, -0.0436,  0.0664,  0.0125,  0.0895,  0.0931,\n",
      "          0.0200, -0.0186, -0.0203, -0.0500, -0.0377, -0.0270,  0.0313, -0.0127,\n",
      "         -0.0003,  0.0036, -0.0031, -0.0543,  0.0705, -0.0559, -0.0584, -0.0464,\n",
      "         -0.0907, -0.0292,  0.0742, -0.0943,  0.0098,  0.0064,  0.0918,  0.0422,\n",
      "         -0.0504,  0.0648, -0.0105, -0.0378, -0.0485,  0.0366,  0.0689,  0.0459,\n",
      "         -0.0022,  0.0358,  0.0710, -0.0453,  0.0143,  0.0081,  0.0263, -0.0257,\n",
      "         -0.0594, -0.0859,  0.0372, -0.0183, -0.0505,  0.0127, -0.0926,  0.0410,\n",
      "          0.0286, -0.0944,  0.0262,  0.0494,  0.0398, -0.0635,  0.0709, -0.0165]],\n",
      "       dtype=torch.float64, requires_grad=True), None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "G.trainer = Trainer(3, G.X_train.shape[1])\n",
    "G.trainer.setdata(G.X_train, G.y_train)\n",
    "num_iter = 1\n",
    "for i in range(num_iter):\n",
    "    print('i', i)\n",
    "    G.trainer.step(10, True)\n",
    "#         joblib.dump(G.model, '2/'+str(i)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.16 0.31 0.83 0.   0.01 0.01 0.87 0.   0.04 0.68 0.6  0.01 0.25\n",
      " 0.6  0.86 0.   0.34 0.01 0.83 0.65 0.   0.   0.03 0.37 0.87 0.   0.01\n",
      " 0.3  0.07 0.91 0.01 0.05 0.17 0.01 0.21 0.6  0.   0.   0.   0.76 0.59\n",
      " 0.14 0.04 0.   0.41 0.06 0.77 0.   0.18 0.   0.01 0.   0.38 0.04 0.\n",
      " 0.28 0.86 0.9  0.12 0.09 0.11 0.06 0.   0.03 0.02 0.99 0.   0.07 0.42\n",
      " 1.   0.62 0.06 0.   0.06 0.   0.26 0.23 0.35 0.   0.42 0.08 0.03 1.\n",
      " 0.2  0.02 0.   0.51 0.01 0.86 0.1  0.01 0.8  0.27 0.04 0.   0.02 0.1\n",
      " 0.32 0.   0.28 0.01 0.   0.01 0.03 0.01 0.4  0.02 0.   0.   0.   0.18\n",
      " 0.41 0.   0.22 0.01 0.32 0.   0.03 0.1  0.08 0.   0.01 0.07 0.01 0.01\n",
      " 0.95 0.01 0.19 0.97 0.42 0.   0.   0.89 0.35 0.03 0.41 0.09 0.2  0.02\n",
      " 0.76 0.   0.94 0.85 0.03 0.06 0.09 0.25 1.   0.02 0.   0.03 0.05 0.01\n",
      " 0.78 0.   0.01 0.03 0.01 0.33 0.07 0.23 0.09 0.04 0.77 0.39 0.62 0.35\n",
      " 0.   0.1  0.79 0.22 0.02 0.48 0.06 0.54 0.13 0.25 0.35 0.59 0.39 1.\n",
      " 0.03 0.3  0.03 0.08 0.05 0.01 0.03 0.   0.88 0.29 0.04 0.01 0.01 0.03\n",
      " 0.1  0.94 0.   0.07 0.54 0.62 0.22 0.11 0.6  0.63 0.13 0.12 0.79 0.38\n",
      " 0.   0.   0.33 0.47 0.01 0.25 0.02 0.   0.06 0.03 0.52 0.01 0.05 0.5\n",
      " 0.55 0.4  1.   0.48 0.   0.1  0.   0.87 0.15 0.36 0.02 0.07 0.89 0.\n",
      " 0.02 0.15 0.   0.72 0.   0.21 0.   0.38 0.13 0.05 0.45 0.19 0.   0.09\n",
      " 0.36 0.25 0.06 0.   0.51 0.01 0.01 0.21 0.78 0.11 0.02 0.01 0.07 0.28\n",
      " 0.25 0.05 0.   0.1  0.3  0.16 0.66 0.3  0.26 0.   0.04 0.   1.   0.03\n",
      " 0.35 0.1  0.   0.04 0.57 0.03 0.   0.58 0.45 0.05 0.59 0.09 0.19 0.01\n",
      " 0.06 0.03 0.01 0.01 0.99 0.42 0.38 0.   0.02 0.01 0.   0.08 0.06 0.02\n",
      " 0.86 0.39 0.56 0.   0.25 0.54 0.6  0.12 0.01 0.   0.68 0.15 0.03 0.81\n",
      " 0.27 0.04 0.   0.68 0.13 0.   0.25 1.   0.   0.   0.32 0.09 0.92 0.\n",
      " 0.   0.01 0.2  0.22 0.12 0.18 0.02 0.77 0.96 0.05 1.   0.52 0.   0.05\n",
      " 0.02 0.   0.01 0.08 0.26 0.63 0.14 1.   0.11 0.02 0.15 0.18 0.01 0.12\n",
      " 0.42 0.8  0.57 0.53 0.27 0.   0.24 0.01 0.1  0.62 0.01 0.47 0.8  0.\n",
      " 0.04 0.   0.33 0.05 0.98 0.04 0.09 0.01 0.02 0.02 0.35 0.87 0.1  0.01\n",
      " 0.19 0.   0.02 0.02 0.84 0.09 0.65 0.75 0.09 0.   0.   0.04 0.33 0.02\n",
      " 0.07 0.01 0.01 0.64 0.01 0.29 0.   0.   0.12 0.2  0.07 0.54 1.   0.39\n",
      " 0.02 0.02 0.02 0.07 0.01 0.06 0.01 0.01 0.   0.   0.34 0.   0.31 0.01\n",
      " 0.   0.63 0.51 0.   0.53 0.88 0.33 0.28 0.01 0.5  0.   0.91 0.84 0.09\n",
      " 0.01 0.02 0.17 0.11 0.83 0.07 0.03 0.02 0.02 0.71 0.   0.25 0.23 0.14\n",
      " 0.72 0.08 0.14 0.01 0.87 0.25 0.13 0.   0.   0.02 0.02 0.34 0.02 0.02\n",
      " 0.1  0.02 0.43 0.05 0.54 0.02 0.   1.   0.02 0.08 0.   0.01 0.06 0.08\n",
      " 0.02 0.02 0.22 0.06 0.07 0.59 0.   0.12 0.   0.21 0.17 0.32 0.42 0.06\n",
      " 0.26 0.28 0.   0.99 0.   0.26 0.   0.01 0.   0.   0.02 0.   0.   0.03\n",
      " 0.98 0.   0.09 0.15 0.3  0.   0.63 0.03 0.65 0.38 0.15 0.99 0.28 0.01\n",
      " 0.02 0.09 0.22 0.6  0.14 0.78 0.43 0.   0.18 0.68 0.14 0.   0.83 0.43\n",
      " 0.72 0.17 0.11 0.32 0.   0.   0.71 0.63 0.43 0.15 0.36 0.73 0.72 0.01\n",
      " 0.02 0.01 0.47 0.03 0.01 0.04 0.17 0.02 0.73 0.   0.43 0.05 0.33 0.02\n",
      " 0.72 0.86 0.1  0.37 0.82 0.48 0.12 0.71 0.69 0.01 0.03 0.02 0.32 0.86\n",
      " 0.   0.02 0.   0.13 0.21 0.   0.82 0.02 0.01 0.65 0.82 0.   0.4  0.04\n",
      " 0.18 0.59 0.01 0.01 0.01 0.46 0.03 0.07 0.38 0.97 0.   0.02 0.21 0.11\n",
      " 0.   0.43 0.07 0.98 0.25 0.01 0.02 0.07 0.13 0.94 0.38 0.97 0.17 0.24\n",
      " 0.06 0.04 0.26 0.   0.1  0.96 0.1  0.01 0.59 0.   0.03 0.   0.9  1.\n",
      " 0.01 0.   0.   0.51 0.03 0.   0.13 0.   0.92 0.22 0.49 0.   0.83 0.01\n",
      " 0.12 0.06 0.64 0.06 0.01 0.   0.08 0.04 0.28 0.04 0.15 0.55 0.   0.02\n",
      " 0.05 0.87 0.   0.   0.04 0.01 0.02 0.98 0.21 0.02 0.3  0.44 0.6  0.07\n",
      " 0.64 0.   0.05 0.14 0.11 0.01 1.   0.2  0.34 0.   0.01 0.01 0.63 0.83\n",
      " 0.05 0.75 1.   0.   0.01 0.03 0.21 0.02 0.53 0.84 0.11 0.5  0.43 0.03\n",
      " 0.4  0.01 0.18 0.01 0.79 0.94 0.18 0.69 0.1  0.05 0.06 0.08 0.99 0.02\n",
      " 0.   0.1  0.15 0.25 0.78 0.01 0.   0.23 0.26 0.42 0.01 0.01 0.07 0.29\n",
      " 0.18 0.52 0.06 0.01 0.03 0.31 0.55 0.5  0.87 0.58 0.03 0.02 0.22 0.38\n",
      " 0.03 0.09 0.54 0.63 0.2  0.4  0.08 0.01 0.   0.   0.01 0.01 0.   0.47\n",
      " 0.   0.   0.02 0.   0.51 0.66 0.76 0.04 0.09 0.   0.01 0.63 0.33 0.05\n",
      " 0.67 0.86 0.67 0.23 0.27 0.04 0.14 0.   0.01 0.02 0.2  0.28 0.09 0.64\n",
      " 0.01 0.38 0.01 0.1  0.22 0.12 0.25 0.41 0.08 0.89 0.02 0.07 0.6  0.1\n",
      " 0.07 0.31 0.02 0.72 0.02 0.   0.   0.14 0.   0.02 0.04 0.03 0.51 0.01\n",
      " 0.02 0.   0.79 0.88 0.1  0.04 0.31 0.24 0.18 0.03 0.14 0.06 0.01 0.2\n",
      " 0.07 0.   0.   0.39 0.01 0.04 0.59 0.47 0.82 0.01 0.06 0.99 0.   0.44\n",
      " 0.01 0.12 0.32 0.2  0.74 0.15 0.02 0.32 0.02 0.03 0.06 0.06 0.79 0.13\n",
      " 0.92 0.02 0.06 0.11 0.49 0.21 0.02 0.25 0.06 0.01 0.68 0.66 0.03 0.07\n",
      " 1.   0.   0.4  0.75 0.11 0.77 0.43 0.72 0.12 0.22 0.34 0.   0.48 0.01\n",
      " 0.13 0.88 0.   0.16 0.61 0.83 0.02 0.   0.02 0.91 0.69 0.35 0.53 0.35\n",
      " 0.01 0.03 0.27 0.   0.53 0.   0.17 0.35 0.3  0.01 0.6  0.84 0.48 0.43\n",
      " 0.02 0.07 0.01 0.07 0.14 0.   0.01 0.66 0.16 0.   0.28 0.5  0.01 0.52\n",
      " 0.   0.01 0.23 0.56 0.01 0.39 0.   0.71 0.16 0.   0.13 0.35 0.05 0.\n",
      " 0.34 0.   0.56 0.   0.07 0.38 0.5  0.37 0.   0.01 0.05 0.   0.85 0.\n",
      " 0.02 0.49 0.07 0.   0.25 1.   0.31 0.07 0.06 0.1  0.01 0.62 1.   1.\n",
      " 0.32 0.   0.03 0.17 0.34 0.12 0.3  0.13 0.   0.   0.65 0.84 1.   0.41\n",
      " 0.33 0.   0.01 0.01 0.65 0.16]\n"
     ]
    }
   ],
   "source": [
    "def predict(X, w):\n",
    "    y = sigmoid(X @ w)\n",
    "    print(y[:100])\n",
    "    y = np.rint(y).astype(np.int8)\n",
    "    return y\n",
    "\n",
    "G.y_test = predict(G.X_test, G.model.w[0])#joblib.load('logistic-85589.pkl'))\n",
    "df_pred = pd.DataFrame({\n",
    "    'id': np.arange(1, len(G.X_test)+1),\n",
    "    'label': G.y_test\n",
    "})\n",
    "df_pred.to_csv('submission.csv', index=False)\n",
    "print(df_pred['label'].values[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
